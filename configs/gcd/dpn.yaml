# ===================================================================
# BOLT Platform: DPN 算法配置文件 (v2)
# ===================================================================

# --- 必需参数 ---
dataset: "banking"
known_cls_ratio: 0.25

# --- 常用参数 ---
seed: 0
data_dir: "data"
save_results_path: "results/gcd/dpn"
pretrain_dir: "outputs/gcd/dpn/premodels"
bert_model: "./pretrained_models/bert-base-uncased"
labeled_ratio: 0.1
fold_num: 5
fold_idx: 0

# --- 训练参数 ---
pretrain_batch_size: 32
train_batch_size: 256
eval_batch_size: 64
num_pretrain_epochs: 100
num_train_epochs: 100
lr_pre: !!float 5e-5
lr: !!float 1e-5
warmup_proportion: 0.1
wait_patient: 20

# --- 算法专属参数 ---
method: "DPN"
cluster_num_factor: 1.0
feat_dim: 768
momentum_factor: 0.9
temperature: 0.07

# --- 【新增】数据集专属配置 ---
dataset_specific_configs:
  clinc:
    max_seq_length: 30
    gamma: 10
    num_train_epochs: 80
  stackoverflow:
    max_seq_length: 45
    gamma: 90
    num_train_epochs: 10
  banking:
    max_seq_length: 55
    gamma: 10
    num_train_epochs: 60
  mcid:
    max_seq_length: 65
    gamma: 30
    num_train_epochs: 80
  ecdt:
    max_seq_length: 65
    gamma: 30
    num_train_epochs: 80
  hwu:
    max_seq_length: 20
    gamma: 30
    num_train_epochs: 80
  # --- 新增补齐的配置 ---
  # 1. 短文本数据集 (Short Text Datasets)
  TREC:
    max_seq_length: 40
    gamma: 10
    num_train_epochs: 80
  
  # 2. 中等规模/段落数据集 (Medium-Scale / Paragraph Datasets)
  AGNews:
    max_seq_length: 128
    gamma: 30
    num_train_epochs: 30
  Yahoo: # Yahoo Answers
    max_seq_length: 128
    gamma: 30
    num_train_epochs: 30
  DBPedia:
    max_seq_length: 256
    gamma: 30
    train_batch_size: 16
    eval_batch_size: 32
    pretrain_batch_size: 16
    num_train_epochs: 30
  medical:
    max_seq_length: 256
    gamma: 30
    num_train_epochs: 30

  # 3. 大型文档数据集 (Large Document Datasets)
  ele:
    max_seq_length: 200
    gamma: 90
    num_train_epochs: 10
  news:
    max_seq_length: 500
    gamma: 90
    num_train_epochs: 10
    train_batch_size: 8
    eval_batch_size: 32
    pretrain_batch_size: 16
  thucnews:
    max_seq_length: 500
    gamma: 90
    num_train_epochs: 10
    train_batch_size: 16
    eval_batch_size: 32
    pretrain_batch_size: 16
  20NG: # 20 Newsgroups
    max_seq_length: 512
    gamma: 90
    num_train_epochs: 10
    train_batch_size: 16
    eval_batch_size: 32
    pretrain_batch_size: 16
  X-Topic:
    max_seq_length: 512
    gamma: 90
    num_train_epochs: 10