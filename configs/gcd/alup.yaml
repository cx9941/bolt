# ALUP 方法的统一配置文件
# ----------------------------------

# --- 任务设置 ---
dataset: "banking"
known_cls_ratio: 0.25
labeled_ratio: 0.1
seed: 0
fold_idx: 0  # 沿用Glean/SDC的交叉验证文件夹索引
fold_num: 5 

# --- 路径与环境设置 ---
gpu_id: "0"
data_dir: "./data"
bert_model: "./pretrained_models/bert-base-uncased"
# `output_base_dir` 是一个基础路径，脚本会在此基础上创建pretrain和finetune的子目录
output_base_dir: "./outputs/gcd/alup" 

# --- 训练超参数 ---
num_pretrain_epochs: 100 # 对应ALUP的预训练阶段
num_train_epochs: 34     # 对应ALUP的对比学习和主动学习微调阶段
pretrain_batch_size: 16
train_batch_size: 32
eval_batch_size: 64
lr: !!float 1e-5
lr_pre: !!float 5e-5
warmup_proportion: 0.1
wait_patient: 20
finish_pretrain: False 
early_stopping_patience: 5        # 等待多少个epoch没提升就停
early_stopping_min_delta: 0.001   # 至少提升多少才算改进
monitor_sum_metrics: true         # 是否监控 ACC+ARI+NMI (true)，否则只看 ACC

# --- ALUP 算法超参数 ---
# 对比学习与数据增强
cluster_num_factor: 1.0
embed_feat_dim: 768
head_feat_dim: 128
topk: 50
rtr_prob: 0.25
update_per_epoch: 5 # 主动学习更新频率

# 主动学习与LLM
llm_model_name: 'deepseek-v3:671b' # 你的LLM模型
api_base: 'https://uni-api.cstcloud.cn/v1' # 你的API地址
comparison_cluster_ratio: 0.5
student_t_freedom: 1
uncertainty_neighbour_num: 25
rho: 0.1

# --- 数据集专属配置 (从ALUP代码中提取) ---
dataset_specific_configs:
  hwu:
    max_seq_length: 55
  clinc:
    max_seq_length: 30
  banking:
    max_seq_length: 55
  stackoverflow:
    max_seq_length: 45
  mcid:
    max_seq_length: 55
  ecdt:
    max_seq_length: 55
  # --- Medium Length / Paragraph Datasets ---
  stackoverflow:
    max_seq_length: 45 # Although a large dataset, individual posts for classification are often concise.
  AGNews:
    max_seq_length: 128
  Yahoo: # Yahoo Answers
    max_seq_length: 128
  ele:
    max_seq_length: 200
  DBPedia:
    max_seq_length: 256
  medical:
    max_seq_length: 256

  # --- Long Document Datasets ---
  news:
    max_seq_length: 500
  thucnews:
    max_seq_length: 500
  20NG: # 20 Newsgroups
    max_seq_length: 512
  X-Topic:
    max_seq_length: 512