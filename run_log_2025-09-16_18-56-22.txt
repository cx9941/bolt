======== Script Execution Log started at Tue Sep 16 06:56:22 PM UTC 2025 ========

-----------------------------------------------------
INFO: Starting script: scripts/gcd/dpn.sh

>>>>>>>>>> Starting process for dataset: [banking] <<<<<<<<<<
========================================================================
Running DPN with: dataset=banking, known_cls_ratio=0.25, fold=0, seed=0
========================================================================
Data and Parameters Initialization...
num_labeled_samples 1150
num_unlabeled_samples 7853
Pre-training begin...
Epoch:   0%|          | 0/1 [00:00<?, ?it/s]Epoch: 100%|██████████| 1/1 [00:43<00:00, 43.63s/it]Epoch: 100%|██████████| 1/1 [00:43<00:00, 43.63s/it]
Epoch 0 train_loss: 5.527095240058628
Epoch 0 eval_score: 95.74
Pre-training finished!
Training begin...
Performing k-means...
K-means finished
Fine-tuning Epochs:   0%|          | 0/60 [00:00<?, ?it/s]Fine-tuning Epochs:   0%|          | 0/60 [00:14<?, ?it/s, avg_loss=9.2630]Fine-tuning Epochs:   2%|▏         | 1/60 [00:16<16:13, 16.50s/it, avg_loss=9.2630]Fine-tuning Epochs:   2%|▏         | 1/60 [00:31<16:13, 16.50s/it, avg_loss=9.0774]Fine-tuning Epochs:   3%|▎         | 2/60 [00:33<16:08, 16.70s/it, avg_loss=9.0774]Fine-tuning Epochs:   3%|▎         | 2/60 [00:48<16:08, 16.70s/it, avg_loss=8.8603]Fine-tuning Epochs:   5%|▌         | 3/60 [00:50<16:01, 16.86s/it, avg_loss=8.8603]Fine-tuning Epochs:   5%|▌         | 3/60 [01:05<16:01, 16.86s/it, avg_loss=8.6228]Fine-tuning Epochs:   7%|▋         | 4/60 [01:07<15:53, 17.02s/it, avg_loss=8.6228]Fine-tuning Epochs:   7%|▋         | 4/60 [01:22<15:53, 17.02s/it, avg_loss=8.3745]Fine-tuning Epochs:   8%|▊         | 5/60 [01:24<15:40, 17.09s/it, avg_loss=8.3745]Fine-tuning Epochs:   8%|▊         | 5/60 [01:39<15:40, 17.09s/it, avg_loss=8.1139]Fine-tuning Epochs:  10%|█         | 6/60 [01:42<15:24, 17.13s/it, avg_loss=8.1139]Fine-tuning Epochs:  10%|█         | 6/60 [01:57<15:24, 17.13s/it, avg_loss=7.8856]Fine-tuning Epochs:  12%|█▏        | 7/60 [01:59<15:11, 17.21s/it, avg_loss=7.8856]Fine-tuning Epochs:  12%|█▏        | 7/60 [02:14<15:11, 17.21s/it, avg_loss=7.7269]Fine-tuning Epochs:  13%|█▎        | 8/60 [02:16<14:57, 17.26s/it, avg_loss=7.7269]Fine-tuning Epochs:  13%|█▎        | 8/60 [02:31<14:57, 17.26s/it, avg_loss=7.5858]Fine-tuning Epochs:  15%|█▌        | 9/60 [02:34<14:42, 17.29s/it, avg_loss=7.5858]Fine-tuning Epochs:  15%|█▌        | 9/60 [02:49<14:42, 17.29s/it, avg_loss=7.4799]Fine-tuning Epochs:  17%|█▋        | 10/60 [02:51<14:23, 17.27s/it, avg_loss=7.4799]Fine-tuning Epochs:  17%|█▋        | 10/60 [03:06<14:23, 17.27s/it, avg_loss=7.3806]Fine-tuning Epochs:  18%|█▊        | 11/60 [03:09<14:11, 17.37s/it, avg_loss=7.3806]Fine-tuning Epochs:  18%|█▊        | 11/60 [03:24<14:11, 17.37s/it, avg_loss=7.2770]Fine-tuning Epochs:  20%|██        | 12/60 [03:26<13:53, 17.37s/it, avg_loss=7.2770]Fine-tuning Epochs:  20%|██        | 12/60 [03:41<13:53, 17.37s/it, avg_loss=7.1999]Fine-tuning Epochs:  22%|██▏       | 13/60 [03:43<13:35, 17.35s/it, avg_loss=7.1999]Fine-tuning Epochs:  22%|██▏       | 13/60 [03:58<13:35, 17.35s/it, avg_loss=7.1224]Fine-tuning Epochs:  23%|██▎       | 14/60 [04:01<13:19, 17.38s/it, avg_loss=7.1224]Fine-tuning Epochs:  23%|██▎       | 14/60 [04:16<13:19, 17.38s/it, avg_loss=7.0538]Fine-tuning Epochs:  25%|██▌       | 15/60 [04:18<13:00, 17.35s/it, avg_loss=7.0538]Fine-tuning Epochs:  25%|██▌       | 15/60 [04:33<13:00, 17.35s/it, avg_loss=6.9913]Fine-tuning Epochs:  27%|██▋       | 16/60 [04:35<12:43, 17.36s/it, avg_loss=6.9913]Fine-tuning Epochs:  27%|██▋       | 16/60 [04:50<12:43, 17.36s/it, avg_loss=6.9377]Fine-tuning Epochs:  28%|██▊       | 17/60 [04:53<12:26, 17.37s/it, avg_loss=6.9377]Fine-tuning Epochs:  28%|██▊       | 17/60 [05:08<12:26, 17.37s/it, avg_loss=6.8724]Fine-tuning Epochs:  30%|███       | 18/60 [05:10<12:08, 17.35s/it, avg_loss=6.8724]Fine-tuning Epochs:  30%|███       | 18/60 [05:25<12:08, 17.35s/it, avg_loss=6.8313]Fine-tuning Epochs:  32%|███▏      | 19/60 [05:27<11:51, 17.35s/it, avg_loss=6.8313]Fine-tuning Epochs:  32%|███▏      | 19/60 [05:42<11:51, 17.35s/it, avg_loss=6.7783]Fine-tuning Epochs:  33%|███▎      | 20/60 [05:44<11:31, 17.29s/it, avg_loss=6.7783]Fine-tuning Epochs:  33%|███▎      | 20/60 [06:00<11:31, 17.29s/it, avg_loss=6.7389]Fine-tuning Epochs:  35%|███▌      | 21/60 [06:02<11:14, 17.30s/it, avg_loss=6.7389]Fine-tuning Epochs:  35%|███▌      | 21/60 [06:17<11:14, 17.30s/it, avg_loss=6.6912]Fine-tuning Epochs:  37%|███▋      | 22/60 [06:19<11:00, 17.39s/it, avg_loss=6.6912]Fine-tuning Epochs:  37%|███▋      | 22/60 [06:34<11:00, 17.39s/it, avg_loss=6.6616]Fine-tuning Epochs:  38%|███▊      | 23/60 [06:37<10:43, 17.39s/it, avg_loss=6.6616]Fine-tuning Epochs:  38%|███▊      | 23/60 [06:52<10:43, 17.39s/it, avg_loss=6.6271]Fine-tuning Epochs:  40%|████      | 24/60 [06:54<10:23, 17.32s/it, avg_loss=6.6271]Fine-tuning Epochs:  40%|████      | 24/60 [07:09<10:23, 17.32s/it, avg_loss=6.5961]Fine-tuning Epochs:  42%|████▏     | 25/60 [07:11<10:07, 17.34s/it, avg_loss=6.5961]Fine-tuning Epochs:  42%|████▏     | 25/60 [07:26<10:07, 17.34s/it, avg_loss=6.5838]Fine-tuning Epochs:  43%|████▎     | 26/60 [07:29<09:50, 17.35s/it, avg_loss=6.5838]Fine-tuning Epochs:  43%|████▎     | 26/60 [07:44<09:50, 17.35s/it, avg_loss=6.5367]Fine-tuning Epochs:  45%|████▌     | 27/60 [07:46<09:32, 17.33s/it, avg_loss=6.5367]Fine-tuning Epochs:  45%|████▌     | 27/60 [08:01<09:32, 17.33s/it, avg_loss=6.5179]Fine-tuning Epochs:  47%|████▋     | 28/60 [08:03<09:13, 17.29s/it, avg_loss=6.5179]Fine-tuning Epochs:  47%|████▋     | 28/60 [08:18<09:13, 17.29s/it, avg_loss=6.4900]Fine-tuning Epochs:  48%|████▊     | 29/60 [08:20<08:54, 17.25s/it, avg_loss=6.4900]Fine-tuning Epochs:  48%|████▊     | 29/60 [08:35<08:54, 17.25s/it, avg_loss=6.4660]Fine-tuning Epochs:  50%|█████     | 30/60 [08:37<08:35, 17.18s/it, avg_loss=6.4660]Fine-tuning Epochs:  50%|█████     | 30/60 [08:52<08:35, 17.18s/it, avg_loss=6.4602]Fine-tuning Epochs:  52%|█████▏    | 31/60 [08:55<08:18, 17.21s/it, avg_loss=6.4602]Fine-tuning Epochs:  52%|█████▏    | 31/60 [09:10<08:18, 17.21s/it, avg_loss=6.4336]Fine-tuning Epochs:  53%|█████▎    | 32/60 [09:12<08:01, 17.20s/it, avg_loss=6.4336]Fine-tuning Epochs:  53%|█████▎    | 32/60 [09:27<08:01, 17.20s/it, avg_loss=6.4216]Fine-tuning Epochs:  55%|█████▌    | 33/60 [09:29<07:44, 17.21s/it, avg_loss=6.4216]Fine-tuning Epochs:  55%|█████▌    | 33/60 [09:44<07:44, 17.21s/it, avg_loss=6.3927]Fine-tuning Epochs:  57%|█████▋    | 34/60 [09:46<07:26, 17.18s/it, avg_loss=6.3927]Fine-tuning Epochs:  57%|█████▋    | 34/60 [10:01<07:26, 17.18s/it, avg_loss=6.3818]Fine-tuning Epochs:  58%|█████▊    | 35/60 [10:03<07:08, 17.16s/it, avg_loss=6.3818]Fine-tuning Epochs:  58%|█████▊    | 35/60 [10:18<07:08, 17.16s/it, avg_loss=6.3624]Fine-tuning Epochs:  60%|██████    | 36/60 [10:20<06:52, 17.17s/it, avg_loss=6.3624]Fine-tuning Epochs:  60%|██████    | 36/60 [10:35<06:52, 17.17s/it, avg_loss=6.3497]Fine-tuning Epochs:  62%|██████▏   | 37/60 [10:38<06:34, 17.17s/it, avg_loss=6.3497]Fine-tuning Epochs:  62%|██████▏   | 37/60 [10:53<06:34, 17.17s/it, avg_loss=6.3463]Fine-tuning Epochs:  63%|██████▎   | 38/60 [10:55<06:17, 17.17s/it, avg_loss=6.3463]Fine-tuning Epochs:  63%|██████▎   | 38/60 [11:10<06:17, 17.17s/it, avg_loss=6.3243]Fine-tuning Epochs:  65%|██████▌   | 39/60 [11:12<06:00, 17.18s/it, avg_loss=6.3243]Fine-tuning Epochs:  65%|██████▌   | 39/60 [11:27<06:00, 17.18s/it, avg_loss=6.3131]Fine-tuning Epochs:  67%|██████▋   | 40/60 [11:29<05:42, 17.11s/it, avg_loss=6.3131]Fine-tuning Epochs:  67%|██████▋   | 40/60 [11:44<05:42, 17.11s/it, avg_loss=6.2972]Fine-tuning Epochs:  67%|██████▋   | 40/60 [11:46<05:53, 17.67s/it, avg_loss=6.2972]
Epoch 1 loss: 9.2630
Epoch 2 loss: 9.0774
Epoch 3 loss: 8.8603
Epoch 4 loss: 8.6228
Epoch 5 loss: 8.3745
Epoch 6 loss: 8.1139
Epoch 7 loss: 7.8856
Epoch 8 loss: 7.7269
Epoch 9 loss: 7.5858
Epoch 10 loss: 7.4799
Epoch 11 loss: 7.3806
Epoch 12 loss: 7.2770
Epoch 13 loss: 7.1999
Epoch 14 loss: 7.1224
Epoch 15 loss: 7.0538
Epoch 16 loss: 6.9913
Epoch 17 loss: 6.9377
Epoch 18 loss: 6.8724
Epoch 19 loss: 6.8313
Epoch 20 loss: 6.7783
Epoch 21 loss: 6.7389
Epoch 22 loss: 6.6912
Epoch 23 loss: 6.6616
Epoch 24 loss: 6.6271
Epoch 25 loss: 6.5961
Epoch 26 loss: 6.5838
Epoch 27 loss: 6.5367
Epoch 28 loss: 6.5179
Epoch 29 loss: 6.4900
Epoch 30 loss: 6.4660
Epoch 31 loss: 6.4602
Epoch 32 loss: 6.4336
Epoch 33 loss: 6.4216
Epoch 34 loss: 6.3927
Epoch 35 loss: 6.3818
Epoch 36 loss: 6.3624
Epoch 37 loss: 6.3497
Epoch 38 loss: 6.3463
Epoch 39 loss: 6.3243
Epoch 40 loss: 6.3131
Epoch 41 loss: 6.2972
[EarlyStop] stop at epoch 41: best NMI=86.71
Training finished!
Evaluation begin...
{'ACC': 36.49, 'H-Score': 34.27, 'K-ACC': 81.71, 'N-ACC': 21.68, 'ARI': 25.9, 'NMI': 64.3}
test_results      ACC  H-Score  ...   K                                               args
0  44.55    44.45  ...  77  {"data_dir": "data", "pretrain_dir": "outputs/...
1  36.49    34.27  ...  77  {"data_dir": "data", "pretrain_dir": "outputs/...

[2 rows x 14 columns]
Evaluation finished!
All DPN experiments have been completed.
Final timing summary is available in 
SUCCESS: Script scripts/gcd/dpn.sh finished successfully in 824 seconds.

-----------------------------------------------------
INFO: Starting script: scripts/gcd/sdc.sh
========================================================================
Running SDC with: dataset=banking, known_cls_ratio=0.25, fold=0, seed=0
========================================================================
--- Stage 1: Running Pre-training (baseline.py) ---
Data and Parameters Initialization...
num_labeled_samples 229
num_unlabeled_samples 8774
77
Extracting representation for clustering:   0%|          | 0/8 [00:00<?, ?it/s]Extracting representation for clustering:  12%|█▎        | 1/8 [00:00<00:01,  4.21it/s]Extracting representation for clustering:  88%|████████▊ | 7/8 [00:00<00:00, 23.98it/s]Extracting representation for clustering: 100%|██████████| 8/8 [00:00<00:00, 21.13it/s]
Extracting representation for clustering:   0%|          | 0/282 [00:00<?, ?it/s]Extracting representation for clustering:   2%|▏         | 6/282 [00:00<00:05, 52.45it/s]Extracting representation for clustering:   4%|▍         | 12/282 [00:00<00:05, 45.68it/s]Extracting representation for clustering:   6%|▌         | 17/282 [00:00<00:06, 44.01it/s]Extracting representation for clustering:   8%|▊         | 22/282 [00:00<00:06, 43.21it/s]Extracting representation for clustering:  10%|▉         | 27/282 [00:00<00:05, 42.90it/s]Extracting representation for clustering:  11%|█▏        | 32/282 [00:00<00:05, 42.43it/s]Extracting representation for clustering:  13%|█▎        | 37/282 [00:00<00:05, 41.42it/s]Extracting representation for clustering:  15%|█▍        | 42/282 [00:00<00:05, 40.60it/s]Extracting representation for clustering:  17%|█▋        | 47/282 [00:01<00:05, 40.49it/s]Extracting representation for clustering:  18%|█▊        | 52/282 [00:01<00:05, 40.70it/s]Extracting representation for clustering:  20%|██        | 57/282 [00:01<00:05, 41.00it/s]Extracting representation for clustering:  22%|██▏       | 62/282 [00:01<00:05, 41.29it/s]Extracting representation for clustering:  24%|██▍       | 67/282 [00:01<00:05, 41.34it/s]Extracting representation for clustering:  26%|██▌       | 72/282 [00:01<00:05, 41.35it/s]Extracting representation for clustering:  27%|██▋       | 77/282 [00:01<00:04, 41.06it/s]Extracting representation for clustering:  29%|██▉       | 82/282 [00:01<00:04, 40.60it/s]Extracting representation for clustering:  31%|███       | 87/282 [00:02<00:04, 40.47it/s]Extracting representation for clustering:  33%|███▎      | 92/282 [00:02<00:04, 40.63it/s]Extracting representation for clustering:  34%|███▍      | 97/282 [00:02<00:04, 40.77it/s]Extracting representation for clustering:  36%|███▌      | 102/282 [00:02<00:04, 40.95it/s]Extracting representation for clustering:  38%|███▊      | 107/282 [00:02<00:04, 41.06it/s]Extracting representation for clustering:  40%|███▉      | 112/282 [00:02<00:04, 41.11it/s]Extracting representation for clustering:  41%|████▏     | 117/282 [00:02<00:04, 40.91it/s]Extracting representation for clustering:  43%|████▎     | 122/282 [00:02<00:03, 40.49it/s]Extracting representation for clustering:  45%|████▌     | 127/282 [00:03<00:03, 40.38it/s]Extracting representation for clustering:  47%|████▋     | 132/282 [00:03<00:03, 40.45it/s]Extracting representation for clustering:  49%|████▊     | 137/282 [00:03<00:03, 40.54it/s]Extracting representation for clustering:  50%|█████     | 142/282 [00:03<00:03, 40.81it/s]Extracting representation for clustering:  52%|█████▏    | 147/282 [00:03<00:03, 41.00it/s]Extracting representation for clustering:  54%|█████▍    | 152/282 [00:03<00:03, 41.02it/s]Extracting representation for clustering:  56%|█████▌    | 157/282 [00:03<00:03, 40.88it/s]Extracting representation for clustering:  57%|█████▋    | 162/282 [00:03<00:02, 40.63it/s]Extracting representation for clustering:  59%|█████▉    | 167/282 [00:04<00:02, 40.54it/s]Extracting representation for clustering:  61%|██████    | 172/282 [00:04<00:02, 40.51it/s]Extracting representation for clustering:  63%|██████▎   | 177/282 [00:04<00:02, 40.66it/s]Extracting representation for clustering:  65%|██████▍   | 182/282 [00:04<00:02, 40.77it/s]Extracting representation for clustering:  66%|██████▋   | 187/282 [00:04<00:02, 40.85it/s]Extracting representation for clustering:  68%|██████▊   | 192/282 [00:04<00:02, 41.01it/s]Extracting representation for clustering:  70%|██████▉   | 197/282 [00:04<00:02, 40.81it/s]Extracting representation for clustering:  72%|███████▏  | 202/282 [00:04<00:01, 40.57it/s]Extracting representation for clustering:  73%|███████▎  | 207/282 [00:05<00:01, 40.52it/s]Extracting representation for clustering:  75%|███████▌  | 212/282 [00:05<00:01, 40.53it/s]Extracting representation for clustering:  77%|███████▋  | 217/282 [00:05<00:01, 40.58it/s]Extracting representation for clustering:  79%|███████▊  | 222/282 [00:05<00:01, 40.71it/s]Extracting representation for clustering:  80%|████████  | 227/282 [00:05<00:01, 40.75it/s]Extracting representation for clustering:  82%|████████▏ | 232/282 [00:05<00:01, 40.84it/s]Extracting representation for clustering:  84%|████████▍ | 237/282 [00:05<00:01, 40.69it/s]Extracting representation for clustering:  86%|████████▌ | 242/282 [00:05<00:00, 40.48it/s]Extracting representation for clustering:  88%|████████▊ | 247/282 [00:06<00:00, 40.41it/s]Extracting representation for clustering:  89%|████████▉ | 252/282 [00:06<00:00, 40.52it/s]Extracting representation for clustering:  91%|█████████ | 257/282 [00:06<00:00, 40.55it/s]Extracting representation for clustering:  93%|█████████▎| 262/282 [00:06<00:00, 40.56it/s]Extracting representation for clustering:  95%|█████████▍| 267/282 [00:06<00:00, 40.56it/s]Extracting representation for clustering:  96%|█████████▋| 272/282 [00:06<00:00, 40.60it/s]Extracting representation for clustering:  98%|█████████▊| 277/282 [00:06<00:00, 40.56it/s]Extracting representation for clustering: 100%|██████████| 282/282 [00:06<00:00, 40.47it/s]Extracting representation for clustering: 100%|██████████| 282/282 [00:06<00:00, 40.96it/s]
--- Pre-training finished. ---
--- Stage 2: Running Main Training (train.py) ---
Data and Parameters Initialization...
num_labeled_samples 229
num_unlabeled_samples 8774
77
Extracting representation for clustering:   0%|          | 0/8 [00:00<?, ?it/s]Extracting representation for clustering:  12%|█▎        | 1/8 [00:00<00:01,  4.39it/s]Extracting representation for clustering:  88%|████████▊ | 7/8 [00:00<00:00, 25.43it/s]Extracting representation for clustering: 100%|██████████| 8/8 [00:00<00:00, 22.26it/s]
Extracting representation for clustering:   0%|          | 0/282 [00:00<?, ?it/s]Extracting representation for clustering:   2%|▏         | 6/282 [00:00<00:05, 54.67it/s]Extracting representation for clustering:   4%|▍         | 12/282 [00:00<00:05, 47.27it/s]Extracting representation for clustering:   6%|▌         | 17/282 [00:00<00:05, 45.39it/s]Extracting representation for clustering:   8%|▊         | 22/282 [00:00<00:05, 44.31it/s]Extracting representation for clustering:  10%|▉         | 27/282 [00:00<00:05, 43.85it/s]Extracting representation for clustering:  11%|█▏        | 32/282 [00:00<00:05, 43.57it/s]Extracting representation for clustering:  13%|█▎        | 37/282 [00:00<00:05, 42.76it/s]Extracting representation for clustering:  15%|█▍        | 42/282 [00:00<00:05, 41.93it/s]Extracting representation for clustering:  17%|█▋        | 47/282 [00:01<00:05, 41.47it/s]Extracting representation for clustering:  18%|█▊        | 52/282 [00:01<00:05, 41.60it/s]Extracting representation for clustering:  20%|██        | 57/282 [00:01<00:05, 41.88it/s]Extracting representation for clustering:  22%|██▏       | 62/282 [00:01<00:05, 42.08it/s]Extracting representation for clustering:  24%|██▍       | 67/282 [00:01<00:05, 42.33it/s]Extracting representation for clustering:  26%|██▌       | 72/282 [00:01<00:04, 42.50it/s]Extracting representation for clustering:  27%|██▋       | 77/282 [00:01<00:04, 42.49it/s]Extracting representation for clustering:  29%|██▉       | 82/282 [00:01<00:04, 42.06it/s]Extracting representation for clustering:  31%|███       | 87/282 [00:02<00:04, 41.64it/s]Extracting representation for clustering:  33%|███▎      | 92/282 [00:02<00:04, 41.51it/s]Extracting representation for clustering:  34%|███▍      | 97/282 [00:02<00:04, 41.71it/s]Extracting representation for clustering:  36%|███▌      | 102/282 [00:02<00:04, 41.88it/s]Extracting representation for clustering:  38%|███▊      | 107/282 [00:02<00:04, 41.99it/s]Extracting representation for clustering:  40%|███▉      | 112/282 [00:02<00:04, 42.16it/s]Extracting representation for clustering:  41%|████▏     | 117/282 [00:02<00:03, 42.31it/s]Extracting representation for clustering:  43%|████▎     | 122/282 [00:02<00:03, 41.93it/s]Extracting representation for clustering:  45%|████▌     | 127/282 [00:02<00:03, 41.61it/s]Extracting representation for clustering:  47%|████▋     | 132/282 [00:03<00:03, 41.49it/s]Extracting representation for clustering:  49%|████▊     | 137/282 [00:03<00:03, 41.55it/s]Extracting representation for clustering:  50%|█████     | 142/282 [00:03<00:03, 41.76it/s]Extracting representation for clustering:  52%|█████▏    | 147/282 [00:03<00:03, 41.85it/s]Extracting representation for clustering:  54%|█████▍    | 152/282 [00:03<00:03, 42.10it/s]Extracting representation for clustering:  56%|█████▌    | 157/282 [00:03<00:02, 42.23it/s]Extracting representation for clustering:  57%|█████▋    | 162/282 [00:03<00:02, 42.07it/s]Extracting representation for clustering:  59%|█████▉    | 167/282 [00:03<00:02, 41.84it/s]Extracting representation for clustering:  61%|██████    | 172/282 [00:04<00:02, 41.63it/s]Extracting representation for clustering:  63%|██████▎   | 177/282 [00:04<00:02, 41.69it/s]Extracting representation for clustering:  65%|██████▍   | 182/282 [00:04<00:02, 41.70it/s]Extracting representation for clustering:  66%|██████▋   | 187/282 [00:04<00:02, 41.84it/s]Extracting representation for clustering:  68%|██████▊   | 192/282 [00:04<00:02, 41.96it/s]Extracting representation for clustering:  70%|██████▉   | 197/282 [00:04<00:02, 42.10it/s]Extracting representation for clustering:  72%|███████▏  | 202/282 [00:04<00:01, 42.02it/s]Extracting representation for clustering:  73%|███████▎  | 207/282 [00:04<00:01, 41.86it/s]Extracting representation for clustering:  75%|███████▌  | 212/282 [00:05<00:01, 41.72it/s]Extracting representation for clustering:  77%|███████▋  | 217/282 [00:05<00:01, 41.66it/s]Extracting representation for clustering:  79%|███████▊  | 222/282 [00:05<00:01, 41.67it/s]Extracting representation for clustering:  80%|████████  | 227/282 [00:05<00:01, 41.74it/s]Extracting representation for clustering:  82%|████████▏ | 232/282 [00:05<00:01, 41.89it/s]Extracting representation for clustering:  84%|████████▍ | 237/282 [00:05<00:01, 41.87it/s]Extracting representation for clustering:  86%|████████▌ | 242/282 [00:05<00:00, 41.94it/s]Extracting representation for clustering:  88%|████████▊ | 247/282 [00:05<00:00, 41.83it/s]Extracting representation for clustering:  89%|████████▉ | 252/282 [00:05<00:00, 41.71it/s]Extracting representation for clustering:  91%|█████████ | 257/282 [00:06<00:00, 41.62it/s]Extracting representation for clustering:  93%|█████████▎| 262/282 [00:06<00:00, 41.56it/s]Extracting representation for clustering:  95%|█████████▍| 267/282 [00:06<00:00, 41.62it/s]Extracting representation for clustering:  96%|█████████▋| 272/282 [00:06<00:00, 41.63it/s]Extracting representation for clustering:  98%|█████████▊| 277/282 [00:06<00:00, 41.66it/s]Extracting representation for clustering: 100%|██████████| 282/282 [00:06<00:00, 41.77it/s]Extracting representation for clustering: 100%|██████████| 282/282 [00:06<00:00, 42.11it/s]
outputs/gcd/sdc/models/banking_0.25_0.1_fold0_seed0/premodel.pth has been trained.
Evaluation begin...
results {'ACC': 22.18, 'H-Score': 21.12, 'K-ACC': 19.47, 'N-ACC': 23.06, 'ARI': 8.82, 'NMI': 42.49}
test_results      ACC  H-Score  ...   K                                               args
0  22.18    21.12  ...  77  {"dataset": "banking", "known_cls_ratio": 0.25...

[1 rows x 15 columns]
Evaluation finished!
--- Main training finished. ---
All SDC experiments (two-stage) have been completed.
SUCCESS: Script scripts/gcd/sdc.sh finished successfully in 122 seconds.

-----------------------------------------------------
INFO: Starting script: scripts/openset/ab.sh

>>>>>>>>>> Starting process for dataset: [banking] (emb=sbert, seed=0) <<<<<<<<<<
====================================================
Running AB -> Dataset: banking, Embedding: sbert, Seed: 0, Known Ratio: 0.25
====================================================
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758049935.112198  179113 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46000 MB memory:  -> device: 0, name: NVIDIA RTX 5880 Ada Generation, pci bus id: 0000:0b:00.0, compute capability: 8.9
I0000 00:00:1758049935.113998  179113 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 2431 MB memory:  -> device: 1, name: NVIDIA RTX 5880 Ada Generation, pci bus id: 0000:0c:00.0, compute capability: 8.9
I0000 00:00:1758049935.115357  179113 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 2037 MB memory:  -> device: 2, name: NVIDIA RTX 5880 Ada Generation, pci bus id: 0000:1b:00.0, compute capability: 8.9
I0000 00:00:1758049935.116744  179113 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 46640 MB memory:  -> device: 3, name: NVIDIA RTX 5880 Ada Generation, pci bus id: 0000:1c:00.0, compute capability: 8.9
Loading standardized data...
Data loaded. Train samples: 229, Test samples: 3080
Loading embedding model: sbert...
Starting evaluation...

Results have been saved to: ./outputs/openset/ab/banking_sbert_0.25_0/metrics/results.csv
Appended new result row:
   dataset  seed  ...  N-F1                                               args
0  banking     0  ...  84.8  {"config": "configs/openset/ab.yaml", "seed": ...

[1 rows x 10 columns]
All AB experiments have been completed.
SUCCESS: Script scripts/openset/ab.sh finished successfully in 12 seconds.

-----------------------------------------------------
INFO: Starting script: scripts/openset/adb.sh
========================================================================
Running ADB with: dataset=banking, known_cls_ratio=0.25, seed=0
========================================================================
Data and Parameters Initialization...
Pre-training begin...
Epoch:   0%|          | 0/100 [00:00<?, ?it/s]
Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha = 1) (Triggered internally at /pytorch/torch/csrc/utils/python_arg_parser.cpp:1691.)
  next_m.mul_(beta1).add_(1 - beta1, grad)

Iteration:   6%|▌         | 1/18 [00:01<00:21,  1.28s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.10s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.08s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:13,  1.07s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:12,  1.07s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:11,  1.06s/it][A
Iteration:  44%|████▍     | 8/18 [00:08<00:10,  1.06s/it][A
Iteration:  50%|█████     | 9/18 [00:09<00:09,  1.06s/it][A
Iteration:  56%|█████▌    | 10/18 [00:10<00:08,  1.06s/it][A
Iteration:  61%|██████    | 11/18 [00:11<00:07,  1.06s/it][A
Iteration:  67%|██████▋   | 12/18 [00:12<00:06,  1.06s/it][A
Iteration:  72%|███████▏  | 13/18 [00:13<00:05,  1.06s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.06s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.06s/it][A
Iteration:  89%|████████▉ | 16/18 [00:17<00:02,  1.07s/it][A
Iteration:  94%|█████████▍| 17/18 [00:18<00:01,  1.07s/it][A
Iteration: 100%|██████████| 18/18 [00:19<00:00,  1.07s/it][AIteration: 100%|██████████| 18/18 [00:19<00:00,  1.07s/it]
train_loss 2.9454486634996204

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  33%|███▎      | 1/3 [00:00<00:01,  1.11it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.74it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]
Epoch:   1%|          | 1/100 [00:21<34:54, 21.16s/it]eval_score 10.47

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:18,  1.07s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:17,  1.08s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.08s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.07s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:13,  1.07s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:12,  1.08s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:11,  1.08s/it][A
Iteration:  44%|████▍     | 8/18 [00:08<00:10,  1.08s/it][A
Iteration:  50%|█████     | 9/18 [00:09<00:09,  1.08s/it][A
Iteration:  56%|█████▌    | 10/18 [00:10<00:08,  1.08s/it][A
Iteration:  61%|██████    | 11/18 [00:11<00:07,  1.08s/it][A
Iteration:  67%|██████▋   | 12/18 [00:12<00:06,  1.08s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.08s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.08s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.08s/it][A
Iteration:  89%|████████▉ | 16/18 [00:17<00:02,  1.08s/it][A
Iteration:  94%|█████████▍| 17/18 [00:18<00:01,  1.08s/it][A
Iteration: 100%|██████████| 18/18 [00:19<00:00,  1.08s/it][AIteration: 100%|██████████| 18/18 [00:19<00:00,  1.08s/it]
train_loss 2.922598123550415

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.18it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.53it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.63it/s]
Epoch:   2%|▏         | 2/100 [00:42<34:40, 21.23s/it]eval_score 12.4

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:18,  1.08s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:17,  1.08s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.09s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.09s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.09s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.09s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.09s/it][A
Iteration:  44%|████▍     | 8/18 [00:08<00:10,  1.09s/it][A
Iteration:  50%|█████     | 9/18 [00:09<00:09,  1.09s/it][A
Iteration:  56%|█████▌    | 10/18 [00:10<00:08,  1.09s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.09s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.10s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.10s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.10s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.10s/it][A
Iteration:  89%|████████▉ | 16/18 [00:17<00:02,  1.10s/it][A
Iteration:  94%|█████████▍| 17/18 [00:18<00:01,  1.10s/it][A
Iteration: 100%|██████████| 18/18 [00:19<00:00,  1.10s/it][AIteration: 100%|██████████| 18/18 [00:19<00:00,  1.09s/it]
train_loss 2.8762168884277344

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.14it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.51it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.60it/s]
Epoch:   3%|▎         | 3/100 [01:04<34:35, 21.39s/it]eval_score 19.77

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:18,  1.10s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:17,  1.10s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.10s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.11s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.11s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.11s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.11s/it][A
Iteration:  44%|████▍     | 8/18 [00:08<00:11,  1.11s/it][A
Iteration:  50%|█████     | 9/18 [00:09<00:09,  1.11s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:08,  1.11s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.11s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.11s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.11s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.12s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.12s/it][A
Iteration:  89%|████████▉ | 16/18 [00:17<00:02,  1.12s/it][A
Iteration:  94%|█████████▍| 17/18 [00:18<00:01,  1.12s/it][A
Iteration: 100%|██████████| 18/18 [00:19<00:00,  1.11s/it][AIteration: 100%|██████████| 18/18 [00:19<00:00,  1.11s/it]
train_loss 2.775546736187405

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.10it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.48it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]
Epoch:   4%|▍         | 4/100 [01:25<34:34, 21.61s/it]eval_score 41.09

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.12s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:17,  1.12s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.12s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.12s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.12s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.12s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.12s/it][A
Iteration:  44%|████▍     | 8/18 [00:08<00:11,  1.12s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.12s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:08,  1.12s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 2.522527191374037

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.09it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:   5%|▌         | 5/100 [01:48<34:32, 21.82s/it]eval_score 66.67

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.9902112616433039

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.08it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:   6%|▌         | 6/100 [02:10<34:25, 21.97s/it]eval_score 75.58

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.3586463729540508

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.08it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:   7%|▋         | 7/100 [02:32<34:12, 22.07s/it]eval_score 84.88

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 0.8817101054721408

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.08it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:   8%|▊         | 8/100 [02:55<33:58, 22.15s/it]eval_score 88.76

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 0.5880529781182607

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:   9%|▉         | 9/100 [03:17<33:40, 22.20s/it]eval_score 90.31

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 0.41891416741742027

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  10%|█         | 10/100 [03:39<33:21, 22.24s/it]eval_score 91.47

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 0.31776782621939975

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  11%|█         | 11/100 [04:02<33:03, 22.29s/it]eval_score 93.02

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 0.25426072296169067

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  12%|█▏        | 12/100 [04:24<32:45, 22.33s/it]eval_score 94.19

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 0.21347922335068384

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  13%|█▎        | 13/100 [04:46<32:24, 22.35s/it]eval_score 94.96

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 0.18944444093439314

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  14%|█▍        | 14/100 [05:09<32:01, 22.35s/it]eval_score 94.96

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 0.16469427736269104

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  15%|█▌        | 15/100 [05:31<31:38, 22.34s/it]eval_score 95.35

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 0.13993586475650469

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  16%|█▌        | 16/100 [05:53<31:16, 22.33s/it]eval_score 94.57

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 0.12801647517416212

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  17%|█▋        | 17/100 [06:16<30:54, 22.35s/it]eval_score 94.57

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 0.12119259188572566

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  18%|█▊        | 18/100 [06:38<30:33, 22.36s/it]eval_score 94.57

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 0.1046079554491573

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.08it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  19%|█▉        | 19/100 [07:00<30:10, 22.35s/it]eval_score 94.96

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 0.10399061068892479

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  20%|██        | 20/100 [07:23<29:48, 22.36s/it]eval_score 94.96

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:18,  1.22s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:16,  1.18s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:15,  1.17s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.16s/it][A
Iteration:  39%|███▉      | 7/18 [00:08<00:12,  1.15s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:16<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 0.09518347018294865

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  21%|██        | 21/100 [07:45<29:30, 22.41s/it]eval_score 95.35

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 0.08218998130824831

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  22%|██▏       | 22/100 [08:08<29:07, 22.40s/it]eval_score 94.57

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 0.07858889053265254

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  23%|██▎       | 23/100 [08:30<28:44, 22.39s/it]eval_score 94.57

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 0.07581165867547195

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  24%|██▍       | 24/100 [08:53<28:21, 22.39s/it]eval_score 94.19

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 0.0661379707356294

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  24%|██▍       | 24/100 [09:15<29:18, 23.14s/it]
eval_score 94.57
Pre-training finished!
Training begin...
Epoch:   0%|          | 0/100 [00:00<?, ?it/s]
Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:21,  1.28s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:19,  1.19s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.17s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:16,  1.15s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:08<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 8.8773578537835

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.08it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:   1%|          | 1/100 [00:22<37:03, 22.46s/it]eval_score 0.0

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 8.305325852500069

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:   2%|▏         | 2/100 [00:44<36:32, 22.37s/it]eval_score 1.3596

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 7.541363053851658

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.08it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:   3%|▎         | 3/100 [01:07<36:07, 22.35s/it]eval_score 3.6984

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 6.655335532294379

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:   4%|▍         | 4/100 [01:29<35:45, 22.35s/it]eval_score 15.4585

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 5.657767057418823

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:   5%|▌         | 5/100 [01:51<35:23, 22.36s/it]eval_score 31.1644

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 4.719952053493923

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:   6%|▌         | 6/100 [02:14<35:02, 22.36s/it]eval_score 50.5511

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 3.735516177283393

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:   7%|▋         | 7/100 [02:36<34:39, 22.36s/it]eval_score 70.6973

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 2.7980235152774386

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:   8%|▊         | 8/100 [02:58<34:17, 22.36s/it]eval_score 78.7826

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.9550499717394512

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:   9%|▉         | 9/100 [03:21<33:54, 22.36s/it]eval_score 82.4954

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.4653919339179993

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  10%|█         | 10/100 [03:43<33:30, 22.34s/it]eval_score 84.0379

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.2199843790796068

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  11%|█         | 11/100 [04:05<33:07, 22.33s/it]eval_score 85.5706

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 1.1871383885542552

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  12%|█▏        | 12/100 [04:28<32:46, 22.35s/it]eval_score 85.6665

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 1.1728646622763739

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  13%|█▎        | 13/100 [04:50<32:26, 22.37s/it]eval_score 85.6665

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.1776213149229686

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  14%|█▍        | 14/100 [05:13<32:02, 22.36s/it]eval_score 85.9284

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.1892145408524408

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  15%|█▌        | 15/100 [05:35<31:39, 22.34s/it]eval_score 85.9284

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.188319550620185

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.08it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  16%|█▌        | 16/100 [05:57<31:17, 22.35s/it]eval_score 86.0897

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.1565128962198894

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  17%|█▋        | 17/100 [06:20<30:54, 22.34s/it]eval_score 86.0897

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.1663870016733806

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  18%|█▊        | 18/100 [06:42<30:30, 22.33s/it]eval_score 85.8002

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.175427238146464

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.08it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  19%|█▉        | 19/100 [07:04<30:08, 22.33s/it]eval_score 85.8278

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.175314360194736

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  20%|██        | 20/100 [07:27<29:47, 22.34s/it]eval_score 85.538

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.1864842375119526

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  21%|██        | 21/100 [07:49<29:24, 22.34s/it]eval_score 85.6665

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.1826360755496554

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  22%|██▏       | 22/100 [08:11<29:03, 22.35s/it]eval_score 85.6665

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 1.1757410963376362

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  23%|██▎       | 23/100 [08:34<28:41, 22.36s/it]eval_score 85.6665

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.1611733900176153

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  24%|██▍       | 24/100 [08:56<28:19, 22.36s/it]eval_score 86.0897

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.158062520954344

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.08it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  25%|██▌       | 25/100 [09:18<27:56, 22.36s/it]eval_score 85.8278

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:16,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:16<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.1941300365659926

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  26%|██▌       | 26/100 [09:41<27:32, 22.33s/it]eval_score 85.5383

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.1684626539548237

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.08it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  27%|██▋       | 27/100 [10:03<27:10, 22.33s/it]eval_score 85.5383

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.168690820535024

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  28%|██▊       | 28/100 [10:25<26:48, 22.33s/it]eval_score 85.8002

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.1848127841949463

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.47it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]
Epoch:  29%|██▉       | 29/100 [10:48<26:26, 22.34s/it]eval_score 85.649

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 1.1833957036336262

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  30%|███       | 30/100 [11:10<26:05, 22.36s/it]eval_score 85.9284

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.14s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.14s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.14s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.14s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.14s/it]
train_loss 1.1670586201879714

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  31%|███       | 31/100 [11:32<25:43, 22.36s/it]eval_score 85.4096

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.13s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.169861422644721

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.07it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  32%|███▏      | 32/100 [11:55<25:20, 22.37s/it]eval_score 85.6665

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.13s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.13s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.13s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.13s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.13s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.13s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.13s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.13s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.13s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.13s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.13s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.13s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.1565106444888644

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  33%|███▎      | 33/100 [12:17<24:57, 22.36s/it]eval_score 86.0894

Iteration:   0%|          | 0/18 [00:00<?, ?it/s][A
Iteration:   6%|▌         | 1/18 [00:01<00:19,  1.14s/it][A
Iteration:  11%|█         | 2/18 [00:02<00:18,  1.14s/it][A
Iteration:  17%|█▋        | 3/18 [00:03<00:17,  1.14s/it][A
Iteration:  22%|██▏       | 4/18 [00:04<00:15,  1.14s/it][A
Iteration:  28%|██▊       | 5/18 [00:05<00:14,  1.13s/it][A
Iteration:  33%|███▎      | 6/18 [00:06<00:13,  1.13s/it][A
Iteration:  39%|███▉      | 7/18 [00:07<00:12,  1.13s/it][A
Iteration:  44%|████▍     | 8/18 [00:09<00:11,  1.14s/it][A
Iteration:  50%|█████     | 9/18 [00:10<00:10,  1.13s/it][A
Iteration:  56%|█████▌    | 10/18 [00:11<00:09,  1.14s/it][A
Iteration:  61%|██████    | 11/18 [00:12<00:07,  1.14s/it][A
Iteration:  67%|██████▋   | 12/18 [00:13<00:06,  1.14s/it][A
Iteration:  72%|███████▏  | 13/18 [00:14<00:05,  1.14s/it][A
Iteration:  78%|███████▊  | 14/18 [00:15<00:04,  1.14s/it][A
Iteration:  83%|████████▎ | 15/18 [00:17<00:03,  1.14s/it][A
Iteration:  89%|████████▉ | 16/18 [00:18<00:02,  1.14s/it][A
Iteration:  94%|█████████▍| 17/18 [00:19<00:01,  1.14s/it][A
Iteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it][AIteration: 100%|██████████| 18/18 [00:20<00:00,  1.13s/it]
train_loss 1.1717225909233093

Iteration:   0%|          | 0/3 [00:00<?, ?it/s][A
Iteration:  67%|██████▋   | 2/3 [00:00<00:00,  2.06it/s][A
Iteration: 100%|██████████| 3/3 [00:01<00:00,  1.46it/s][AIteration: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]
Epoch:  33%|███▎      | 33/100 [12:39<25:42, 23.03s/it]
eval_score 85.377
Training finished!
Evaluation begin...
Iteration:   0%|          | 0/25 [00:00<?, ?it/s]Iteration:   8%|▊         | 2/25 [00:00<00:11,  2.06it/s]Iteration:  12%|█▏        | 3/25 [00:01<00:15,  1.46it/s]Iteration:  16%|█▌        | 4/25 [00:02<00:16,  1.27it/s]Iteration:  20%|██        | 5/25 [00:03<00:16,  1.18it/s]Iteration:  24%|██▍       | 6/25 [00:04<00:16,  1.13it/s]Iteration:  28%|██▊       | 7/25 [00:05<00:16,  1.10it/s]Iteration:  32%|███▏      | 8/25 [00:06<00:15,  1.08it/s]Iteration:  36%|███▌      | 9/25 [00:07<00:15,  1.07it/s]Iteration:  40%|████      | 10/25 [00:08<00:14,  1.06it/s]Iteration:  44%|████▍     | 11/25 [00:09<00:13,  1.05it/s]Iteration:  48%|████▊     | 12/25 [00:10<00:12,  1.05it/s]Iteration:  52%|█████▏    | 13/25 [00:11<00:11,  1.05it/s]Iteration:  56%|█████▌    | 14/25 [00:12<00:10,  1.04it/s]Iteration:  60%|██████    | 15/25 [00:13<00:09,  1.04it/s]Iteration:  64%|██████▍   | 16/25 [00:14<00:08,  1.04it/s]Iteration:  68%|██████▊   | 17/25 [00:15<00:07,  1.04it/s]Iteration:  72%|███████▏  | 18/25 [00:16<00:06,  1.04it/s]Iteration:  76%|███████▌  | 19/25 [00:17<00:05,  1.04it/s]Iteration:  80%|████████  | 20/25 [00:18<00:04,  1.04it/s]Iteration:  84%|████████▍ | 21/25 [00:19<00:03,  1.04it/s]Iteration:  88%|████████▊ | 22/25 [00:20<00:02,  1.04it/s]Iteration:  92%|█████████▏| 23/25 [00:21<00:01,  1.04it/s]Iteration:  96%|█████████▌| 24/25 [00:22<00:00,  1.04it/s]Iteration: 100%|██████████| 25/25 [00:23<00:00,  1.04it/s]Iteration: 100%|██████████| 25/25 [00:23<00:00,  1.08it/s]
Test results saved to: ./outputs/openset/adb/banking_0.25_0/results/results.csv
      K-f1     N-f1  ...  seed                                               args
0  67.7087  83.1433  ...     0  {"config": "configs/openset/adb.yaml", "output...

[1 rows x 9 columns]
Evaluation finished!
All ADB experiments have been completed.
SUCCESS: Script scripts/openset/adb.sh finished successfully in 1363 seconds.

-----------------------------------------------------
INFO: Starting script: scripts/openset/clap.sh
================================================================
Running CLAP -> Dataset: banking, Seed: 0, Known Ratio: 0.25
================================================================
---> STAGE 1: Finetuning...
Pre-Train Epoch:   0%|          | 0/10 [00:00<?, ?it/s]
Pre-Train Iteration:   0%|          | 0/8 [00:00<?, ?it/s][A/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha = 1) (Triggered internally at /pytorch/torch/csrc/utils/python_arg_parser.cpp:1691.)
  next_m.mul_(beta1).add_(1 - beta1, grad)
Pre-Train Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.20it/s]

Pre-Train Eval Iteration:   0%|          | 0/1 [00:00<?, ?it/s][APre-Train Eval Iteration: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s]
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Pre-Train Epoch:  10%|█         | 1/10 [00:07<01:05,  7.25s/it]
Pre-Train Iteration:   0%|          | 0/8 [00:00<?, ?it/s][APre-Train Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]

Pre-Train Eval Iteration:   0%|          | 0/1 [00:00<?, ?it/s][APre-Train Eval Iteration: 100%|██████████| 1/1 [00:00<00:00, 110.82it/s]
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Pre-Train Epoch:  20%|██        | 2/10 [00:14<00:59,  7.47s/it]
Pre-Train Iteration:   0%|          | 0/8 [00:00<?, ?it/s][APre-Train Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]

Pre-Train Eval Iteration:   0%|          | 0/1 [00:00<?, ?it/s][APre-Train Eval Iteration: 100%|██████████| 1/1 [00:00<00:00, 110.88it/s]
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Pre-Train Epoch:  30%|███       | 3/10 [00:22<00:52,  7.53s/it]
Pre-Train Iteration:   0%|          | 0/8 [00:00<?, ?it/s][APre-Train Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]

Pre-Train Eval Iteration:   0%|          | 0/1 [00:00<?, ?it/s][APre-Train Eval Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.38it/s]
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Pre-Train Epoch:  40%|████      | 4/10 [00:30<00:45,  7.55s/it]
Pre-Train Iteration:   0%|          | 0/8 [00:00<?, ?it/s][APre-Train Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]

Pre-Train Eval Iteration:   0%|          | 0/1 [00:00<?, ?it/s][APre-Train Eval Iteration: 100%|██████████| 1/1 [00:00<00:00, 110.06it/s]
start_time:2025-09-16 19:35:05.746247
args:  Namespace(lang='english', bert_base_model='./pretrained_models/bert-base-uncased', data_dir='./data', dataset='banking', dataset_mode='fixed', known_cls_ratio=0.25, labeled_ratio=0.1, pretrain_model_path='./outputs/openset/clap/banking_0.25_0/finetuned_model', pretrain_loss_type=1, kccl_k=5, neg_num=1, temperature=1.0, KCCL_LOSS_LAMBDA=0.25, CE_LOSS_LAMBDA=0.75, LMCL_LOSS_LAMBDA=1.0, metric_type=1, kccl_euc=0, ks=1.0, km=0.0, s_v=1, m=0, c_m=2, t_a=0.35, neg_margin=0, neg_m=0.35, loss_metric=0, neg_method=0, centroids=1, centroids_norm=0, poolout_norm=0, model_type='1.1', adbes_type='train', le_random=1, optimizer_lr=1, softplus=0, adbes_model_path=None, save_version='0', save_path_suffix='cos', eval_metric='f1', seed=0, seed_data=0, gpu_id='3', max_seq_length=128, feat_dim=768, warmup_proportion=0.1, freeze_bert_parameters=False, num_pretrain_epochs=10.0, num_train_epochs=1, pretrain_lr=2e-05, lr_boundary=0.05, weight_decay=0.0, train_batch_size=32, eval_batch_size=32, wait_patient=10, output_dir='./outputs/openset/clap/banking_0.25_0', fold_idx=0, fold_num=5, config='configs/openset/clap.yaml')
mode: train, len: 229
mode: eval, len: 28
mode: test, len: 3080
2025-09-16 19:35:06.208901  Data and Parameters finished loading!
2025-09-16 19:35:06.208951  Pre-training begin...
{
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.6.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

self.model_type:  1.1
self.num_train_optimization_steps:  70.0
error:  Number of classes, 19, does not match size of target_names, 20. Try specifying the labels parameter
epoch: 0, loss: 3.06107234954834, eval_score_acc: 17.57
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000         2
           1     0.1042    1.0000    0.1887         5
           2     0.3333    0.5000    0.4000         4
           3     0.0000    0.0000    0.0000         8
           4     0.0000    0.0000    0.0000         2
           5     1.0000    1.0000    1.0000         1
           6     0.0000    0.0000    0.0000         6
           7     0.0000    0.0000    0.0000         3
           8     0.0000    0.0000    0.0000         3
           9     0.0000    0.0000    0.0000         1
          10     0.0000    0.0000    0.0000         9
          11     0.0000    0.0000    0.0000         2
          12     0.0000    0.0000    0.0000         1
          13     0.0000    0.0000    0.0000         3
          14     0.4167    1.0000    0.5882         5
          15     0.0000    0.0000    0.0000         5
          16     0.0000    0.0000    0.0000         3
          17     0.0000    0.0000    0.0000         4
          18     0.0000    0.0000    0.0000         7

    accuracy                         0.1757        74
   macro avg     0.0976    0.1842    0.1146        74
weighted avg     0.0667    0.1757    0.0876        74

save the best pretrained models, seed: 0, epoch: 0, eval_score_acc: 17.57, save dir: ./outputs/openset/clap/banking_0.25_0/finetuned_model
error:  Number of classes, 19, does not match size of target_names, 20. Try specifying the labels parameter
epoch: 1, loss: 3.0159001648426056, eval_score_acc: 78.38
              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000         1
           1     0.6250    1.0000    0.7692         5
           2     1.0000    1.0000    1.0000         6
           3     0.3846    1.0000    0.5556         5
           4     1.0000    1.0000    1.0000         4
           5     1.0000    1.0000    1.0000         3
           6     1.0000    0.4000    0.5714         5
           7     0.0000    0.0000    0.0000         1
           8     1.0000    1.0000    1.0000         4
           9     1.0000    1.0000    1.0000         6
          10     1.0000    1.0000    1.0000         5
          11     1.0000    1.0000    1.0000         2
          12     0.5000    1.0000    0.6667         2
          13     0.0000    0.0000    0.0000         2
          14     1.0000    1.0000    1.0000         4
          15     0.8571    1.0000    0.9231         6
          16     0.0000    0.0000    0.0000         1
          17     1.0000    1.0000    1.0000         4
          18     0.0000    0.0000    0.0000         8

    accuracy                         0.7838        74
   macro avg     0.6509    0.7053    0.6572        74
weighted avg     0.7323    0.7838    0.7345        74

save the best pretrained models, seed: 0, epoch: 1, eval_score_acc: 78.38, save dir: ./outputs/openset/clap/banking_0.25_0/finetuned_model
error:  Number of classes, 19, does not match size of target_names, 20. Try specifying the labels parameter
epoch: 2, loss: 2.96212375164032, eval_score_acc: 82.43
              precision    recall  f1-score   support

           0     1.0000    1.0000    1.0000         2
           1     1.0000    1.0000    1.0000         7
           2     1.0000    1.0000    1.0000         4
           3     0.4545    1.0000    0.6250         5
           4     1.0000    1.0000    1.0000         2
           5     1.0000    1.0000    1.0000         2
           6     1.0000    0.5000    0.6667         6
           7     0.0000    0.0000    0.0000         3
           8     1.0000    1.0000    1.0000         2
           9     1.0000    1.0000    1.0000         2
          10     1.0000    1.0000    1.0000         8
          11     0.4000    1.0000    0.5714         2
          12     0.6667    1.0000    0.8000         2
          13     0.0000    0.0000    0.0000         1
          14     1.0000    1.0000    1.0000         7
          15     0.6250    1.0000    0.7692         5
          16     1.0000    1.0000    1.0000         2
          17     1.0000    1.0000    1.0000         6
          18     0.0000    0.0000    0.0000         6

    accuracy                         0.8243        74
   macro avg     0.7445    0.8158    0.7596        74
weighted avg     0.7774    0.8243    0.7799        74

save the best pretrained models, seed: 0, epoch: 2, eval_score_acc: 82.43, save dir: ./outputs/openset/clap/banking_0.25_0/finetuned_model
error:  Number of classes, 19, does not match size of target_names, 20. Try specifying the labels parameter
epoch: 3, loss: 2.923531085252762, eval_score_acc: 87.84
              precision    recall  f1-score   support

           0     1.0000    1.0000    1.0000         1
           1     1.0000    1.0000    1.0000         6
           2     1.0000    1.0000    1.0000         7
           3     1.0000    1.0000    1.0000         6
           4     1.0000    1.0000    1.0000         2
           5     1.0000    1.0000    1.0000         3
           6     1.0000    0.5000    0.6667         6
           7     0.0000    0.0000    0.0000         2
           8     1.0000    1.0000    1.0000         2
           9     1.0000    1.0000    1.0000         2
          10     1.0000    1.0000    1.0000         6
          11     0.5000    1.0000    0.6667         2
          12     0.3333    1.0000    0.5000         2
          13     0.0000    0.0000    0.0000         4
          14     1.0000    1.0000    1.0000         5
          15     0.6250    1.0000    0.7692         5
          16     1.0000    1.0000    1.0000         2
          17     1.0000    1.0000    1.0000         7
          18     1.0000    1.0000    1.0000         4

    accuracy                         0.8784        74
   macro avg     0.8136    0.8684    0.8212        74
weighted avg     0.8620    0.8784    0.8538        74

save the best pretrained models, seed: 0, epoch: 3, eval_score_acc: 87.84, save dir: ./outputs/openset/clap/banking_0.25_0/finetuned_model
error:  Number of classes, 19, does not match size of target_names, 20. Try specifying the labels parameter/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Pre-Train Epoch:  50%|█████     | 5/10 [00:37<00:37,  7.56s/it]
Pre-Train Iteration:   0%|          | 0/8 [00:00<?, ?it/s][APre-Train Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]

Pre-Train Eval Iteration:   0%|          | 0/1 [00:00<?, ?it/s][APre-Train Eval Iteration: 100%|██████████| 1/1 [00:00<00:00, 110.73it/s]
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Pre-Train Epoch:  60%|██████    | 6/10 [00:45<00:30,  7.57s/it]
Pre-Train Iteration:   0%|          | 0/8 [00:00<?, ?it/s][APre-Train Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]

Pre-Train Eval Iteration:   0%|          | 0/1 [00:00<?, ?it/s][APre-Train Eval Iteration: 100%|██████████| 1/1 [00:00<00:00, 110.90it/s]
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Pre-Train Epoch:  70%|███████   | 7/10 [00:51<00:21,  7.20s/it]
Pre-Train Iteration:   0%|          | 0/8 [00:00<?, ?it/s][APre-Train Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.26it/s]

Pre-Train Eval Iteration:   0%|          | 0/1 [00:00<?, ?it/s][APre-Train Eval Iteration: 100%|██████████| 1/1 [00:00<00:00, 110.88it/s]
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Pre-Train Epoch:  80%|████████  | 8/10 [00:58<00:13,  6.97s/it]
Pre-Train Iteration:   0%|          | 0/8 [00:00<?, ?it/s][ATraining beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
Pre-Train Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.25it/s]

Pre-Train Eval Iteration:   0%|          | 0/1 [00:00<?, ?it/s][APre-Train Eval Iteration: 100%|██████████| 1/1 [00:00<00:00, 110.22it/s]
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Pre-Train Epoch:  90%|█████████ | 9/10 [01:04<00:06,  6.81s/it]
Pre-Train Iteration:   0%|          | 0/8 [00:00<?, ?it/s][ATraining beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
Pre-Train Iteration: 100%|██████████| 8/8 [00:06<00:00,  1.25it/s]

Pre-Train Eval Iteration:   0%|          | 0/1 [00:00<?, ?it/s][APre-Train Eval Iteration: 100%|██████████| 1/1 [00:00<00:00, 111.61it/s]
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
Pre-Train Epoch: 100%|██████████| 10/10 [01:11<00:00,  6.71s/it]Pre-Train Epoch: 100%|██████████| 10/10 [01:11<00:00,  7.11s/it]
2025-09-16 19:35:05.746251  Data and Parameters Initialization...
---> STAGE 2: Boundary Adjustment...
/ssd/lijinpeng/code/bolt/code/openset/baselines/CLAP/boundary_adjustment/util.py:177: SyntaxWarning: invalid escape sequence '\D'
  plt.ylabel('Decision Boundary $\Delta$', fontsize=12)
Loading finetuned model...
Training boundary...
Epoch:   0%|          | 0/100 [00:00<?, ?it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:   1%|          | 1/100 [00:00<01:38,  1.01it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:   2%|▏         | 2/100 [00:01<01:31,  1.08it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:   3%|▎         | 3/100 [00:02<01:28,  1.10it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:   4%|▍         | 4/100 [00:03<01:26,  1.11it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:   5%|▌         | 5/100 [00:04<01:24,  1.12it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:   6%|▌         | 6/100 [00:05<01:23,  1.12it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:   7%|▋         | 7/100 [00:06<01:22,  1.12it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:   8%|▊         | 8/100 [00:07<01:21,  1.12it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:   9%|▉         | 9/100 [00:08<01:20,  1.12it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:  10%|█         | 10/100 [00:08<01:20,  1.12it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:  11%|█         | 11/100 [00:09<01:19,  1.12it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:  12%|█▏        | 12/100 [00:10<01:18,  1.12it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:  13%|█▎        | 13/100 [00:11<01:17,  1.12it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:  14%|█▍        | 14/100 [00:12<01:16,  1.12it/s]/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_true = type_of_target(y_true, input_name="y_true")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  type_pred = type_of_target(y_pred, input_name="y_pred")
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.
  ys_types = set(type_of_target(x) for x in ys)
Epoch:  14%|█▍        | 14/100 [00:13<01:22,  1.04it/s]
Epoch 1, Train Loss: 0.5720358341932297
Eval F1-score: 79.6491
Epoch 2, Train Loss: 0.4877573028206825
Eval F1-score: 79.6491
Epoch 3, Train Loss: 0.4149153381586075
Eval F1-score: 79.6491
Epoch 4, Train Loss: 0.35148022323846817
Eval F1-score: 79.6491
Epoch 5, Train Loss: 0.2970222011208534
Eval F1-score: 79.6491
Epoch 6, Train Loss: 0.24393972009420395
Eval F1-score: 77.3333
Epoch 7, Train Loss: 0.2054358534514904
Eval F1-score: 78.3333
Epoch 8, Train Loss: 0.16741081327199936
Eval F1-score: 78.3333
Epoch 9, Train Loss: 0.13662122562527657
Eval F1-score: 76.6667
Epoch 10, Train Loss: 0.11252558045089245
Eval F1-score: 76.6667
Epoch 11, Train Loss: 0.09040680900216103
Eval F1-score: 71.6667
Epoch 12, Train Loss: 0.07270731218159199
Eval F1-score: 70.0
Epoch 13, Train Loss: 0.05662786867469549
Eval F1-score: 66.6667
Epoch 14, Train Loss: 0.04544112645089626
Eval F1-score: 61.6667
Epoch 15, Train Loss: 0.03651329409331083
Eval F1-score: 61.6667
Evaluating...
Saving results...

Results have been saved to: ./outputs/openset/clap/banking_0.25_0/metrics/results.csv
Appended new result row:
   dataset  seed  ...  N-F1                                               args
0  banking     0  ...   0.0  {"output_dir": "./outputs/openset/clap/banking...

[1 rows x 9 columns]
--- Finished run for banking, seed 0, ratio 0.25 ---
All CLAP experiments have been completed.
SUCCESS: Script scripts/openset/clap.sh finished successfully in 101 seconds.

-----------------------------------------------------
INFO: Starting script: scripts/openset/doc.sh
====================================================
Running DOC -> Dataset: banking, Seed: 0, Known Ratio: 0.25
====================================================
2025-09-16 19:36:44.976395: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-09-16 19:36:45.019874: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-09-16 19:36:45.948121: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.
  warnings.warn(
2025-09-16 19:36:46.740442: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-09-16 19:36:46.793527: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-09-16 19:36:46.795098: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-09-16 19:36:46.801686: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-09-16 19:36:46.803047: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-09-16 19:36:46.804433: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-09-16 19:36:46.932716: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-09-16 19:36:46.932813: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-09-16 19:36:46.934039: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-09-16 19:36:46.935164: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1758051406.936460  180636 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46640 MB memory:  -> device: 0, name: NVIDIA RTX 5880 Ada Generation, pci bus id: 0000:0b:00.0, compute capability: 8.9
Loaded 19 known classes.
Vocabulary size: 99
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ main_input          │ (None, 3000)      │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ embedding           │ (None, 3000, 300) │     30,300 │ main_input[0][0]  │
│ (Embedding)         │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout (Dropout)   │ (None, 3000, 300) │          0 │ embedding[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d (Conv1D)     │ (None, 2998, 150) │    135,150 │ dropout[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1 (Conv1D)   │ (None, 2997, 150) │    180,150 │ dropout[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2 (Conv1D)   │ (None, 2996, 150) │    225,150 │ dropout[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 150)       │          0 │ conv1d[0][0]      │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 150)       │          0 │ conv1d_1[0][0]    │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_max_pooling… │ (None, 150)       │          0 │ conv1d_2[0][0]    │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate         │ (None, 450)       │          0 │ global_max_pooli… │
│ (Concatenate)       │                   │            │ global_max_pooli… │
│                     │                   │            │ global_max_pooli… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 250)       │    112,750 │ concatenate[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1 (Dropout) │ (None, 250)       │          0 │ dense[0][0]       │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 19)        │      4,769 │ dropout_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ main_output         │ (None, 19)        │          0 │ dense_1[0][0]     │
│ (Activation)        │                   │            │                   │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 688,269 (2.63 MB)
 Trainable params: 688,269 (2.63 MB)
 Non-trainable params: 0 (0.00 B)
None
Epoch 1/20
2025-09-16 19:36:49.237498: I external/local_xla/xla/service/service.cc:163] XLA service 0x76fbcc006ce0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-09-16 19:36:49.237559: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA RTX 5880 Ada Generation, Compute Capability 8.9
2025-09-16 19:36:49.275838: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-09-16 19:36:49.480302: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
2025-09-16 19:36:49.609307: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-16 19:36:49.609415: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-16 19:36:49.609427: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-16 19:36:50.478218: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1297', 72 bytes spill stores, 72 bytes spill loads

2025-09-16 19:36:50.498220: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1517', 124 bytes spill stores, 124 bytes spill loads

2025-09-16 19:36:50.508753: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1297', 8 bytes spill stores, 8 bytes spill loads

I0000 00:00:1758051419.289744  180868 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m10s[0m 11s/step - accuracy: 0.0703 - loss: 0.69672025-09-16 19:36:59.705585: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-16 19:36:59.705683: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-16 19:36:59.705693: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-16 19:37:00.007639: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1092', 4 bytes spill stores, 4 bytes spill loads

2025-09-16 19:37:00.021225: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1092', 4 bytes spill stores, 4 bytes spill loads

2025-09-16 19:37:00.175378: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1297', 108 bytes spill stores, 108 bytes spill loads

2025-09-16 19:37:00.231159: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1517', 88 bytes spill stores, 88 bytes spill loads

[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 8s/step - accuracy: 0.0679 - loss: 0.6811  2025-09-16 19:37:07.549930: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-16 19:37:07.765501: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_146', 12 bytes spill stores, 12 bytes spill loads

2025-09-16 19:37:07.844986: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_139', 4 bytes spill stores, 4 bytes spill loads

2025-09-16 19:37:08.044447: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_139', 84 bytes spill stores, 92 bytes spill loads


Epoch 1: val_loss improved from None to 0.59429, saving model to ./outputs/openset/doc/banking_0.25_0/ckpt/model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m21s[0m 10s/step - accuracy: 0.0655 - loss: 0.6655 - val_accuracy: 0.0714 - val_loss: 0.5943
Epoch 2/20
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 119ms/step - accuracy: 0.0938 - loss: 0.5495[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 80ms/step - accuracy: 0.0774 - loss: 0.5269 
Epoch 2: val_loss improved from 0.59429 to 0.39994, saving model to ./outputs/openset/doc/banking_0.25_0/ckpt/model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 187ms/step - accuracy: 0.0611 - loss: 0.5042 - val_accuracy: 0.0714 - val_loss: 0.3999
Epoch 3/20
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 117ms/step - accuracy: 0.0625 - loss: 0.3345[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 76ms/step - accuracy: 0.0640 - loss: 0.3181 
Epoch 3: val_loss improved from 0.39994 to 0.23269, saving model to ./outputs/openset/doc/banking_0.25_0/ckpt/model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 169ms/step - accuracy: 0.0655 - loss: 0.3016 - val_accuracy: 0.0714 - val_loss: 0.2327
Epoch 4/20
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 119ms/step - accuracy: 0.0781 - loss: 0.2371[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 80ms/step - accuracy: 0.0653 - loss: 0.2424 
Epoch 4: val_loss improved from 0.23269 to 0.22730, saving model to ./outputs/openset/doc/banking_0.25_0/ckpt/model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 174ms/step - accuracy: 0.0524 - loss: 0.2477 - val_accuracy: 0.0714 - val_loss: 0.2273
Epoch 5/20
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 122ms/step - accuracy: 0.0156 - loss: 0.2893[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 80ms/step - accuracy: 0.0275 - loss: 0.2896 
Epoch 5: val_loss did not improve from 0.22730
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 145ms/step - accuracy: 0.0393 - loss: 0.2898 - val_accuracy: 0.0714 - val_loss: 0.2319
Epoch 6/20
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 118ms/step - accuracy: 0.0469 - loss: 0.2910[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 80ms/step - accuracy: 0.0540 - loss: 0.2882 
Epoch 6: val_loss improved from 0.22730 to 0.21173, saving model to ./outputs/openset/doc/banking_0.25_0/ckpt/model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 169ms/step - accuracy: 0.0611 - loss: 0.2855 - val_accuracy: 0.0357 - val_loss: 0.2117
Epoch 7/20
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 117ms/step - accuracy: 0.0625 - loss: 0.2520[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 78ms/step - accuracy: 0.0662 - loss: 0.2472 
Epoch 7: val_loss did not improve from 0.21173
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 142ms/step - accuracy: 0.0699 - loss: 0.2424 - val_accuracy: 0.0357 - val_loss: 0.2129
Epoch 8/20
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 115ms/step - accuracy: 0.1016 - loss: 0.2178[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 79ms/step - accuracy: 0.1010 - loss: 0.2196 
Epoch 8: val_loss did not improve from 0.21173
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 145ms/step - accuracy: 0.1004 - loss: 0.2214 - val_accuracy: 0.0357 - val_loss: 0.2485
Epoch 9/20
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 116ms/step - accuracy: 0.0391 - loss: 0.2278[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 77ms/step - accuracy: 0.0479 - loss: 0.2289 
Epoch 9: val_loss did not improve from 0.21173
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 144ms/step - accuracy: 0.0568 - loss: 0.2299 - val_accuracy: 0.1071 - val_loss: 0.2755
Epoch 10/20
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 116ms/step - accuracy: 0.1094 - loss: 0.2377[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 77ms/step - accuracy: 0.1027 - loss: 0.2373 
Epoch 10: val_loss did not improve from 0.21173
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 136ms/step - accuracy: 0.0961 - loss: 0.2368 - val_accuracy: 0.0714 - val_loss: 0.2671
Epoch 11/20
[1m1/2[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 114ms/step - accuracy: 0.0625 - loss: 0.2304[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 79ms/step - accuracy: 0.0575 - loss: 0.2298 
Epoch 11: val_loss did not improve from 0.21173
[1m2/2[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 137ms/step - accuracy: 0.0524 - loss: 0.2291 - val_accuracy: 0.0714 - val_loss: 0.2376
2025-09-16 19:37:12.083654: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-16 19:37:12.357847: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_83', 4 bytes spill stores, 4 bytes spill loads

2025-09-16 19:37:12.555677: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_83', 84 bytes spill stores, 92 bytes spill loads

[1m1/8[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m9s[0m 1s/step[1m8/8[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 121ms/step[1m8/8[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 123ms/step
[1m 1/97[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 20ms/step[1m13/97[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 4ms/step [1m25/97[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m0s[0m 4ms/step[1m37/97[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 4ms/step[1m49/97[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 4ms/step[1m61/97[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 4ms/step[1m73/97[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 4ms/step[1m85/97[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 4ms/step[1m97/97[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 13ms/step[1m97/97[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 13ms/step
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        40
           1       0.00      0.00      0.00        40
           2       0.00      0.00      0.00        40
           3       0.00      0.00      0.00        40
           4       0.00      0.00      0.00        40
           5       0.00      0.00      0.00        40
           6       0.00      0.00      0.00        40
           7       0.00      0.00      0.00        40
           8       0.00      0.00      0.00        40
           9       0.00      0.00      0.00        40
          10       0.00      0.00      0.00        40
          11       0.00      0.00      0.00        40
          12       0.00      0.00      0.00        40
          13       0.00      0.00      0.00        40
          14       0.00      0.00      0.00        40
          15       0.00      0.00      0.00        40
          16       0.00      0.00      0.00        40
          17       0.00      0.00      0.00        40
          18       0.00      0.00      0.00        40
          19       0.75      1.00      0.86      2320

    accuracy                           0.75      3080
   macro avg       0.04      0.05      0.04      3080
weighted avg       0.57      0.75      0.65      3080


Results have been saved to: ./outputs/openset/doc/banking_0.25_0/metrics/results.csv
   dataset  seed  ...      N-F1                                               args
0  banking     0  ...  0.859259  {"config": "configs/openset/doc.yaml", "seed":...

[1 rows x 8 columns]
All DOC experiments have been completed.
SUCCESS: Script scripts/openset/doc.sh finished successfully in 32 seconds.

-----------------------------------------------------
INFO: Starting script: scripts/openset/dyen.sh
scripts/openset/dyen.sh: 9: Bad substitution
====================================================
Running DyEn -> Dataset: banking, Seed: 0, Known Ratio: 0.25
====================================================
2025-09-16 19:37:20.964180: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-09-16 19:37:21.006723: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-09-16 19:37:22.004961: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
09/16/2025 19:37:23 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 4distributed training: True, 16-bits training: False
09/16/2025 19:37:23 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(
_n_gpu=4,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.NO,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./outputs/openset/dyen/banking_0.25_0/runs/Sep16_19-37-22_cnic,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./outputs/openset/dyen/banking_0.25_0,
overwrite_output_dir=True,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['tensorboard', 'wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.STEPS,
save_total_limit=None,
seed=0,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[INFO|configuration_utils.py:763] 2025-09-16 19:37:24,013 >> loading configuration file ./pretrained_models/bert-base-uncased/config.json
[INFO|configuration_utils.py:839] 2025-09-16 19:37:24,013 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.56.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|tokenization_utils_base.py:2066] 2025-09-16 19:37:24,013 >> loading file vocab.txt
[INFO|tokenization_utils_base.py:2066] 2025-09-16 19:37:24,013 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2066] 2025-09-16 19:37:24,014 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2066] 2025-09-16 19:37:24,014 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2066] 2025-09-16 19:37:24,014 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2066] 2025-09-16 19:37:24,014 >> loading file chat_template.jinja
[INFO|configuration_utils.py:763] 2025-09-16 19:37:24,014 >> loading configuration file ./pretrained_models/bert-base-uncased/config.json
[INFO|configuration_utils.py:839] 2025-09-16 19:37:24,014 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.56.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

Map:   0%|          | 0/2303 [00:00<?, ? examples/s]Map: 100%|██████████| 2303/2303 [00:00<00:00, 17140.54 examples/s]Map: 100%|██████████| 2303/2303 [00:00<00:00, 16818.40 examples/s]
Map:   0%|          | 0/258 [00:00<?, ? examples/s]Map: 100%|██████████| 258/258 [00:00<00:00, 15340.23 examples/s]
Map:   0%|          | 0/742 [00:00<?, ? examples/s]Map: 100%|██████████| 742/742 [00:00<00:00, 19703.04 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 19473.79 examples/s]
Map:   0%|          | 0/3080 [00:00<?, ? examples/s]Map: 100%|██████████| 3080/3080 [00:00<00:00, 21524.66 examples/s]Map: 100%|██████████| 3080/3080 [00:00<00:00, 21035.07 examples/s]
[INFO|configuration_utils.py:763] 2025-09-16 19:37:24,449 >> loading configuration file ./pretrained_models/bert-base-uncased/config.json
[INFO|configuration_utils.py:839] 2025-09-16 19:37:24,449 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.56.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|modeling_utils.py:1277] 2025-09-16 19:37:24,450 >> loading weights file ./pretrained_models/bert-base-uncased/model.safetensors
[INFO|logging.py:343] 2025-09-16 19:37:24,461 >> A pretrained model of type `BertModel` contains parameters that have been renamed internally (a few are listed below but more are present in the model):
* `bert.encoder.layer.9.output.LayerNorm.beta` -> `encoder.layer.9.output.LayerNorm.bias`
* `bert.encoder.layer.9.output.LayerNorm.gamma` -> `encoder.layer.9.output.LayerNorm.weight`
If you are using a model from the Hub, consider submitting a PR to adjust these weights and help future users.
[INFO|modeling_utils.py:5711] 2025-09-16 19:37:24,484 >> Some weights of the model checkpoint at ./pretrained_models/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.beta', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO|modeling_utils.py:5729] 2025-09-16 19:37:24,484 >> All the weights of BertModel were initialized from the model checkpoint at ./pretrained_models/bert-base-uncased.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.
/ssd/lijinpeng/code/bolt/code/openset/baselines/DyEn/my_trainer.py:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SimpleTrainer.__init__`. Use `processing_class` instead.
  super().__init__(**kwargs)
[2025-09-16 19:37:24,679] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
nvcc warning : incompatible redefinition for option 'compiler-bindir', the last value of this option was used
nvcc warning : incompatible redefinition for option 'compiler-bindir', the last value of this option was used
nvcc warning : incompatible redefinition for option 'compiler-bindir', the last value of this option was used
nvcc warning : incompatible redefinition for option 'compiler-bindir', the last value of this option was used
nvcc warning : incompatible redefinition for option 'compiler-bindir', the last value of this option was used
nvcc warning : incompatible redefinition for option 'compiler-bindir', the last value of this option was used
nvcc warning : incompatible redefinition for option 'compiler-bindir', the last value of this option was used
[2025-09-16 19:37:25,867] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
Epoch: [001]: Loss 32.1940 | F1 0.0846 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:07  +  0:00:00
Epoch: [002]: Loss 30.9602 | F1 0.2720 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:06  +  0:00:00
Epoch: [003]: Loss 28.2140 | F1 0.4939 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:06  +  0:00:00
Epoch: [004]: Loss 24.5065 | F1 0.5843 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:06  +  0:00:00
Epoch: [005]: Loss 21.1769 | F1 0.6441 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:06  +  0:00:00
Epoch: [006]: Loss 18.5876 | F1 0.6828 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:06  +  0:00:00
Epoch: [007]: Loss 16.8196 | F1 0.7129 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:06  +  0:00:00
Epoch: [008]: Loss 15.6135 | F1 0.7309 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:06  +  0:00:00
Epoch: [009]: Loss 14.8784 | F1 0.7419 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:06  +  0:00:00
Epoch: [010]: Loss 14.5357 | F1 0.7416 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:06  +  0:00:00

---> Running Evaluation for method: knn
test_Evaluator - 018/018 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:02  +  0:00:00
test_Evaluator - 025/025 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:03  +  0:00:00
test_Evaluator - 003/003 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00  +  0:00:00
Traceback (most recent call last):
  File "/ssd/lijinpeng/code/bolt/code/openset/baselines/DyEn/run_main.py", line 317, in <module>
    main()
  File "/ssd/lijinpeng/code/bolt/code/openset/baselines/DyEn/run_main.py", line 296, in main
    final_results['args'] = json.dumps(vars(training_args), ensure_ascii=False)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/json/encoder.py", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/json/encoder.py", line 258, in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
  File "/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type AcceleratorConfig is not JSON serializable
FAILURE: Script scripts/openset/dyen.sh failed with exit code 1. Skipping to the next script.

-----------------------------------------------------
INFO: Starting script: scripts/openset/knncon.sh
====================================================
Running KnnCon -> Dataset: banking, Seed: 0, Known Ratio: 0.25
====================================================
2025-09-16 19:38:55.080624: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-09-16 19:38:55.125779: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-09-16 19:38:56.132156: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Map:   0%|          | 0/2303 [00:00<?, ? examples/s]Map:  87%|████████▋ | 2000/2303 [00:00<00:00, 15924.70 examples/s]Map: 100%|██████████| 2303/2303 [00:00<00:00, 15318.82 examples/s]
Map:   0%|          | 0/258 [00:00<?, ? examples/s]Map: 100%|██████████| 258/258 [00:00<00:00, 16183.33 examples/s]
Map:   0%|          | 0/742 [00:00<?, ? examples/s]Map: 100%|██████████| 742/742 [00:00<00:00, 20188.60 examples/s]
Map:   0%|          | 0/3080 [00:00<?, ? examples/s]Map:  97%|█████████▋| 3000/3080 [00:00<00:00, 20082.08 examples/s]Map: 100%|██████████| 3080/3080 [00:00<00:00, 19478.12 examples/s]
Iter (sup_loss):   0%|          | 0/144 [00:00<?, ?it/s]Iter (sup_cont_loss=3.463):   0%|          | 0/144 [00:00<?, ?it/s]Iter (sup_cont_loss=3.463):   1%|          | 1/144 [00:00<01:25,  1.68it/s]Iter (sup_cont_loss=3.403):   1%|          | 1/144 [00:00<01:25,  1.68it/s]Iter (sup_cont_loss=3.403):   1%|▏         | 2/144 [00:00<00:45,  3.11it/s]Iter (sup_cont_loss=3.458):   1%|▏         | 2/144 [00:00<00:45,  3.11it/s]Iter (sup_cont_loss=3.458):   2%|▏         | 3/144 [00:00<00:32,  4.27it/s]Iter (sup_cont_loss=3.418):   2%|▏         | 3/144 [00:00<00:32,  4.27it/s]Iter (sup_cont_loss=3.418):   3%|▎         | 4/144 [00:00<00:26,  5.20it/s]Iter (sup_cont_loss=3.434):   3%|▎         | 4/144 [00:01<00:26,  5.20it/s]Iter (sup_cont_loss=3.434):   3%|▎         | 5/144 [00:01<00:23,  5.92it/s]Iter (sup_cont_loss=3.389):   3%|▎         | 5/144 [00:01<00:23,  5.92it/s]Iter (sup_cont_loss=3.389):   4%|▍         | 6/144 [00:01<00:21,  6.48it/s]Iter (sup_cont_loss=3.426):   4%|▍         | 6/144 [00:01<00:21,  6.48it/s]Iter (sup_cont_loss=3.426):   5%|▍         | 7/144 [00:01<00:19,  7.17it/s]Iter (sup_cont_loss=3.392):   5%|▍         | 7/144 [00:01<00:19,  7.17it/s]Iter (sup_cont_loss=3.392):   6%|▌         | 8/144 [00:01<00:18,  7.50it/s]Iter (sup_cont_loss=3.448):   6%|▌         | 8/144 [00:01<00:18,  7.50it/s]Iter (sup_cont_loss=3.448):   6%|▋         | 9/144 [00:01<00:17,  7.82it/s]Iter (sup_cont_loss=3.458):   6%|▋         | 9/144 [00:01<00:17,  7.82it/s]Iter (sup_cont_loss=3.458):   7%|▋         | 10/144 [00:01<00:17,  7.87it/s]Iter (sup_cont_loss=3.420):   7%|▋         | 10/144 [00:01<00:17,  7.87it/s]Iter (sup_cont_loss=3.420):   8%|▊         | 11/144 [00:01<00:16,  7.85it/s]Iter (sup_cont_loss=3.373):   8%|▊         | 11/144 [00:01<00:16,  7.85it/s]Iter (sup_cont_loss=3.373):   8%|▊         | 12/144 [00:01<00:17,  7.71it/s]Iter (sup_cont_loss=3.415):   8%|▊         | 12/144 [00:02<00:17,  7.71it/s]Iter (sup_cont_loss=3.415):   9%|▉         | 13/144 [00:02<00:16,  7.76it/s]Iter (sup_cont_loss=3.482):   9%|▉         | 13/144 [00:02<00:16,  7.76it/s]Iter (sup_cont_loss=3.482):  10%|▉         | 14/144 [00:02<00:16,  8.00it/s]Iter (sup_cont_loss=3.400):  10%|▉         | 14/144 [00:02<00:16,  8.00it/s]Iter (sup_cont_loss=3.400):  10%|█         | 15/144 [00:02<00:16,  7.94it/s]Iter (sup_cont_loss=3.436):  10%|█         | 15/144 [00:02<00:16,  7.94it/s]Iter (sup_cont_loss=3.436):  11%|█         | 16/144 [00:02<00:16,  7.94it/s]Iter (sup_cont_loss=3.372):  11%|█         | 16/144 [00:02<00:16,  7.94it/s]Iter (sup_cont_loss=3.372):  12%|█▏        | 17/144 [00:02<00:15,  7.99it/s]Iter (sup_cont_loss=3.476):  12%|█▏        | 17/144 [00:02<00:15,  7.99it/s]Iter (sup_cont_loss=3.476):  12%|█▎        | 18/144 [00:02<00:15,  8.17it/s]Iter (sup_cont_loss=3.401):  12%|█▎        | 18/144 [00:02<00:15,  8.17it/s]Iter (sup_cont_loss=3.401):  13%|█▎        | 19/144 [00:02<00:15,  8.05it/s]Iter (sup_cont_loss=3.384):  13%|█▎        | 19/144 [00:02<00:15,  8.05it/s]Iter (sup_cont_loss=3.384):  14%|█▍        | 20/144 [00:02<00:15,  8.05it/s]Iter (sup_cont_loss=3.369):  14%|█▍        | 20/144 [00:03<00:15,  8.05it/s]Iter (sup_cont_loss=3.369):  15%|█▍        | 21/144 [00:03<00:15,  7.91it/s]Iter (sup_cont_loss=3.350):  15%|█▍        | 21/144 [00:03<00:15,  7.91it/s]Iter (sup_cont_loss=3.350):  15%|█▌        | 22/144 [00:03<00:15,  7.80it/s]Iter (sup_cont_loss=3.355):  15%|█▌        | 22/144 [00:03<00:15,  7.80it/s]Iter (sup_cont_loss=3.355):  16%|█▌        | 23/144 [00:03<00:15,  7.78it/s]Iter (sup_cont_loss=3.290):  16%|█▌        | 23/144 [00:03<00:15,  7.78it/s]Iter (sup_cont_loss=3.290):  17%|█▋        | 24/144 [00:03<00:15,  7.83it/s]Iter (sup_cont_loss=3.275):  17%|█▋        | 24/144 [00:03<00:15,  7.83it/s]Iter (sup_cont_loss=3.275):  17%|█▋        | 25/144 [00:03<00:15,  7.84it/s]Iter (sup_cont_loss=3.440):  17%|█▋        | 25/144 [00:03<00:15,  7.84it/s]Iter (sup_cont_loss=3.440):  18%|█▊        | 26/144 [00:03<00:15,  7.82it/s]Iter (sup_cont_loss=3.435):  18%|█▊        | 26/144 [00:03<00:15,  7.82it/s]Iter (sup_cont_loss=3.435):  19%|█▉        | 27/144 [00:03<00:14,  7.89it/s]Iter (sup_cont_loss=3.307):  19%|█▉        | 27/144 [00:03<00:14,  7.89it/s]Iter (sup_cont_loss=3.307):  19%|█▉        | 28/144 [00:03<00:14,  8.03it/s]Iter (sup_cont_loss=3.348):  19%|█▉        | 28/144 [00:04<00:14,  8.03it/s]Iter (sup_cont_loss=3.348):  20%|██        | 29/144 [00:04<00:14,  8.21it/s]Iter (sup_cont_loss=3.280):  20%|██        | 29/144 [00:04<00:14,  8.21it/s]Iter (sup_cont_loss=3.280):  21%|██        | 30/144 [00:04<00:13,  8.15it/s]Iter (sup_cont_loss=3.390):  21%|██        | 30/144 [00:04<00:13,  8.15it/s]Iter (sup_cont_loss=3.390):  22%|██▏       | 31/144 [00:04<00:14,  7.95it/s]Iter (sup_cont_loss=3.357):  22%|██▏       | 31/144 [00:04<00:14,  7.95it/s]Iter (sup_cont_loss=3.357):  22%|██▏       | 32/144 [00:04<00:14,  7.82it/s]Iter (sup_cont_loss=3.354):  22%|██▏       | 32/144 [00:04<00:14,  7.82it/s]Iter (sup_cont_loss=3.354):  23%|██▎       | 33/144 [00:04<00:14,  7.80it/s]Iter (sup_cont_loss=3.344):  23%|██▎       | 33/144 [00:04<00:14,  7.80it/s]Iter (sup_cont_loss=3.344):  24%|██▎       | 34/144 [00:04<00:13,  7.88it/s]Iter (sup_cont_loss=3.310):  24%|██▎       | 34/144 [00:04<00:13,  7.88it/s]Iter (sup_cont_loss=3.310):  24%|██▍       | 35/144 [00:04<00:13,  7.91it/s]Iter (sup_cont_loss=3.339):  24%|██▍       | 35/144 [00:04<00:13,  7.91it/s]Iter (sup_cont_loss=3.339):  25%|██▌       | 36/144 [00:04<00:13,  7.88it/s]Iter (sup_cont_loss=3.253):  25%|██▌       | 36/144 [00:05<00:13,  7.88it/s]Iter (sup_cont_loss=3.253):  26%|██▌       | 37/144 [00:05<00:13,  7.84it/s]Iter (sup_cont_loss=3.297):  26%|██▌       | 37/144 [00:05<00:13,  7.84it/s]Iter (sup_cont_loss=3.297):  26%|██▋       | 38/144 [00:05<00:13,  8.02it/s]Iter (sup_cont_loss=3.106):  26%|██▋       | 38/144 [00:05<00:13,  8.02it/s]Iter (sup_cont_loss=3.106):  27%|██▋       | 39/144 [00:05<00:12,  8.20it/s]Iter (sup_cont_loss=3.166):  27%|██▋       | 39/144 [00:05<00:12,  8.20it/s]Iter (sup_cont_loss=3.166):  28%|██▊       | 40/144 [00:05<00:12,  8.15it/s]Iter (sup_cont_loss=3.198):  28%|██▊       | 40/144 [00:05<00:12,  8.15it/s]Iter (sup_cont_loss=3.198):  28%|██▊       | 41/144 [00:05<00:12,  7.96it/s]Iter (sup_cont_loss=3.197):  28%|██▊       | 41/144 [00:05<00:12,  7.96it/s]Iter (sup_cont_loss=3.197):  29%|██▉       | 42/144 [00:05<00:12,  7.85it/s]Iter (sup_cont_loss=3.161):  29%|██▉       | 42/144 [00:05<00:12,  7.85it/s]Iter (sup_cont_loss=3.161):  30%|██▉       | 43/144 [00:05<00:12,  7.83it/s]Iter (sup_cont_loss=3.302):  30%|██▉       | 43/144 [00:05<00:12,  7.83it/s]Iter (sup_cont_loss=3.302):  31%|███       | 44/144 [00:05<00:12,  7.86it/s]Iter (sup_cont_loss=3.091):  31%|███       | 44/144 [00:06<00:12,  7.86it/s]Iter (sup_cont_loss=3.091):  31%|███▏      | 45/144 [00:06<00:12,  7.92it/s]Iter (sup_cont_loss=3.114):  31%|███▏      | 45/144 [00:06<00:12,  7.92it/s]Iter (sup_cont_loss=3.114):  32%|███▏      | 46/144 [00:06<00:12,  7.91it/s]Iter (sup_cont_loss=3.011):  32%|███▏      | 46/144 [00:06<00:12,  7.91it/s]Iter (sup_cont_loss=3.011):  33%|███▎      | 47/144 [00:06<00:12,  7.86it/s]Iter (sup_cont_loss=3.114):  33%|███▎      | 47/144 [00:06<00:12,  7.86it/s]Iter (sup_cont_loss=3.114):  33%|███▎      | 48/144 [00:06<00:11,  8.01it/s]Iter (sup_cont_loss=3.185):  33%|███▎      | 48/144 [00:06<00:11,  8.01it/s]Iter (sup_cont_loss=3.185):  34%|███▍      | 49/144 [00:06<00:11,  8.23it/s]Iter (sup_cont_loss=3.044):  34%|███▍      | 49/144 [00:06<00:11,  8.23it/s]Iter (sup_cont_loss=3.044):  35%|███▍      | 50/144 [00:06<00:11,  8.13it/s]Iter (sup_cont_loss=2.935):  35%|███▍      | 50/144 [00:06<00:11,  8.13it/s]Iter (sup_cont_loss=2.935):  35%|███▌      | 51/144 [00:06<00:11,  8.00it/s]Iter (sup_cont_loss=2.965):  35%|███▌      | 51/144 [00:06<00:11,  8.00it/s]Iter (sup_cont_loss=2.965):  36%|███▌      | 52/144 [00:06<00:11,  7.92it/s]Iter (sup_cont_loss=3.036):  36%|███▌      | 52/144 [00:07<00:11,  7.92it/s]Iter (sup_cont_loss=3.036):  37%|███▋      | 53/144 [00:07<00:11,  7.97it/s]Iter (sup_cont_loss=2.923):  37%|███▋      | 53/144 [00:07<00:11,  7.97it/s]Iter (sup_cont_loss=2.923):  38%|███▊      | 54/144 [00:07<00:11,  7.96it/s]Iter (sup_cont_loss=2.958):  38%|███▊      | 54/144 [00:07<00:11,  7.96it/s]Iter (sup_cont_loss=2.958):  38%|███▊      | 55/144 [00:07<00:11,  7.92it/s]Iter (sup_cont_loss=2.878):  38%|███▊      | 55/144 [00:07<00:11,  7.92it/s]Iter (sup_cont_loss=2.878):  39%|███▉      | 56/144 [00:07<00:11,  7.94it/s]Iter (sup_cont_loss=3.005):  39%|███▉      | 56/144 [00:07<00:11,  7.94it/s]Iter (sup_cont_loss=3.005):  40%|███▉      | 57/144 [00:07<00:10,  8.07it/s]Iter (sup_cont_loss=2.909):  40%|███▉      | 57/144 [00:07<00:10,  8.07it/s]Iter (sup_cont_loss=2.909):  40%|████      | 58/144 [00:07<00:10,  8.24it/s]Iter (sup_cont_loss=2.829):  40%|████      | 58/144 [00:07<00:10,  8.24it/s]Iter (sup_cont_loss=2.829):  41%|████      | 59/144 [00:07<00:10,  8.15it/s]Iter (sup_cont_loss=2.912):  41%|████      | 59/144 [00:07<00:10,  8.15it/s]Iter (sup_cont_loss=2.912):  42%|████▏     | 60/144 [00:07<00:10,  7.94it/s]Iter (sup_cont_loss=2.796):  42%|████▏     | 60/144 [00:08<00:10,  7.94it/s]Iter (sup_cont_loss=2.796):  42%|████▏     | 61/144 [00:08<00:10,  7.82it/s]Iter (sup_cont_loss=2.960):  42%|████▏     | 61/144 [00:08<00:10,  7.82it/s]Iter (sup_cont_loss=2.960):  43%|████▎     | 62/144 [00:08<00:10,  7.79it/s]Iter (sup_cont_loss=2.862):  43%|████▎     | 62/144 [00:08<00:10,  7.79it/s]Iter (sup_cont_loss=2.862):  44%|████▍     | 63/144 [00:08<00:10,  7.86it/s]Iter (sup_cont_loss=2.776):  44%|████▍     | 63/144 [00:08<00:10,  7.86it/s]Iter (sup_cont_loss=2.776):  44%|████▍     | 64/144 [00:08<00:10,  7.88it/s]Iter (sup_cont_loss=2.758):  44%|████▍     | 64/144 [00:08<00:10,  7.88it/s]Iter (sup_cont_loss=2.758):  45%|████▌     | 65/144 [00:08<00:10,  7.86it/s]Iter (sup_cont_loss=2.835):  45%|████▌     | 65/144 [00:08<00:10,  7.86it/s]Iter (sup_cont_loss=2.835):  46%|████▌     | 66/144 [00:08<00:09,  7.89it/s]Iter (sup_cont_loss=2.610):  46%|████▌     | 66/144 [00:08<00:09,  7.89it/s]Iter (sup_cont_loss=2.610):  47%|████▋     | 67/144 [00:08<00:09,  8.01it/s]Iter (sup_cont_loss=2.750):  47%|████▋     | 67/144 [00:08<00:09,  8.01it/s]Iter (sup_cont_loss=2.750):  47%|████▋     | 68/144 [00:08<00:09,  8.21it/s]Iter (sup_cont_loss=2.626):  47%|████▋     | 68/144 [00:09<00:09,  8.21it/s]Iter (sup_cont_loss=2.626):  48%|████▊     | 69/144 [00:09<00:09,  8.16it/s]Iter (sup_cont_loss=2.855):  48%|████▊     | 69/144 [00:09<00:09,  8.16it/s]Iter (sup_cont_loss=2.855):  49%|████▊     | 70/144 [00:09<00:09,  7.98it/s]Iter (sup_cont_loss=2.632):  49%|████▊     | 70/144 [00:09<00:09,  7.98it/s]Iter (sup_cont_loss=2.632):  49%|████▉     | 71/144 [00:09<00:09,  7.94it/s]Iter (sup_cont_loss=2.788):  49%|████▉     | 71/144 [00:09<00:09,  7.94it/s]Iter (sup_cont_loss=2.788):  50%|█████     | 72/144 [00:09<00:08,  8.13it/s]Iter (sup_cont_loss=2.773):  50%|█████     | 72/144 [00:09<00:08,  8.13it/s]Iter (sup_cont_loss=2.773):  51%|█████     | 73/144 [00:09<00:08,  8.12it/s]Iter (sup_cont_loss=2.771):  51%|█████     | 73/144 [00:09<00:08,  8.12it/s]Iter (sup_cont_loss=2.771):  51%|█████▏    | 74/144 [00:09<00:08,  8.08it/s]Iter (sup_cont_loss=2.553):  51%|█████▏    | 74/144 [00:09<00:08,  8.08it/s]Iter (sup_cont_loss=2.553):  52%|█████▏    | 75/144 [00:09<00:08,  8.12it/s]Iter (sup_cont_loss=2.581):  52%|█████▏    | 75/144 [00:09<00:08,  8.12it/s]Iter (sup_cont_loss=2.581):  53%|█████▎    | 76/144 [00:09<00:08,  8.24it/s]Iter (sup_cont_loss=2.551):  53%|█████▎    | 76/144 [00:10<00:08,  8.24it/s]Iter (sup_cont_loss=2.551):  53%|█████▎    | 77/144 [00:10<00:08,  8.13it/s]Iter (sup_cont_loss=2.363):  53%|█████▎    | 77/144 [00:10<00:08,  8.13it/s]Iter (sup_cont_loss=2.363):  54%|█████▍    | 78/144 [00:10<00:08,  8.04it/s]Iter (sup_cont_loss=2.638):  54%|█████▍    | 78/144 [00:10<00:08,  8.04it/s]Iter (sup_cont_loss=2.638):  55%|█████▍    | 79/144 [00:10<00:08,  7.92it/s]Iter (sup_cont_loss=2.602):  55%|█████▍    | 79/144 [00:10<00:08,  7.92it/s]Iter (sup_cont_loss=2.602):  56%|█████▌    | 80/144 [00:10<00:08,  7.92it/s]Iter (sup_cont_loss=2.644):  56%|█████▌    | 80/144 [00:10<00:08,  7.92it/s]Iter (sup_cont_loss=2.644):  56%|█████▋    | 81/144 [00:10<00:07,  8.16it/s]Iter (sup_cont_loss=2.577):  56%|█████▋    | 81/144 [00:10<00:07,  8.16it/s]Iter (sup_cont_loss=2.577):  57%|█████▋    | 82/144 [00:10<00:07,  8.04it/s]Iter (sup_cont_loss=2.505):  57%|█████▋    | 82/144 [00:10<00:07,  8.04it/s]Iter (sup_cont_loss=2.505):  58%|█████▊    | 83/144 [00:10<00:07,  8.03it/s]Iter (sup_cont_loss=2.653):  58%|█████▊    | 83/144 [00:10<00:07,  8.03it/s]Iter (sup_cont_loss=2.653):  58%|█████▊    | 84/144 [00:10<00:07,  8.10it/s]Iter (sup_cont_loss=2.648):  58%|█████▊    | 84/144 [00:11<00:07,  8.10it/s]Iter (sup_cont_loss=2.648):  59%|█████▉    | 85/144 [00:11<00:07,  8.25it/s]Iter (sup_cont_loss=2.507):  59%|█████▉    | 85/144 [00:11<00:07,  8.25it/s]Iter (sup_cont_loss=2.507):  60%|█████▉    | 86/144 [00:11<00:07,  8.15it/s]Iter (sup_cont_loss=2.558):  60%|█████▉    | 86/144 [00:11<00:07,  8.15it/s]Iter (sup_cont_loss=2.558):  60%|██████    | 87/144 [00:11<00:07,  7.99it/s]Iter (sup_cont_loss=2.387):  60%|██████    | 87/144 [00:11<00:07,  7.99it/s]Iter (sup_cont_loss=2.387):  61%|██████    | 88/144 [00:11<00:07,  7.99it/s]Iter (sup_cont_loss=2.207):  61%|██████    | 88/144 [00:11<00:07,  7.99it/s]Iter (sup_cont_loss=2.207):  62%|██████▏   | 89/144 [00:11<00:06,  7.95it/s]Iter (sup_cont_loss=2.592):  62%|██████▏   | 89/144 [00:11<00:06,  7.95it/s]Iter (sup_cont_loss=2.592):  62%|██████▎   | 90/144 [00:11<00:06,  8.26it/s]Iter (sup_cont_loss=2.355):  62%|██████▎   | 90/144 [00:11<00:06,  8.26it/s]Iter (sup_cont_loss=2.355):  63%|██████▎   | 91/144 [00:11<00:06,  8.20it/s]Iter (sup_cont_loss=2.210):  63%|██████▎   | 91/144 [00:11<00:06,  8.20it/s]Iter (sup_cont_loss=2.210):  64%|██████▍   | 92/144 [00:11<00:06,  8.21it/s]Iter (sup_cont_loss=2.313):  64%|██████▍   | 92/144 [00:12<00:06,  8.21it/s]Iter (sup_cont_loss=2.313):  65%|██████▍   | 93/144 [00:12<00:06,  8.32it/s]Iter (sup_cont_loss=2.244):  65%|██████▍   | 93/144 [00:12<00:06,  8.32it/s]Iter (sup_cont_loss=2.244):  65%|██████▌   | 94/144 [00:12<00:06,  8.19it/s]Iter (sup_cont_loss=2.336):  65%|██████▌   | 94/144 [00:12<00:06,  8.19it/s]Iter (sup_cont_loss=2.336):  66%|██████▌   | 95/144 [00:12<00:06,  8.06it/s]Iter (sup_cont_loss=2.369):  66%|██████▌   | 95/144 [00:12<00:06,  8.06it/s]Iter (sup_cont_loss=2.369):  67%|██████▋   | 96/144 [00:12<00:05,  8.04it/s]Iter (sup_cont_loss=2.224):  67%|██████▋   | 96/144 [00:12<00:05,  8.04it/s]Iter (sup_cont_loss=2.224):  67%|██████▋   | 97/144 [00:12<00:05,  8.16it/s]Iter (sup_cont_loss=2.362):  67%|██████▋   | 97/144 [00:12<00:05,  8.16it/s]Iter (sup_cont_loss=2.362):  68%|██████▊   | 98/144 [00:12<00:05,  8.44it/s]Iter (sup_cont_loss=2.311):  68%|██████▊   | 98/144 [00:12<00:05,  8.44it/s]Iter (sup_cont_loss=2.311):  69%|██████▉   | 99/144 [00:12<00:05,  8.22it/s]Iter (sup_cont_loss=2.654):  69%|██████▉   | 99/144 [00:12<00:05,  8.22it/s]Iter (sup_cont_loss=2.654):  69%|██████▉   | 100/144 [00:12<00:05,  8.17it/s]Iter (sup_cont_loss=2.246):  69%|██████▉   | 100/144 [00:13<00:05,  8.17it/s]Iter (sup_cont_loss=2.246):  70%|███████   | 101/144 [00:13<00:05,  8.08it/s]Iter (sup_cont_loss=2.252):  70%|███████   | 101/144 [00:13<00:05,  8.08it/s]Iter (sup_cont_loss=2.252):  71%|███████   | 102/144 [00:13<00:05,  7.98it/s]Iter (sup_cont_loss=2.248):  71%|███████   | 102/144 [00:13<00:05,  7.98it/s]Iter (sup_cont_loss=2.248):  72%|███████▏  | 103/144 [00:13<00:05,  8.00it/s]Iter (sup_cont_loss=2.333):  72%|███████▏  | 103/144 [00:13<00:05,  8.00it/s]Iter (sup_cont_loss=2.333):  72%|███████▏  | 104/144 [00:13<00:05,  7.96it/s]Iter (sup_cont_loss=2.119):  72%|███████▏  | 104/144 [00:13<00:05,  7.96it/s]Iter (sup_cont_loss=2.119):  73%|███████▎  | 105/144 [00:13<00:04,  7.91it/s]Iter (sup_cont_loss=1.906):  73%|███████▎  | 105/144 [00:13<00:04,  7.91it/s]Iter (sup_cont_loss=1.906):  74%|███████▎  | 106/144 [00:13<00:04,  7.95it/s]Iter (sup_cont_loss=2.209):  74%|███████▎  | 106/144 [00:13<00:04,  7.95it/s]Iter (sup_cont_loss=2.209):  74%|███████▍  | 107/144 [00:13<00:04,  7.93it/s]Iter (sup_cont_loss=2.432):  74%|███████▍  | 107/144 [00:13<00:04,  7.93it/s]Iter (sup_cont_loss=2.432):  75%|███████▌  | 108/144 [00:13<00:04,  7.88it/s]Iter (sup_cont_loss=2.120):  75%|███████▌  | 108/144 [00:14<00:04,  7.88it/s]Iter (sup_cont_loss=2.120):  76%|███████▌  | 109/144 [00:14<00:04,  7.93it/s]Iter (sup_cont_loss=2.122):  76%|███████▌  | 109/144 [00:14<00:04,  7.93it/s]Iter (sup_cont_loss=2.122):  76%|███████▋  | 110/144 [00:14<00:04,  8.04it/s]Iter (sup_cont_loss=2.252):  76%|███████▋  | 110/144 [00:14<00:04,  8.04it/s]Iter (sup_cont_loss=2.252):  77%|███████▋  | 111/144 [00:14<00:04,  8.19it/s]Iter (sup_cont_loss=2.298):  77%|███████▋  | 111/144 [00:14<00:04,  8.19it/s]Iter (sup_cont_loss=2.298):  78%|███████▊  | 112/144 [00:14<00:03,  8.13it/s]Iter (sup_cont_loss=2.374):  78%|███████▊  | 112/144 [00:14<00:03,  8.13it/s]Iter (sup_cont_loss=2.374):  78%|███████▊  | 113/144 [00:14<00:03,  7.99it/s]Iter (sup_cont_loss=2.503):  78%|███████▊  | 113/144 [00:14<00:03,  7.99it/s]Iter (sup_cont_loss=2.503):  79%|███████▉  | 114/144 [00:14<00:03,  7.98it/s]Iter (sup_cont_loss=2.053):  79%|███████▉  | 114/144 [00:14<00:03,  7.98it/s]Iter (sup_cont_loss=2.053):  80%|███████▉  | 115/144 [00:14<00:03,  7.96it/s]Iter (sup_cont_loss=2.260):  80%|███████▉  | 115/144 [00:14<00:03,  7.96it/s]Iter (sup_cont_loss=2.260):  81%|████████  | 116/144 [00:14<00:03,  8.26it/s]Iter (sup_cont_loss=2.304):  81%|████████  | 116/144 [00:15<00:03,  8.26it/s]Iter (sup_cont_loss=2.304):  81%|████████▏ | 117/144 [00:15<00:03,  8.20it/s]Iter (sup_cont_loss=2.234):  81%|████████▏ | 117/144 [00:15<00:03,  8.20it/s]Iter (sup_cont_loss=2.234):  82%|████████▏ | 118/144 [00:15<00:03,  8.21it/s]Iter (sup_cont_loss=2.022):  82%|████████▏ | 118/144 [00:15<00:03,  8.21it/s]Iter (sup_cont_loss=2.022):  83%|████████▎ | 119/144 [00:15<00:03,  8.09it/s]Iter (sup_cont_loss=2.106):  83%|████████▎ | 119/144 [00:15<00:03,  8.09it/s]Iter (sup_cont_loss=2.106):  83%|████████▎ | 120/144 [00:15<00:02,  8.02it/s]Iter (sup_cont_loss=2.027):  83%|████████▎ | 120/144 [00:15<00:02,  8.02it/s]Iter (sup_cont_loss=2.027):  84%|████████▍ | 121/144 [00:15<00:02,  8.01it/s]Iter (sup_cont_loss=2.016):  84%|████████▍ | 121/144 [00:15<00:02,  8.01it/s]Iter (sup_cont_loss=2.016):  85%|████████▍ | 122/144 [00:15<00:02,  7.96it/s]Iter (sup_cont_loss=2.170):  85%|████████▍ | 122/144 [00:15<00:02,  7.96it/s]Iter (sup_cont_loss=2.170):  85%|████████▌ | 123/144 [00:15<00:02,  7.92it/s]Iter (sup_cont_loss=1.943):  85%|████████▌ | 123/144 [00:15<00:02,  7.92it/s]Iter (sup_cont_loss=1.943):  86%|████████▌ | 124/144 [00:15<00:02,  7.94it/s]Iter (sup_cont_loss=2.029):  86%|████████▌ | 124/144 [00:16<00:02,  7.94it/s]Iter (sup_cont_loss=2.029):  87%|████████▋ | 125/144 [00:16<00:02,  8.25it/s]Iter (sup_cont_loss=1.951):  87%|████████▋ | 125/144 [00:16<00:02,  8.25it/s]Iter (sup_cont_loss=1.951):  88%|████████▊ | 126/144 [00:16<00:02,  8.15it/s]Iter (sup_cont_loss=2.042):  88%|████████▊ | 126/144 [00:16<00:02,  8.15it/s]Iter (sup_cont_loss=2.042):  88%|████████▊ | 127/144 [00:16<00:02,  8.20it/s]Iter (sup_cont_loss=2.102):  88%|████████▊ | 127/144 [00:16<00:02,  8.20it/s]Iter (sup_cont_loss=2.102):  89%|████████▉ | 128/144 [00:16<00:01,  8.34it/s]Iter (sup_cont_loss=1.885):  89%|████████▉ | 128/144 [00:16<00:01,  8.34it/s]Iter (sup_cont_loss=1.885):  90%|████████▉ | 129/144 [00:16<00:01,  8.25it/s]Iter (sup_cont_loss=2.038):  90%|████████▉ | 129/144 [00:16<00:01,  8.25it/s]Iter (sup_cont_loss=2.038):  90%|█████████ | 130/144 [00:16<00:01,  8.04it/s]Iter (sup_cont_loss=2.052):  90%|█████████ | 130/144 [00:16<00:01,  8.04it/s]Iter (sup_cont_loss=2.052):  91%|█████████ | 131/144 [00:16<00:01,  7.88it/s]Iter (sup_cont_loss=2.157):  91%|█████████ | 131/144 [00:16<00:01,  7.88it/s]Iter (sup_cont_loss=2.157):  92%|█████████▏| 132/144 [00:16<00:01,  7.83it/s]Iter (sup_cont_loss=2.144):  92%|█████████▏| 132/144 [00:17<00:01,  7.83it/s]Iter (sup_cont_loss=2.144):  92%|█████████▏| 133/144 [00:17<00:01,  7.85it/s]Iter (sup_cont_loss=1.971):  92%|█████████▏| 133/144 [00:17<00:01,  7.85it/s]Iter (sup_cont_loss=1.971):  93%|█████████▎| 134/144 [00:17<00:01,  8.20it/s]Iter (sup_cont_loss=2.054):  93%|█████████▎| 134/144 [00:17<00:01,  8.20it/s]Iter (sup_cont_loss=2.054):  94%|█████████▍| 135/144 [00:17<00:01,  8.10it/s]Iter (sup_cont_loss=1.946):  94%|█████████▍| 135/144 [00:17<00:01,  8.10it/s]Iter (sup_cont_loss=1.946):  94%|█████████▍| 136/144 [00:17<00:00,  8.08it/s]Iter (sup_cont_loss=2.062):  94%|█████████▍| 136/144 [00:17<00:00,  8.08it/s]Iter (sup_cont_loss=2.062):  95%|█████████▌| 137/144 [00:17<00:00,  8.02it/s]Iter (sup_cont_loss=2.015):  95%|█████████▌| 137/144 [00:17<00:00,  8.02it/s]Iter (sup_cont_loss=2.015):  96%|█████████▌| 138/144 [00:17<00:00,  7.94it/s]Iter (sup_cont_loss=1.961):  96%|█████████▌| 138/144 [00:17<00:00,  7.94it/s]Iter (sup_cont_loss=1.961):  97%|█████████▋| 139/144 [00:17<00:00,  7.95it/s]Iter (sup_cont_loss=1.957):  97%|█████████▋| 139/144 [00:17<00:00,  7.95it/s]Iter (sup_cont_loss=1.957):  97%|█████████▋| 140/144 [00:17<00:00,  7.93it/s]Iter (sup_cont_loss=2.016):  97%|█████████▋| 140/144 [00:18<00:00,  7.93it/s]Iter (sup_cont_loss=2.016):  98%|█████████▊| 141/144 [00:18<00:00,  7.87it/s]Iter (sup_cont_loss=1.929):  98%|█████████▊| 141/144 [00:18<00:00,  7.87it/s]Iter (sup_cont_loss=1.929):  99%|█████████▊| 142/144 [00:18<00:00,  7.90it/s]Iter (sup_cont_loss=1.728):  99%|█████████▊| 142/144 [00:18<00:00,  7.90it/s]Iter (sup_cont_loss=1.728):  99%|█████████▉| 143/144 [00:18<00:00,  7.87it/s]Iter (sup_cont_loss=2.003):  99%|█████████▉| 143/144 [00:18<00:00,  7.87it/s]Iter (sup_cont_loss=2.003): 100%|██████████| 144/144 [00:18<00:00,  7.99it/s]Iter (sup_cont_loss=2.003): 100%|██████████| 144/144 [00:18<00:00,  7.81it/s]
Epoch: [0]: Loss 2.7147
Iter (sup_loss): 100%|██████████| 144/144 [00:00<?, ?it/s]Iter (sup_cont_loss=1.879): 100%|██████████| 144/144 [00:00<?, ?it/s]Iter (sup_cont_loss=1.879): : 145it [00:00,  7.84it/s]               Iter (sup_cont_loss=1.801): : 145it [00:00,  7.84it/s]Iter (sup_cont_loss=1.801): : 146it [00:00,  7.82it/s]Iter (sup_cont_loss=1.991): : 146it [00:00,  7.82it/s]Iter (sup_cont_loss=1.991): : 147it [00:00,  8.21it/s]Iter (sup_cont_loss=1.884): : 147it [00:00,  8.21it/s]Iter (sup_cont_loss=1.884): : 148it [00:00,  8.05it/s]Iter (sup_cont_loss=2.005): : 148it [00:00,  8.05it/s]Iter (sup_cont_loss=2.005): : 149it [00:00,  8.04it/s]Iter (sup_cont_loss=1.729): : 149it [00:00,  8.04it/s]Iter (sup_cont_loss=1.729): : 150it [00:00,  8.12it/s]Iter (sup_cont_loss=2.057): : 150it [00:00,  8.12it/s]Iter (sup_cont_loss=2.057): : 151it [00:00,  8.26it/s]Iter (sup_cont_loss=1.919): : 151it [00:00,  8.26it/s]Iter (sup_cont_loss=1.919): : 152it [00:00,  8.14it/s]Iter (sup_cont_loss=1.737): : 152it [00:01,  8.14it/s]Iter (sup_cont_loss=1.737): : 153it [00:01,  8.04it/s]Iter (sup_cont_loss=1.726): : 153it [00:01,  8.04it/s]Iter (sup_cont_loss=1.726): : 154it [00:01,  8.03it/s]Iter (sup_cont_loss=1.795): : 154it [00:01,  8.03it/s]Iter (sup_cont_loss=1.795): : 155it [00:01,  8.17it/s]Iter (sup_cont_loss=1.837): : 155it [00:01,  8.17it/s]Iter (sup_cont_loss=1.837): : 156it [00:01,  8.12it/s]Iter (sup_cont_loss=1.914): : 156it [00:01,  8.12it/s]Iter (sup_cont_loss=1.914): : 157it [00:01,  8.04it/s]Iter (sup_cont_loss=1.845): : 157it [00:01,  8.04it/s]Iter (sup_cont_loss=1.845): : 158it [00:01,  7.86it/s]Iter (sup_cont_loss=2.081): : 158it [00:01,  7.86it/s]Iter (sup_cont_loss=2.081): : 159it [00:01,  7.96it/s]Iter (sup_cont_loss=1.822): : 159it [00:01,  7.96it/s]Iter (sup_cont_loss=1.822): : 160it [00:01,  8.12it/s]Iter (sup_cont_loss=1.787): : 160it [00:02,  8.12it/s]Iter (sup_cont_loss=1.787): : 161it [00:02,  8.05it/s]Iter (sup_cont_loss=1.829): : 161it [00:02,  8.05it/s]Iter (sup_cont_loss=1.829): : 162it [00:02,  7.94it/s]Iter (sup_cont_loss=1.652): : 162it [00:02,  7.94it/s]Iter (sup_cont_loss=1.652): : 163it [00:02,  7.84it/s]Iter (sup_cont_loss=1.852): : 163it [00:02,  7.84it/s]Iter (sup_cont_loss=1.852): : 164it [00:02,  7.83it/s]Iter (sup_cont_loss=1.587): : 164it [00:02,  7.83it/s]Iter (sup_cont_loss=1.587): : 165it [00:02,  8.05it/s]Iter (sup_cont_loss=1.641): : 165it [00:02,  8.05it/s]Iter (sup_cont_loss=1.641): : 166it [00:02,  8.02it/s]Iter (sup_cont_loss=1.670): : 166it [00:02,  8.02it/s]Iter (sup_cont_loss=1.670): : 167it [00:02,  8.00it/s]Iter (sup_cont_loss=1.657): : 167it [00:02,  8.00it/s]Iter (sup_cont_loss=1.657): : 168it [00:02,  8.02it/s]Iter (sup_cont_loss=1.802): : 168it [00:03,  8.02it/s]Iter (sup_cont_loss=1.802): : 169it [00:03,  8.15it/s]Iter (sup_cont_loss=1.782): : 169it [00:03,  8.15it/s]Iter (sup_cont_loss=1.782): : 170it [00:03,  8.02it/s]Iter (sup_cont_loss=1.679): : 170it [00:03,  8.02it/s]Iter (sup_cont_loss=1.679): : 171it [00:03,  8.02it/s]Iter (sup_cont_loss=2.001): : 171it [00:03,  8.02it/s]Iter (sup_cont_loss=2.001): : 172it [00:03,  7.96it/s]Iter (sup_cont_loss=1.720): : 172it [00:03,  7.96it/s]Iter (sup_cont_loss=1.720): : 173it [00:03,  8.00it/s]Iter (sup_cont_loss=1.544): : 173it [00:03,  8.00it/s]Iter (sup_cont_loss=1.544): : 174it [00:03,  8.23it/s]Iter (sup_cont_loss=1.681): : 174it [00:03,  8.23it/s]Iter (sup_cont_loss=1.681): : 175it [00:03,  8.11it/s]Iter (sup_cont_loss=1.707): : 175it [00:03,  8.11it/s]Iter (sup_cont_loss=1.707): : 176it [00:03,  8.03it/s]Iter (sup_cont_loss=1.814): : 176it [00:04,  8.03it/s]Iter (sup_cont_loss=1.814): : 177it [00:04,  7.98it/s]Iter (sup_cont_loss=1.671): : 177it [00:04,  7.98it/s]Iter (sup_cont_loss=1.671): : 178it [00:04,  7.90it/s]Iter (sup_cont_loss=1.722): : 178it [00:04,  7.90it/s]Iter (sup_cont_loss=1.722): : 179it [00:04,  8.12it/s]Iter (sup_cont_loss=1.697): : 179it [00:04,  8.12it/s]Iter (sup_cont_loss=1.697): : 180it [00:04,  8.06it/s]Iter (sup_cont_loss=1.626): : 180it [00:04,  8.06it/s]Iter (sup_cont_loss=1.626): : 181it [00:04,  7.91it/s]Iter (sup_cont_loss=1.766): : 181it [00:04,  7.91it/s]Iter (sup_cont_loss=1.766): : 182it [00:04,  7.87it/s]Iter (sup_cont_loss=1.679): : 182it [00:04,  7.87it/s]Iter (sup_cont_loss=1.679): : 183it [00:04,  8.03it/s]Iter (sup_cont_loss=1.654): : 183it [00:04,  8.03it/s]Iter (sup_cont_loss=1.654): : 184it [00:04,  8.02it/s]Iter (sup_cont_loss=1.831): : 184it [00:05,  8.02it/s]Iter (sup_cont_loss=1.831): : 185it [00:05,  7.95it/s]Iter (sup_cont_loss=1.714): : 185it [00:05,  7.95it/s]Iter (sup_cont_loss=1.714): : 186it [00:05,  7.92it/s]Iter (sup_cont_loss=1.643): : 186it [00:05,  7.92it/s]Iter (sup_cont_loss=1.643): : 187it [00:05,  8.05it/s]Iter (sup_cont_loss=1.865): : 187it [00:05,  8.05it/s]Iter (sup_cont_loss=1.865): : 188it [00:05,  8.21it/s]Iter (sup_cont_loss=1.740): : 188it [00:05,  8.21it/s]Iter (sup_cont_loss=1.740): : 189it [00:05,  8.15it/s]Iter (sup_cont_loss=1.561): : 189it [00:05,  8.15it/s]Iter (sup_cont_loss=1.561): : 190it [00:05,  7.96it/s]Iter (sup_cont_loss=1.687): : 190it [00:05,  7.96it/s]Iter (sup_cont_loss=1.687): : 191it [00:05,  7.90it/s]Iter (sup_cont_loss=1.674): : 191it [00:05,  7.90it/s]Iter (sup_cont_loss=1.674): : 192it [00:05,  8.04it/s]Iter (sup_cont_loss=1.613): : 192it [00:06,  8.04it/s]Iter (sup_cont_loss=1.613): : 193it [00:06,  8.00it/s]Iter (sup_cont_loss=1.614): : 193it [00:06,  8.00it/s]Iter (sup_cont_loss=1.614): : 194it [00:06,  7.92it/s]Iter (sup_cont_loss=1.693): : 194it [00:06,  7.92it/s]Iter (sup_cont_loss=1.693): : 195it [00:06,  7.95it/s]Iter (sup_cont_loss=1.584): : 195it [00:06,  7.95it/s]Iter (sup_cont_loss=1.584): : 196it [00:06,  8.03it/s]Iter (sup_cont_loss=1.514): : 196it [00:06,  8.03it/s]Iter (sup_cont_loss=1.514): : 197it [00:06,  8.18it/s]Iter (sup_cont_loss=1.584): : 197it [00:06,  8.18it/s]Iter (sup_cont_loss=1.584): : 198it [00:06,  8.08it/s]Iter (sup_cont_loss=1.577): : 198it [00:06,  8.08it/s]Iter (sup_cont_loss=1.577): : 199it [00:06,  7.95it/s]Iter (sup_cont_loss=1.656): : 199it [00:06,  7.95it/s]Iter (sup_cont_loss=1.656): : 200it [00:06,  7.98it/s]Iter (sup_cont_loss=1.610): : 200it [00:07,  7.98it/s]Iter (sup_cont_loss=1.610): : 201it [00:07,  7.94it/s]Iter (sup_cont_loss=1.472): : 201it [00:07,  7.94it/s]Iter (sup_cont_loss=1.472): : 202it [00:07,  8.21it/s]Iter (sup_cont_loss=1.661): : 202it [00:07,  8.21it/s]Iter (sup_cont_loss=1.661): : 203it [00:07,  8.10it/s]Iter (sup_cont_loss=1.558): : 203it [00:07,  8.10it/s]Iter (sup_cont_loss=1.558): : 204it [00:07,  7.95it/s]Iter (sup_cont_loss=1.473): : 204it [00:07,  7.95it/s]Iter (sup_cont_loss=1.473): : 205it [00:07,  8.04it/s]Iter (sup_cont_loss=1.561): : 205it [00:07,  8.04it/s]Iter (sup_cont_loss=1.561): : 206it [00:07,  8.19it/s]Iter (sup_cont_loss=1.596): : 206it [00:07,  8.19it/s]Iter (sup_cont_loss=1.596): : 207it [00:07,  8.13it/s]Iter (sup_cont_loss=1.596): : 207it [00:07,  8.13it/s]Iter (sup_cont_loss=1.596): : 208it [00:07,  7.98it/s]Iter (sup_cont_loss=1.457): : 208it [00:08,  7.98it/s]Iter (sup_cont_loss=1.457): : 209it [00:08,  7.97it/s]Iter (sup_cont_loss=1.461): : 209it [00:08,  7.97it/s]Iter (sup_cont_loss=1.461): : 210it [00:08,  7.94it/s]Iter (sup_cont_loss=1.457): : 210it [00:08,  7.94it/s]Iter (sup_cont_loss=1.457): : 211it [00:08,  8.25it/s]Iter (sup_cont_loss=1.707): : 211it [00:08,  8.25it/s]Iter (sup_cont_loss=1.707): : 212it [00:08,  8.20it/s]Iter (sup_cont_loss=1.775): : 212it [00:08,  8.20it/s]Iter (sup_cont_loss=1.775): : 213it [00:08,  8.22it/s]Iter (sup_cont_loss=1.506): : 213it [00:08,  8.22it/s]Iter (sup_cont_loss=1.506): : 214it [00:08,  8.33it/s]Iter (sup_cont_loss=1.364): : 214it [00:08,  8.33it/s]Iter (sup_cont_loss=1.364): : 215it [00:08,  8.22it/s]Iter (sup_cont_loss=1.451): : 215it [00:08,  8.22it/s]Iter (sup_cont_loss=1.451): : 216it [00:08,  8.04it/s]Iter (sup_cont_loss=1.561): : 216it [00:09,  8.04it/s]Iter (sup_cont_loss=1.561): : 217it [00:09,  8.02it/s]Iter (sup_cont_loss=1.504): : 217it [00:09,  8.02it/s]Iter (sup_cont_loss=1.504): : 218it [00:09,  7.98it/s]Iter (sup_cont_loss=1.377): : 218it [00:09,  7.98it/s]Iter (sup_cont_loss=1.377): : 219it [00:09,  8.27it/s]Iter (sup_cont_loss=1.742): : 219it [00:09,  8.27it/s]Iter (sup_cont_loss=1.742): : 220it [00:09,  8.20it/s]Iter (sup_cont_loss=1.358): : 220it [00:09,  8.20it/s]Iter (sup_cont_loss=1.358): : 221it [00:09,  8.20it/s]Iter (sup_cont_loss=1.680): : 221it [00:09,  8.20it/s]Iter (sup_cont_loss=1.680): : 222it [00:09,  8.30it/s]Iter (sup_cont_loss=1.499): : 222it [00:09,  8.30it/s]Iter (sup_cont_loss=1.499): : 223it [00:09,  8.16it/s]Iter (sup_cont_loss=1.526): : 223it [00:09,  8.16it/s]Iter (sup_cont_loss=1.526): : 224it [00:09,  8.03it/s]Iter (sup_cont_loss=1.592): : 224it [00:10,  8.03it/s]Iter (sup_cont_loss=1.592): : 225it [00:10,  7.89it/s]Iter (sup_cont_loss=1.450): : 225it [00:10,  7.89it/s]Iter (sup_cont_loss=1.450): : 226it [00:10,  7.83it/s]Iter (sup_cont_loss=1.631): : 226it [00:10,  7.83it/s]Iter (sup_cont_loss=1.631): : 227it [00:10,  7.85it/s]Iter (sup_cont_loss=1.497): : 227it [00:10,  7.85it/s]Iter (sup_cont_loss=1.497): : 228it [00:10,  7.84it/s]Iter (sup_cont_loss=1.548): : 228it [00:10,  7.84it/s]Iter (sup_cont_loss=1.548): : 229it [00:10,  7.88it/s]Iter (sup_cont_loss=1.560): : 229it [00:10,  7.88it/s]Iter (sup_cont_loss=1.560): : 230it [00:10,  7.88it/s]Iter (sup_cont_loss=1.452): : 230it [00:10,  7.88it/s]Iter (sup_cont_loss=1.452): : 231it [00:10,  7.94it/s]Iter (sup_cont_loss=1.474): : 231it [00:10,  7.94it/s]Iter (sup_cont_loss=1.474): : 232it [00:10,  7.89it/s]Iter (sup_cont_loss=1.433): : 232it [00:11,  7.89it/s]Iter (sup_cont_loss=1.433): : 233it [00:11,  8.09it/s]Iter (sup_cont_loss=1.550): : 233it [00:11,  8.09it/s]Iter (sup_cont_loss=1.550): : 234it [00:11,  8.05it/s]Iter (sup_cont_loss=1.531): : 234it [00:11,  8.05it/s]Iter (sup_cont_loss=1.531): : 235it [00:11,  7.87it/s]Iter (sup_cont_loss=1.537): : 235it [00:11,  7.87it/s]Iter (sup_cont_loss=1.537): : 236it [00:11,  7.75it/s]Iter (sup_cont_loss=1.494): : 236it [00:11,  7.75it/s]Iter (sup_cont_loss=1.494): : 237it [00:11,  7.73it/s]Iter (sup_cont_loss=1.502): : 237it [00:11,  7.73it/s]Iter (sup_cont_loss=1.502): : 238it [00:11,  7.78it/s]Iter (sup_cont_loss=1.373): : 238it [00:11,  7.78it/s]Iter (sup_cont_loss=1.373): : 239it [00:11,  7.79it/s]Iter (sup_cont_loss=1.511): : 239it [00:11,  7.79it/s]Iter (sup_cont_loss=1.511): : 240it [00:11,  7.82it/s]Iter (sup_cont_loss=1.366): : 240it [00:12,  7.82it/s]Iter (sup_cont_loss=1.366): : 241it [00:12,  7.84it/s]Iter (sup_cont_loss=1.655): : 241it [00:12,  7.84it/s]Iter (sup_cont_loss=1.655): : 242it [00:12,  7.89it/s]Iter (sup_cont_loss=1.416): : 242it [00:12,  7.89it/s]Iter (sup_cont_loss=1.416): : 243it [00:12,  7.86it/s]Iter (sup_cont_loss=1.515): : 243it [00:12,  7.86it/s]Iter (sup_cont_loss=1.515): : 244it [00:12,  8.06it/s]Iter (sup_cont_loss=1.724): : 244it [00:12,  8.06it/s]Iter (sup_cont_loss=1.724): : 245it [00:12,  8.04it/s]Iter (sup_cont_loss=1.486): : 245it [00:12,  8.04it/s]Iter (sup_cont_loss=1.486): : 246it [00:12,  7.87it/s]Iter (sup_cont_loss=1.465): : 246it [00:12,  7.87it/s]Iter (sup_cont_loss=1.465): : 247it [00:12,  7.72it/s]Iter (sup_cont_loss=1.473): : 247it [00:12,  7.72it/s]Iter (sup_cont_loss=1.473): : 248it [00:12,  7.72it/s]Iter (sup_cont_loss=1.462): : 248it [00:13,  7.72it/s]Iter (sup_cont_loss=1.462): : 249it [00:13,  7.77it/s]Iter (sup_cont_loss=1.382): : 249it [00:13,  7.77it/s]Iter (sup_cont_loss=1.382): : 250it [00:13,  7.76it/s]Iter (sup_cont_loss=1.530): : 250it [00:13,  7.76it/s]Iter (sup_cont_loss=1.530): : 251it [00:13,  7.83it/s]Iter (sup_cont_loss=1.387): : 251it [00:13,  7.83it/s]Iter (sup_cont_loss=1.387): : 252it [00:13,  7.84it/s]Iter (sup_cont_loss=1.422): : 252it [00:13,  7.84it/s]Iter (sup_cont_loss=1.422): : 253it [00:13,  7.77it/s]Iter (sup_cont_loss=1.499): : 253it [00:13,  7.77it/s]Iter (sup_cont_loss=1.499): : 254it [00:13,  7.89it/s]Iter (sup_cont_loss=1.455): : 254it [00:13,  7.89it/s]Iter (sup_cont_loss=1.455): : 255it [00:13,  8.08it/s]Iter (sup_cont_loss=1.348): : 255it [00:13,  8.08it/s]Iter (sup_cont_loss=1.348): : 256it [00:14,  8.03it/s]Iter (sup_cont_loss=1.553): : 256it [00:14,  8.03it/s]Iter (sup_cont_loss=1.553): : 257it [00:14,  7.95it/s]Iter (sup_cont_loss=1.485): : 257it [00:14,  7.95it/s]Iter (sup_cont_loss=1.485): : 258it [00:14,  7.85it/s]Iter (sup_cont_loss=1.402): : 258it [00:14,  7.85it/s]Iter (sup_cont_loss=1.402): : 259it [00:14,  7.80it/s]Iter (sup_cont_loss=1.825): : 259it [00:14,  7.80it/s]Iter (sup_cont_loss=1.825): : 260it [00:14,  7.86it/s]Iter (sup_cont_loss=1.332): : 260it [00:14,  7.86it/s]Iter (sup_cont_loss=1.332): : 261it [00:14,  7.87it/s]Iter (sup_cont_loss=1.490): : 261it [00:14,  7.87it/s]Iter (sup_cont_loss=1.490): : 262it [00:14,  7.83it/s]Iter (sup_cont_loss=1.359): : 262it [00:14,  7.83it/s]Iter (sup_cont_loss=1.359): : 263it [00:14,  7.88it/s]Iter (sup_cont_loss=1.389): : 263it [00:14,  7.88it/s]Iter (sup_cont_loss=1.389): : 264it [00:15,  7.99it/s]Iter (sup_cont_loss=1.569): : 264it [00:15,  7.99it/s]Iter (sup_cont_loss=1.569): : 265it [00:15,  8.15it/s]Iter (sup_cont_loss=1.468): : 265it [00:15,  8.15it/s]Iter (sup_cont_loss=1.468): : 266it [00:15,  8.07it/s]Iter (sup_cont_loss=1.496): : 266it [00:15,  8.07it/s]Iter (sup_cont_loss=1.496): : 267it [00:15,  7.96it/s]Iter (sup_cont_loss=1.509): : 267it [00:15,  7.96it/s]Iter (sup_cont_loss=1.509): : 268it [00:15,  7.84it/s]Iter (sup_cont_loss=1.421): : 268it [00:15,  7.84it/s]Iter (sup_cont_loss=1.421): : 269it [00:15,  7.85it/s]Iter (sup_cont_loss=1.409): : 269it [00:15,  7.85it/s]Iter (sup_cont_loss=1.409): : 270it [00:15,  8.07it/s]Iter (sup_cont_loss=1.423): : 270it [00:15,  8.07it/s]Iter (sup_cont_loss=1.423): : 271it [00:15,  8.00it/s]Iter (sup_cont_loss=1.383): : 271it [00:15,  8.00it/s]Iter (sup_cont_loss=1.383): : 272it [00:16,  7.97it/s]Iter (sup_cont_loss=1.461): : 272it [00:16,  7.97it/s]Iter (sup_cont_loss=1.461): : 273it [00:16,  7.99it/s]Iter (sup_cont_loss=1.356): : 273it [00:16,  7.99it/s]Iter (sup_cont_loss=1.356): : 274it [00:16,  8.14it/s]Iter (sup_cont_loss=1.344): : 274it [00:16,  8.14it/s]Iter (sup_cont_loss=1.344): : 275it [00:16,  8.00it/s]Iter (sup_cont_loss=1.326): : 275it [00:16,  8.00it/s]Iter (sup_cont_loss=1.326): : 276it [00:16,  7.99it/s]Iter (sup_cont_loss=1.446): : 276it [00:16,  7.99it/s]Iter (sup_cont_loss=1.446): : 277it [00:16,  7.94it/s]Iter (sup_cont_loss=1.434): : 277it [00:16,  7.94it/s]Iter (sup_cont_loss=1.434): : 278it [00:16,  7.97it/s]Iter (sup_cont_loss=1.393): : 278it [00:16,  7.97it/s]Iter (sup_cont_loss=1.393): : 279it [00:16,  8.17it/s]Iter (sup_cont_loss=1.483): : 279it [00:16,  8.17it/s]Iter (sup_cont_loss=1.483): : 280it [00:17,  8.06it/s]Iter (sup_cont_loss=1.450): : 280it [00:17,  8.06it/s]Iter (sup_cont_loss=1.450): : 281it [00:17,  8.00it/s]Iter (sup_cont_loss=1.469): : 281it [00:17,  8.00it/s]Iter (sup_cont_loss=1.469): : 282it [00:17,  8.01it/s]Iter (sup_cont_loss=1.471): : 282it [00:17,  8.01it/s]Iter (sup_cont_loss=1.471): : 283it [00:17,  8.16it/s]Iter (sup_cont_loss=1.412): : 283it [00:17,  8.16it/s]Iter (sup_cont_loss=1.412): : 284it [00:17,  8.02it/s]Iter (sup_cont_loss=1.406): : 284it [00:17,  8.02it/s]Iter (sup_cont_loss=1.406): : 285it [00:17,  8.01it/s]Iter (sup_cont_loss=1.346): : 285it [00:17,  8.01it/s]Iter (sup_cont_loss=1.346): : 286it [00:17,  7.95it/s]Iter (sup_cont_loss=1.476): : 286it [00:17,  7.95it/s]Iter (sup_cont_loss=1.476): : 287it [00:17,  8.00it/s]Iter (sup_cont_loss=1.463): : 287it [00:17,  8.00it/s]Iter (sup_cont_loss=1.463): : 288it [00:17,  8.35it/s]Iter (sup_cont_loss=1.463): : 288it [00:17,  8.00it/s]
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/utils.py:49: RuntimeWarning: invalid value encountered in scalar divide
  acc_ood = (correct[-1] / total[-1] * 100).round(2)
Epoch: [1]: Loss 2.1515
in-domain f1:0.9589346631965774
this is lof_cosine
Traceback (most recent call last):
  File "/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/run_main.py", line 564, in <module>
    main()
  File "/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/run_main.py", line 553, in main
    evaler.evaluation(model_path=model_args.model_name_or_path)
  File "/ssd/lijinpeng/code/bolt/code/openset/baselines/KnnCon/evaluate.py", line 672, in evaluation
    final_results['args'] = json.dumps(vars(self.args), ensure_ascii=False)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/json/encoder.py", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/json/encoder.py", line 258, in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
  File "/ssd/lijinpeng/miniconda3/envs/bolt_v2/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type device is not JSON serializable
FAILURE: Script scripts/openset/knncon.sh failed with exit code 1. Skipping to the next script.

-----------------------------------------------------
INFO: Starting script: scripts/openset/scl.sh
====================================================
Running SCL -> Dataset: banking, Seed: 0, Known Ratio: 0.25
====================================================
/ssd/lijinpeng/code/bolt/code/openset/baselines/SCL/train.py:208: SyntaxWarning: invalid escape sequence '\]'
  tokenizer = Tokenizer(num_words=args.max_num_words, oov_token="<UNK>", filters='!"#$%&()*+-/:;<=>@[\]^_`{|}~')
2025-09-16 19:39:47.198705: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-09-16 19:39:47.242205: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-09-16 19:39:48.217091: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-09-16 19:39:52.519158: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-09-16 19:39:52.523751: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-09-16 19:39:52.526220: I external/local_xla/xla/stream_executor/gpu/read_numa_node.cc:68] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node so this will  be massaged to NUMA node zero in some places. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
Loaded 19 known classes.
Train seen : Valid seen : Test seen = 2303 : 258 : 760
GPU memory growth set to True for devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Load pre-trained GloVe embedding...
Iter (loss=X.XXX):   0%|          | 0/287 [00:00<?, ?it/s]/ssd/lijinpeng/code/bolt/code/openset/baselines/SCL/train.py:353: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)
  seq = torch.LongTensor(seq)
Iter (sup_cont_loss=2.234):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=2.234):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=1.958):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=1.354):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=2.316):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=0.494):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=2.024):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=1.958):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=1.055):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=0.211):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=2.430):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=1.479):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=0.172):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=1.595):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=1.312):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=3.075):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=0.997):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=0.186):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=1.247):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=1.940):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=1.048):   0%|          | 1/287 [00:00<02:18,  2.07it/s]Iter (sup_cont_loss=1.048):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=2.498):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=1.986):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=1.216):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=2.001):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=3.457):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=1.752):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=2.342):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=0.901):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=1.399):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=1.937):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=2.129):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=2.798):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=1.159):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=1.931):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=1.504):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=0.257):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=1.163):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=2.140):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=1.065):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=0.163):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=0.216):   7%|▋         | 20/287 [00:00<00:05, 44.86it/s]Iter (sup_cont_loss=0.216):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=0.114):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=0.064):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=1.899):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=3.916):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=1.216):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=1.938):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=2.859):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=3.041):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=3.714):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=1.342):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=1.523):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=2.823):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=1.415):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=2.059):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=1.392):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=2.343):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=1.582):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=2.148):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=1.544):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=1.807):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=2.157):  14%|█▍        | 41/287 [00:00<00:02, 84.37it/s]Iter (sup_cont_loss=2.157):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.367):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=3.153):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.435):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=0.359):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.281):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.085):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.566):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.556):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=0.988):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.043):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=2.716):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.380):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=2.049):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.206):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=0.421):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.121):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.273):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.264):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=2.195):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=1.208):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=2.003):  22%|██▏       | 62/287 [00:00<00:01, 115.13it/s]Iter (sup_cont_loss=2.003):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=0.383):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=1.332):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=2.081):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=3.741):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=0.359):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=1.985):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=1.239):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=0.341):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=3.464):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=1.951):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=1.877):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=2.560):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=1.548):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=2.439):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=1.323):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=1.907):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=0.477):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=3.518):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=0.641):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=0.498):  29%|██▉       | 83/287 [00:00<00:01, 138.79it/s]Iter (sup_cont_loss=0.331):  29%|██▉       | 83/287 [00:01<00:01, 138.79it/s]Iter (sup_cont_loss=0.331):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=2.172):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=0.275):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=1.034):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=1.144):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=1.271):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=2.493):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=0.135):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=2.744):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=0.060):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=0.032):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=6.088):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=3.040):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=1.590):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=3.990):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=3.046):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=2.758):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=1.427):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=1.132):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=0.353):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=2.085):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=1.068):  36%|███▌      | 104/287 [00:01<00:01, 156.27it/s]Iter (sup_cont_loss=1.068):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=1.431):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=2.338):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=0.377):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=1.300):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=1.926):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=1.010):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=1.312):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=3.211):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=1.971):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=1.022):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=1.226):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=0.310):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=2.006):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=2.682):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=0.239):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=0.248):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=1.280):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=1.434):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=2.530):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=1.370):  44%|████▎     | 125/287 [00:01<00:00, 169.33it/s]Iter (sup_cont_loss=1.370):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=3.047):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=1.295):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=1.894):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=1.857):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=1.244):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=0.395):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=0.471):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=0.377):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=2.131):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=3.448):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=2.167):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=0.218):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=1.365):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=2.029):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=2.180):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=2.871):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=1.779):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=1.081):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=1.445):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=0.435):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=2.274):  51%|█████     | 145/287 [00:01<00:00, 177.87it/s]Iter (sup_cont_loss=2.274):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=2.002):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=0.256):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=1.164):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=1.544):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=1.344):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=2.070):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=2.482):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=1.031):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=3.949):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=0.322):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=2.208):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=1.194):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=1.266):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=0.267):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=2.354):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=1.302):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=2.869):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=2.331):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=0.210):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=1.013):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=0.336):  58%|█████▊    | 166/287 [00:01<00:00, 184.80it/s]Iter (sup_cont_loss=0.336):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.494):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.195):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.481):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.124):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=2.800):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=0.869):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=2.322):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.342):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=2.121):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=2.904):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.691):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.850):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.973):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=3.476):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=0.967):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.558):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=2.025):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.400):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.618):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.833):  65%|██████▌   | 187/287 [00:01<00:00, 189.82it/s]Iter (sup_cont_loss=1.833):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=0.454):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=1.044):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=1.183):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=1.187):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=1.237):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=0.105):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=1.479):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=2.472):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=2.078):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=0.143):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=2.185):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=2.983):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=2.633):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=1.715):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=1.829):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=1.638):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=0.433):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=0.458):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=1.285):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=2.408):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=1.152):  72%|███████▏  | 207/287 [00:01<00:00, 192.61it/s]Iter (sup_cont_loss=1.152):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=0.237):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=2.106):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=2.783):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=2.631):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=0.249):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=3.014):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=1.946):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=0.395):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=1.409):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=1.052):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=3.481):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=1.237):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=1.440):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=2.211):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=2.838):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=0.980):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=1.876):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=0.743):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=2.020):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=2.363):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=0.355):  79%|███████▉  | 228/287 [00:01<00:00, 195.15it/s]Iter (sup_cont_loss=0.355):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=2.608):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=0.326):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=2.274):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=0.206):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=1.463):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=2.444):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=2.058):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=1.765):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=3.361):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=2.409):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=0.946):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=2.965):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=2.103):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=1.859):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=1.359):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=1.414):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=2.042):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=1.238):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=0.411):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=0.262):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=2.186):  87%|████████▋ | 249/287 [00:01<00:00, 197.04it/s]Iter (sup_cont_loss=2.186):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=2.230):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=0.308):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=2.014):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=0.973):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=2.888):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=1.499):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=2.287):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=0.943):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=0.306):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=1.364):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=3.555):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=2.008):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=2.448):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=2.322):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=1.645):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=1.696):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=1.780):  94%|█████████▍| 270/287 [00:01<00:00, 198.31it/s]Iter (sup_cont_loss=1.780): 100%|██████████| 287/287 [00:01<00:00, 149.98it/s]
Epoch: [1] :  Loss 1.6335
Iter (loss=X.XXX):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.600):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.314):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.430):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=2.268):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=2.413):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.248):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=2.923):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.442):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.550):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.090):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=2.162):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=2.384):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.963):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.315):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.380):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.953):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.296):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.238):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.238):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=2.839):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=0.168):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=4.033):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=2.514):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=3.925):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=1.135):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=2.092):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=2.332):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=2.144):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=1.405):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=0.936):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=2.380):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=1.134):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=2.126):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=2.861):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=2.965):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=2.120):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=0.951):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=1.274):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=1.310):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=2.421):   6%|▋         | 18/287 [00:00<00:01, 175.05it/s]Iter (sup_cont_loss=2.421):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=1.641):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=0.592):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=1.664):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=2.237):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=1.812):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=0.992):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=0.611):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=1.463):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=1.927):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=2.141):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=0.263):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=0.335):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=1.095):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=1.841):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=0.126):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=1.971):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=1.945):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=0.701):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=2.164):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=0.944):  14%|█▎        | 39/287 [00:00<00:01, 193.33it/s]Iter (sup_cont_loss=0.944):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=1.897):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=1.844):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=0.345):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=2.188):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=2.694):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=1.317):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=2.391):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=0.842):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=2.639):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=1.721):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=3.208):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=1.584):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=1.916):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=2.667):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=1.042):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=2.053):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=1.744):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=1.436):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=1.667):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=0.991):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=1.741):  21%|██        | 59/287 [00:00<00:01, 185.19it/s]Iter (sup_cont_loss=1.741):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=1.301):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=1.266):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=1.114):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=1.328):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=1.703):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=0.944):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=0.941):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=1.045):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=0.353):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=1.644):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=1.405):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=0.167):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=2.542):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=0.250):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=0.795):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=2.148):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=2.280):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=0.194):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=0.774):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=1.959):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=0.707):  28%|██▊       | 80/287 [00:00<00:01, 192.38it/s]Iter (sup_cont_loss=0.707):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=3.822):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=0.907):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=1.972):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=0.117):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=1.681):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=1.469):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=1.311):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=2.734):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=3.384):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=1.763):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=2.196):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=2.095):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=1.743):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=0.308):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=0.996):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=1.924):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=1.396):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=2.010):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=0.371):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=0.717):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=0.767):  35%|███▌      | 101/287 [00:00<00:00, 197.27it/s]Iter (sup_cont_loss=0.767):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=0.667):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=1.156):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=0.815):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=2.625):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=2.404):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=1.127):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=1.134):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=1.602):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=0.221):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=2.671):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=0.855):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=0.696):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=3.612):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=1.798):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=2.506):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=1.141):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=4.235):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=1.017):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=1.238):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=0.283):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=2.046):  43%|████▎     | 122/287 [00:00<00:00, 200.23it/s]Iter (sup_cont_loss=2.046):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=0.841):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=1.352):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=2.194):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=1.097):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=0.293):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=1.366):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=0.213):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=0.272):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=1.034):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=2.143):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=0.103):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=2.095):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=1.723):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=0.236):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=1.595):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=2.004):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=2.277):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=2.399):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=1.716):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=0.711):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=2.825):  50%|████▉     | 143/287 [00:00<00:00, 201.89it/s]Iter (sup_cont_loss=2.825):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=2.064):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=0.956):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=0.268):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=1.124):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=1.429):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=0.462):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=0.208):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=2.344):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=0.779):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=1.197):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=2.838):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=1.319):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=1.723):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=1.554):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=2.387):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=1.089):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=0.251):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=0.367):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=2.314):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=0.780):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=0.650):  57%|█████▋    | 164/287 [00:00<00:00, 203.03it/s]Iter (sup_cont_loss=0.650):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=2.045):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=0.538):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=0.165):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=1.752):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=0.846):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=1.170):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=1.169):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=1.791):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=1.775):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=2.600):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=0.975):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=1.322):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=0.702):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=1.794):  64%|██████▍   | 185/287 [00:00<00:00, 203.83it/s]Iter (sup_cont_loss=1.022):  64%|██████▍   | 185/287 [00:01<00:00, 203.83it/s]Iter (sup_cont_loss=3.250):  64%|██████▍   | 185/287 [00:01<00:00, 203.83it/s]Iter (sup_cont_loss=0.857):  64%|██████▍   | 185/287 [00:01<00:00, 203.83it/s]Iter (sup_cont_loss=1.733):  64%|██████▍   | 185/287 [00:01<00:00, 203.83it/s]Iter (sup_cont_loss=3.501):  64%|██████▍   | 185/287 [00:01<00:00, 203.83it/s]Iter (sup_cont_loss=0.829):  64%|██████▍   | 185/287 [00:01<00:00, 203.83it/s]Iter (sup_cont_loss=0.600):  64%|██████▍   | 185/287 [00:01<00:00, 203.83it/s]Iter (sup_cont_loss=0.600):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=0.235):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=1.707):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=0.915):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=1.871):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=1.167):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=0.250):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=2.085):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=1.446):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=2.077):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=0.968):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=1.095):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=2.470):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=2.481):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=0.744):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=1.238):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=1.098):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=1.382):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=0.206):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=0.346):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=0.326):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=0.212):  72%|███████▏  | 206/287 [00:01<00:00, 204.34it/s]Iter (sup_cont_loss=0.212):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.067):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.796):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=0.823):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=0.249):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.509):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=0.138):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=0.178):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.934):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.673):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=0.111):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=0.154):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=3.510):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=0.065):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=0.104):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.394):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.531):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=0.056):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=3.258):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.274):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=0.956):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.223):  79%|███████▉  | 227/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.223):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=1.482):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=1.900):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=1.356):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=2.103):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=2.791):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=0.166):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=1.550):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=1.433):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=1.578):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=1.540):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=0.865):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=1.301):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=2.398):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=3.869):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=1.740):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=1.029):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=1.530):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=0.819):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=0.629):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=0.883):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=0.434):  86%|████████▋ | 248/287 [00:01<00:00, 205.14it/s]Iter (sup_cont_loss=0.434):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=1.907):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=0.338):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=0.275):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=1.822):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=0.774):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=0.143):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=2.280):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=1.667):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=1.190):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=0.806):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=1.896):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=3.007):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=2.355):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=1.096):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=0.819):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=1.381):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=0.662):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=1.681):  94%|█████████▎| 269/287 [00:01<00:00, 205.43it/s]Iter (sup_cont_loss=1.681): 100%|██████████| 287/287 [00:01<00:00, 200.98it/s]
Epoch: [2] :  Loss 1.4413
Iter (loss=X.XXX):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=2.840):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.091):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.236):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.636):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.871):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.781):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.907):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.044):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.179):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.807):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.832):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=2.937):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.089):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=2.399):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.644):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.915):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.142):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=2.023):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=0.551):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.209):   0%|          | 0/287 [00:00<?, ?it/s]Iter (sup_cont_loss=1.209):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=1.037):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.713):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.873):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.926):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.733):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.784):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.925):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.197):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.825):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.761):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=3.013):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=2.047):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=1.701):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.193):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.803):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.950):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=1.967):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.998):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=1.727):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.274):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.681):   7%|▋         | 20/287 [00:00<00:01, 198.42it/s]Iter (sup_cont_loss=0.681):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=0.890):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=1.840):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=0.514):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=1.269):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=1.731):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=2.732):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=0.876):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=1.831):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=2.398):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=0.188):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=0.199):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=1.542):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=1.996):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=0.280):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=1.982):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=2.276):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=1.499):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=1.239):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=0.663):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=1.191):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=1.620):  14%|█▍        | 41/287 [00:00<00:01, 203.85it/s]Iter (sup_cont_loss=1.620):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=0.798):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=0.843):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=1.659):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=1.045):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=1.013):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=1.465):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=0.940):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=2.109):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=0.367):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=2.314):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=4.279):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=1.087):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=0.534):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=1.291):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=0.938):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=0.658):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=1.578):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=1.430):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=1.328):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=0.118):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=1.897):  22%|██▏       | 62/287 [00:00<00:01, 204.01it/s]Iter (sup_cont_loss=1.897):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.886):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.413):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=0.102):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.557):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.989):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=0.184):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.975):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=0.846):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=0.307):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=2.313):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.244):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.334):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=0.527):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.491):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.468):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.612):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=0.349):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=0.263):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.385):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.578):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.611):  29%|██▉       | 83/287 [00:00<00:00, 205.38it/s]Iter (sup_cont_loss=1.611):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=1.014):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=1.017):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=1.600):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=0.728):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=1.061):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=1.408):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=0.943):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=1.695):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=0.933):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=1.408):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=0.759):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=1.046):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=0.923):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=1.569):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=0.731):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=1.918):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=1.267):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=0.926):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=0.335):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=0.555):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=0.334):  36%|███▌      | 104/287 [00:00<00:00, 199.52it/s]Iter (sup_cont_loss=0.334):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.884):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=1.269):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.536):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=1.848):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.997):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.718):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=1.912):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.300):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.156):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.806):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.757):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.735):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.158):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=1.117):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=1.481):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=1.656):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.160):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.571):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.776):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.798):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.119):  44%|████▎     | 125/287 [00:00<00:00, 201.70it/s]Iter (sup_cont_loss=0.119):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=4.092):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=0.835):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=0.108):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=0.866):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=0.935):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=2.313):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=1.755):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=1.924):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=1.447):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=1.016):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=0.883):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=0.131):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=0.126):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=1.034):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=2.967):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=0.116):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=1.740):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=1.889):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=1.068):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=2.058):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=1.889):  51%|█████     | 146/287 [00:00<00:00, 203.10it/s]Iter (sup_cont_loss=1.889):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=0.513):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=1.071):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=0.132):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=1.152):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=0.378):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=1.117):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=1.874):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=0.198):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=1.879):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=1.731):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=1.840):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=0.908):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=1.212):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=0.920):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=2.186):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=1.639):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=1.008):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=1.117):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=1.120):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=2.110):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=0.768):  58%|█████▊    | 167/287 [00:00<00:00, 204.27it/s]Iter (sup_cont_loss=0.768):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=0.193):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=0.632):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=0.999):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=1.381):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=1.409):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=1.903):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=3.087):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=0.205):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=0.630):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=1.642):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=0.352):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=1.695):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=1.133):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=3.113):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=0.885):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=1.061):  66%|██████▌   | 188/287 [00:00<00:00, 204.74it/s]Iter (sup_cont_loss=2.770):  66%|██████▌   | 188/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.502):  66%|██████▌   | 188/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.580):  66%|██████▌   | 188/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=0.761):  66%|██████▌   | 188/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.279):  66%|██████▌   | 188/287 [00:01<00:00, 204.74it/s]Iter (sup_cont_loss=1.279):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=1.957):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=1.589):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=1.093):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=0.804):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=1.096):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=1.097):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=0.341):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=1.195):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=0.386):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=0.246):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=1.267):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=0.317):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=0.198):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=0.725):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=0.630):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=1.543):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=0.745):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=0.524):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=2.321):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=1.164):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=0.486):  73%|███████▎  | 209/287 [00:01<00:00, 205.36it/s]Iter (sup_cont_loss=0.486):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=1.362):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=0.763):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=2.857):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=1.210):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=1.521):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=1.189):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=4.079):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=1.054):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=0.211):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=0.772):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=2.499):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=0.606):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=0.716):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=2.192):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=1.619):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=1.428):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=1.406):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=0.197):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=1.135):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=1.231):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=1.440):  80%|████████  | 230/287 [00:01<00:00, 205.83it/s]Iter (sup_cont_loss=1.440):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=0.763):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=0.172):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=0.790):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=2.320):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=0.267):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=0.305):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=2.707):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=0.558):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=2.694):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=1.845):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=1.244):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=1.585):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=0.239):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=0.261):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=2.174):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=0.645):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=0.684):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=0.558):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=0.679):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=1.604):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=1.539):  87%|████████▋ | 251/287 [00:01<00:00, 205.74it/s]Iter (sup_cont_loss=1.539):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=0.727):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=2.535):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=2.874):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=0.139):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=1.490):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=0.912):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=1.923):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=1.171):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=1.195):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=0.864):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=0.045):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=1.369):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=1.033):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=1.610):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=0.933):  95%|█████████▍| 272/287 [00:01<00:00, 206.06it/s]Iter (sup_cont_loss=0.933): 100%|██████████| 287/287 [00:01<00:00, 204.54it/s]
Epoch: [3] :  Loss 1.2021
Iter (loss=X.XXX):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=24.274):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=23.708):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=24.292):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=23.167):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=23.486):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=24.651):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=23.461):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=23.033):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=23.610):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=22.095):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=23.651):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=22.827):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=21.254):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=21.844):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=22.508):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=20.975):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=19.468):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=22.958):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=21.174):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=23.354):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=20.502):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=20.728):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=18.674):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=22.131):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=20.093):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=21.758):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=16.806):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=19.673):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=20.369):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=16.463):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=18.057):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=19.286):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=19.001):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=19.001):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=17.621):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=20.217):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=17.826):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=18.983):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=18.300):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=18.525):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=16.743):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=16.743):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=16.952):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=19.395):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=18.443):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=15.967):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=18.951):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=15.312):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=16.357):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=16.585):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=15.755):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=18.119):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=18.932):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=16.181):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=16.959):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=15.168):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=15.128):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=16.472):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=14.897):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=17.396):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=13.679):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=14.858):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=15.738):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=14.501):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=16.637):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=15.041):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=14.446):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=12.300):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=12.674):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=14.621):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=14.499):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=14.785):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=12.527):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=12.625):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=13.827):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=13.333):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=9.777):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s] Iter (ce_loss=14.001):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=15.414):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=11.706):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=8.598):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s] Iter (ce_loss=14.393):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=11.943):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=14.358):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=10.667):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=16.029):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=13.391):  14%|█▍        | 41/287 [00:00<00:00, 404.30it/s]Iter (ce_loss=13.391):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=13.372):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=13.100):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=12.063):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=12.896):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=10.347):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=11.387):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=12.624):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=13.081):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=12.044):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=9.998):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s] Iter (ce_loss=10.945):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=9.986):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s] Iter (ce_loss=8.092):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=11.592):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=9.883):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s] Iter (ce_loss=10.436):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=11.340):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=13.207):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=9.596):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s] Iter (ce_loss=14.751):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=9.654):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s] Iter (ce_loss=7.347):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=10.484):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=9.230):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s] Iter (ce_loss=9.855):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=11.451):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=8.681):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s] Iter (ce_loss=5.970):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=12.074):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=7.190):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s] Iter (ce_loss=10.951):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=7.467):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s] Iter (ce_loss=9.809):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=8.371):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=10.227):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=11.368):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=12.498):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=6.161):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s] Iter (ce_loss=11.369):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=9.386):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s] Iter (ce_loss=9.025):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=4.639):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=8.178):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=9.758):  30%|██▉       | 86/287 [00:00<00:00, 429.97it/s]Iter (ce_loss=9.758):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=9.047):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=9.144):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=12.246):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=8.514):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s] Iter (ce_loss=7.183):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=7.404):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=10.567):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=7.951):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s] Iter (ce_loss=12.874):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=9.568):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s] Iter (ce_loss=8.283):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=9.502):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=6.475):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=8.187):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=8.519):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=6.618):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=7.343):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=10.441):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=7.198):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s] Iter (ce_loss=7.068):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=13.877):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=7.022):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s] Iter (ce_loss=8.556):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=5.466):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=8.309):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=8.666):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=7.913):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=7.546):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=7.779):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=9.760):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=12.033):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=8.346):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s] Iter (ce_loss=5.148):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=9.601):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=4.732):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=6.038):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=10.809):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=7.189):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s] Iter (ce_loss=8.724):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=6.434):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=7.562):  45%|████▌     | 130/287 [00:00<00:00, 406.82it/s]Iter (ce_loss=7.562):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=7.003):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=8.178):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=6.770):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=8.510):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=7.649):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=6.161):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=11.466):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=15.660):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=9.318):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s] Iter (ce_loss=8.065):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=7.332):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=3.907):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=9.079):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=7.137):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=13.004):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=7.314):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s] Iter (ce_loss=10.717):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=6.069):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s] Iter (ce_loss=6.535):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=4.650):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=4.364):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=5.828):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=7.992):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=10.351):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=9.940):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s] Iter (ce_loss=8.154):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=8.079):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=6.079):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=4.524):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=5.923):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=5.072):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=8.264):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=6.354):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=6.388):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=8.734):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=6.347):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=4.888):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=9.093):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=5.695):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=6.173):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=4.561):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=7.261):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=5.477):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=8.386):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=2.592):  60%|█████▉    | 171/287 [00:00<00:00, 407.61it/s]Iter (ce_loss=2.592):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=4.969):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=5.535):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=11.547):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=8.107):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s] Iter (ce_loss=5.647):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=3.542):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=10.932):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=6.065):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s] Iter (ce_loss=7.458):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=4.171):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=7.044):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=12.683):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=5.258):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s] Iter (ce_loss=5.565):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=5.724):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=3.210):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=4.634):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=5.196):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=9.671):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=7.995):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=8.469):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=9.289):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=6.788):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=6.192):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=5.453):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=7.778):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=14.254):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=5.127):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s] Iter (ce_loss=9.020):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=3.480):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=9.986):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=6.011):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=4.581):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=9.234):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=14.040):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=5.666):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s] Iter (ce_loss=5.511):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=9.749):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=7.656):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=7.930):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=7.834):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=6.075):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=4.606):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=14.071):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=7.014):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s] Iter (ce_loss=5.829):  75%|███████▌  | 216/287 [00:00<00:00, 418.97it/s]Iter (ce_loss=5.829):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=5.886):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=9.299):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=4.563):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=4.532):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=4.636):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=4.656):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=5.580):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=6.611):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=5.491):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=6.307):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=7.698):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=9.824):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=8.612):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=4.400):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=4.368):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=6.396):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=8.164):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=4.437):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=8.501):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=3.900):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=11.171):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=3.569):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s] Iter (ce_loss=6.735):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=4.760):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=5.729):  91%|█████████▏| 262/287 [00:00<00:00, 430.87it/s]Iter (ce_loss=5.729): 100%|██████████| 287/287 [00:00<00:00, 424.36it/s]
Epoch: [1] :  Loss 10.9647
Iter (loss=X.XXX):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=7.005):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=8.809):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.286):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.320):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.985):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.679):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=5.668):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.666):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.203):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.080):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.582):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.166):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=5.802):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.958):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.796):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=7.256):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.022):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.984):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=6.227):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=5.641):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.236):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=7.962):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=6.688):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=11.288):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.736):   0%|          | 0/287 [00:00<?, ?it/s] Iter (ce_loss=3.537):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.610):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=5.927):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=5.169):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=7.658):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=7.541):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=8.474):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=5.142):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.064):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=9.825):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.259):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.849):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.020):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.828):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.198):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.198):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=6.789):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=9.717):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=4.983):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=4.078):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=4.607):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=7.043):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=5.404):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=2.982):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=4.329):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=7.698):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=8.648):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=4.490):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=3.970):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=5.661):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=5.346):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=5.020):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=9.191):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=4.264):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=7.492):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=2.908):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=5.908):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=4.053):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=8.571):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=4.920):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=6.965):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=2.950):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=4.221):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=10.124):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=5.130):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s] Iter (ce_loss=6.216):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=6.579):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=6.982):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=5.765):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=5.432):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=9.477):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=3.465):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=5.924):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=8.416):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=7.280):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=4.405):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=12.570):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=2.428):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s] Iter (ce_loss=8.194):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=6.163):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=2.514):  14%|█▍        | 40/287 [00:00<00:00, 399.66it/s]Iter (ce_loss=2.514):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=5.272):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=5.013):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=4.380):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=8.113):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=4.480):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=3.269):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=9.428):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=6.890):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=5.375):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=2.752):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=9.505):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=4.638):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=2.719):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=6.482):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=8.299):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=4.385):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=7.218):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=5.163):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=4.721):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=6.355):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=3.356):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=2.682):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=3.645):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=7.804):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=2.832):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=3.276):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=3.299):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=4.417):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=2.657):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=5.708):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=5.980):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=5.052):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=7.115):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=5.385):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=3.703):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=8.224):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=5.971):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=8.136):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=5.485):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=10.410):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=1.611):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s] Iter (ce_loss=3.712):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=4.393):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=6.969):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=10.110):  30%|██▉       | 85/287 [00:00<00:00, 423.87it/s]Iter (ce_loss=10.110):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=5.142):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s] Iter (ce_loss=1.909):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=3.234):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=6.026):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=3.011):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=1.649):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=4.417):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=2.356):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=3.726):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=6.473):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=4.066):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=10.011):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=6.883):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s] Iter (ce_loss=5.580):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=4.331):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=6.294):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=3.863):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=1.894):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=4.135):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=3.496):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=2.449):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=3.693):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=8.292):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=5.589):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=5.033):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=6.610):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=8.128):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=7.823):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=1.003):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=7.301):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=5.196):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=9.001):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=3.869):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=5.546):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=6.468):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=3.950):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=2.830):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=5.149):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=2.928):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=5.563):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=4.479):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=3.607):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=3.408):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=5.037):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=3.953):  45%|████▌     | 130/287 [00:00<00:00, 434.05it/s]Iter (ce_loss=3.953):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=9.431):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.240):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.338):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.051):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=2.449):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=2.169):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=5.190):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=2.308):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.594):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=4.777):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=4.048):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=4.849):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=4.402):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=7.070):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=1.546):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=5.476):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=4.887):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.344):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=2.574):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=8.750):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=2.511):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=5.382):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=1.585):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=5.872):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=6.933):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=2.536):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=7.482):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.201):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=2.511):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=1.969):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=8.457):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=4.525):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=7.417):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=2.380):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=5.613):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.090):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=2.847):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.913):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=8.040):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=6.113):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.425):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.624):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=6.678):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=1.600):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=5.662):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=2.515):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.310):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=2.800):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.918):  61%|██████    | 175/287 [00:00<00:00, 439.22it/s]Iter (ce_loss=3.918):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=6.529):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.249):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=2.419):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=6.299):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=8.255):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=5.523):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.426):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=1.120):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=4.704):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.354):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=11.867):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.440):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s] Iter (ce_loss=3.246):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.910):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=2.015):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=8.500):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=6.281):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.605):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.134):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=4.139):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=4.368):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.527):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=5.014):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=2.424):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=4.774):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.030):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=8.578):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=2.864):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=1.597):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=4.902):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.021):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=1.749):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=6.279):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=2.447):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=1.399):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=7.713):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=2.628):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.162):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=7.151):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=9.276):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=6.334):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=1.763):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=1.335):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.566):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=2.160):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=2.941):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=2.265):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=2.780):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=6.584):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=2.753):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=3.432):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=4.975):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=2.297):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=5.572):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=6.540):  78%|███████▊  | 224/287 [00:00<00:00, 455.88it/s]Iter (ce_loss=6.540):  97%|█████████▋| 279/287 [00:00<00:00, 486.01it/s]Iter (ce_loss=2.057):  97%|█████████▋| 279/287 [00:00<00:00, 486.01it/s]Iter (ce_loss=6.790):  97%|█████████▋| 279/287 [00:00<00:00, 486.01it/s]Iter (ce_loss=5.740):  97%|█████████▋| 279/287 [00:00<00:00, 486.01it/s]Iter (ce_loss=0.637):  97%|█████████▋| 279/287 [00:00<00:00, 486.01it/s]Iter (ce_loss=2.742):  97%|█████████▋| 279/287 [00:00<00:00, 486.01it/s]Iter (ce_loss=4.669):  97%|█████████▋| 279/287 [00:00<00:00, 486.01it/s]Iter (ce_loss=4.545):  97%|█████████▋| 279/287 [00:00<00:00, 486.01it/s]Iter (ce_loss=2.777):  97%|█████████▋| 279/287 [00:00<00:00, 486.01it/s]Iter (ce_loss=2.777): 100%|██████████| 287/287 [00:00<00:00, 462.56it/s]
Epoch: [2] :  Loss 4.9540
Iter (loss=X.XXX):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.145):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=6.586):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.769):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.529):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=0.598):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.225):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.700):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.176):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=0.728):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.369):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.482):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=0.942):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=6.420):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=5.203):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.135):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.736):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.297):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=7.831):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.694):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=6.576):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.837):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=6.422):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=9.975):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.413):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.252):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.334):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.247):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=5.494):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.049):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.525):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.043):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.155):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.155):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.992):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.718):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=3.561):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=0.976):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.350):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.248):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.407):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.949):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.901):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.440):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.462):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.371):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=6.343):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=2.142):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=4.027):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.551):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.996):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=10.605):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=6.953):   0%|          | 0/287 [00:00<?, ?it/s] Iter (ce_loss=0.723):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.420):   0%|          | 0/287 [00:00<?, ?it/s]Iter (ce_loss=1.420):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=3.318):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=4.569):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=4.018):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=6.094):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=8.020):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.743):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.231):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=0.669):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=8.486):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=4.874):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=4.779):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=7.216):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=5.150):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=4.202):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.653):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.693):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=3.669):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=6.937):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=5.035):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=3.638):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=7.486):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=1.456):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=3.286):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=5.140):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=5.854):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=1.437):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=4.157):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.126):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=3.537):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=0.979):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.642):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.626):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=1.135):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.233):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=1.099):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.545):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=4.090):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=1.519):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=4.503):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=1.478):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=4.375):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=1.290):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=1.451):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.426):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=3.870):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=5.895):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=1.152):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=3.822):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=1.273):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=9.386):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=0.789):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.945):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=6.315):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=3.647):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.996):  19%|█▉        | 54/287 [00:00<00:00, 537.73it/s]Iter (ce_loss=2.996):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=5.251):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.313):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=3.863):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=1.706):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.770):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=9.869):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=0.493):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.096):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=3.833):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=1.739):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=3.677):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=5.068):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.113):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=4.230):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=0.799):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=3.030):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=9.593):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.216):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=3.579):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=1.930):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=3.579):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=4.033):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.349):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=4.805):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.078):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=0.960):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=6.941):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=1.663):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=3.989):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=1.381):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.302):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=5.195):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=6.784):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=11.606):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.280):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s] Iter (ce_loss=2.541):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=1.973):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.053):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=1.705):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=6.811):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=3.239):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.262):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=6.628):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=3.774):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=9.699):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=8.140):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=3.872):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=4.986):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=7.082):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=1.722):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.505):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=2.337):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=3.555):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=3.709):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=6.911):  38%|███▊      | 109/287 [00:00<00:00, 542.07it/s]Iter (ce_loss=6.911):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=5.592):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=7.481):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=5.046):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=4.233):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=7.477):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=7.148):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.482):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=5.153):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.527):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.846):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=5.207):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=1.086):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.564):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.212):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=3.859):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.964):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=3.152):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=0.756):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=0.836):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.327):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.302):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=7.701):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=6.971):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=6.711):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=3.992):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=1.127):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=4.536):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=4.294):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=3.657):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=1.885):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.020):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=4.868):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.998):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=0.671):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=1.570):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=7.085):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=5.763):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=0.912):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=11.142):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=0.749):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s] Iter (ce_loss=2.865):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=1.560):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=5.097):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.558):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=1.478):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=0.868):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=1.940):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=7.252):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=1.183):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.898):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=0.674):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=1.733):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=9.498):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=2.751):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=7.545):  57%|█████▋    | 164/287 [00:00<00:00, 539.48it/s]Iter (ce_loss=7.545):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=5.472):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.087):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.208):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.017):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=0.907):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=1.948):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=3.240):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.443):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=3.159):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=4.687):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=4.388):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=4.679):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=0.722):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.758):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=0.795):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=5.824):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=0.832):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=5.937):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=9.093):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.717):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=3.345):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=1.763):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=3.218):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=5.463):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.996):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=1.130):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=1.217):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.336):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=0.881):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.882):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.964):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=0.941):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=3.048):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=4.031):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.453):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.909):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=3.284):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=4.834):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=4.192):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=4.401):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=1.658):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=4.092):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=6.911):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.223):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=8.576):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=4.826):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=6.958):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=1.569):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=0.461):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=5.735):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=1.599):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=2.687):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=7.440):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=5.575):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=5.720):  76%|███████▋  | 219/287 [00:00<00:00, 540.87it/s]Iter (ce_loss=5.720):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=3.742):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=6.182):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=1.249):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=1.459):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=1.865):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=2.017):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=4.009):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=6.338):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=3.451):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=1.585):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=3.505):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=9.508):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=1.273):  95%|█████████▌| 274/287 [00:00<00:00, 541.76it/s]Iter (ce_loss=1.273): 100%|██████████| 287/287 [00:00<00:00, 541.29it/s]
Epoch: [3] :  Loss 3.6027
in-domain f1:0.8655844282525891
gda
estimated threshold: 0.0
                                                  precision    recall  f1-score   support

balance_not_updated_after_cheque_or_cash_deposit       0.00      0.00      0.00        40
                         beneficiary_not_allowed       0.00      0.00      0.00        40
                                 cancel_transfer       0.00      0.00      0.00        40
                                    card_arrival       0.00      0.00      0.00        40
                                 exchange_charge       0.00      0.00      0.00        40
                       extra_charge_on_statement       0.00      0.00      0.00        40
                           fiat_currency_support       0.00      0.00      0.00        40
                     get_disposable_virtual_card       0.00      0.00      0.00        40
                            pending_card_payment       0.00      0.00      0.00        40
                                  pending_top_up       0.00      0.00      0.00        40
                                pending_transfer       0.00      0.00      0.00        40
                  supported_cards_and_currencies       0.00      0.00      0.00        40
                                   top_up_failed       0.00      0.00      0.00        40
                                   top_up_limits       0.00      0.00      0.00        40
                           transfer_into_account       0.00      0.00      0.00        40
                                          unseen       0.75      1.00      0.86      2320
                              verify_my_identity       0.00      0.00      0.00        40
                          verify_source_of_funds       0.00      0.00      0.00        40
                                   verify_top_up       0.00      0.00      0.00        40
                             why_verify_identity       0.00      0.00      0.00        40

                                        accuracy                           0.75      3080
                                       macro avg       0.04      0.05      0.04      3080
                                    weighted avg       0.57      0.75      0.65      3080


Results have been saved to: ./outputs/openset/scl/metrics/results.csv
Appended new result row:
   dataset  seed  ...  K-F1      N-F1
0  banking     0  ...   0.0  0.859259

[1 rows x 9 columns]
lof
                                                  precision    recall  f1-score   support

balance_not_updated_after_cheque_or_cash_deposit       0.23      0.85      0.37        40
                         beneficiary_not_allowed       0.32      0.72      0.45        40
                                 cancel_transfer       0.54      0.75      0.62        40
                                    card_arrival       0.11      0.97      0.20        40
                                 exchange_charge       0.33      0.88      0.48        40
                       extra_charge_on_statement       0.34      0.93      0.50        40
                           fiat_currency_support       0.55      0.85      0.67        40
                     get_disposable_virtual_card       0.34      0.85      0.49        40
                            pending_card_payment       0.18      0.75      0.28        40
                                  pending_top_up       0.33      0.65      0.43        40
                                pending_transfer       0.16      0.88      0.27        40
                  supported_cards_and_currencies       0.20      0.72      0.32        40
                                   top_up_failed       0.14      0.90      0.24        40
                                   top_up_limits       0.39      0.90      0.54        40
                           transfer_into_account       0.55      0.78      0.65        40
                                          unseen       0.95      0.32      0.47      2320
                              verify_my_identity       0.65      0.65      0.65        40
                          verify_source_of_funds       0.53      0.97      0.69        40
                                   verify_top_up       0.97      0.97      0.97        40
                             why_verify_identity       0.27      0.75      0.40        40

                                        accuracy                           0.44      3080
                                       macro avg       0.40      0.80      0.48      3080
                                    weighted avg       0.81      0.44      0.48      3080


Results have been saved to: ./outputs/openset/scl/metrics/results.csv
Appended new result row:
   dataset  seed  ...      K-F1     N-F1
0  banking     0  ...  0.485164  0.47416

[1 rows x 9 columns]
msp
estimated threshold: -0.9824137686683105
                                                  precision    recall  f1-score   support

balance_not_updated_after_cheque_or_cash_deposit       0.78      0.62      0.69        40
                         beneficiary_not_allowed       0.00      0.00      0.00        40
                                 cancel_transfer       0.00      0.00      0.00        40
                                    card_arrival       0.00      0.00      0.00        40
                                 exchange_charge       0.00      0.00      0.00        40
                       extra_charge_on_statement       0.60      0.45      0.51        40
                           fiat_currency_support       0.00      0.00      0.00        40
                     get_disposable_virtual_card       0.71      0.62      0.67        40
                            pending_card_payment       1.00      0.03      0.05        40
                                  pending_top_up       0.00      0.00      0.00        40
                                pending_transfer       0.00      0.00      0.00        40
                  supported_cards_and_currencies       0.00      0.00      0.00        40
                                   top_up_failed       0.00      0.00      0.00        40
                                   top_up_limits       0.00      0.00      0.00        40
                           transfer_into_account       0.00      0.00      0.00        40
                                          unseen       0.77      0.99      0.86      2320
                              verify_my_identity       0.00      0.00      0.00        40
                          verify_source_of_funds       0.00      0.00      0.00        40
                                   verify_top_up       0.00      0.00      0.00        40
                             why_verify_identity       0.00      0.00      0.00        40

                                        accuracy                           0.77      3080
                                       macro avg       0.19      0.14      0.14      3080
                                    weighted avg       0.62      0.77      0.68      3080


Results have been saved to: ./outputs/openset/scl/metrics/results.csv
Appended new result row:
   dataset  seed  ...      K-F1      N-F1
0  banking     0  ...  0.101272  0.864202

[1 rows x 9 columns]
All SCL experiments have been completed.
SUCCESS: Script scripts/openset/scl.sh finished successfully in 30 seconds.

=====================================================
All tasks completed. Log file saved to: run_log_2025-09-16_18-56-22.txt
