{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/19/2025 16:06:13 - INFO - training_args -   PyTorch: setting up devices\n",
      "01/19/2025 16:06:13 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False\n",
      "01/19/2025 16:06:13 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='./model_output/', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=True, model_parallel=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=32, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.0001, adam_beta1=0.9, adam_beta2=0.98, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Jan19_16-06-13_gakki', logging_first_step=False, logging_steps=1000000, save_steps=1000000, save_total_limit=None, no_cuda=False, seed=0, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000000, dataloader_num_workers=0, past_index=-1, run_name='./model_output/', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_skip=False, fp16_backend='auto', sharded_ddp=False, fitlog_dir='./logs', multi_head_num=32, sample_file='./data/snips/train.tsv', max_length=128, sim_embed='/remote-home/dmsong/train_data/adv_learn/counter-fitted-vectors.txt', cosine_npy='/remote-home/dmsong/train_data/adv_learn/cos_sim_counter_fitting.npy', train_multi_head=False, model_path='bert-base-uncased', load_trained_model=False, load_model_pattern='knn_bert', num_labels=2, known_ratio=0.25, data='snips', lmcl=False, cl_model='', rnn_number_layers=1, sup_cont=False, supcont_pre_epoches=50, ind_pre_epoches=30, norm_coef=0.1, setting='lof', cl_mode=1, hidden_dim=128, clip=0.25, mode='both', temperature=0.5, auto_th=25)\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2020 The HuggingFace Inc. team. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\" Finetuning the library models for sequence classification on GLUE.\"\"\"\n",
    "# You can also adapt this script_v0 on your own text classification task. Pointers for this are left as comments.\n",
    "import json\n",
    "import os\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "\n",
    "import dataclasses\n",
    "import inspect\n",
    "import logging\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import fitlog\n",
    "from dataclasses import dataclass, field\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    EvalPrediction,\n",
    "    set_seed,\n",
    ")\n",
    "#from trainer_knn import SimpleTrainer\n",
    "from trainer import SimpleTrainer\n",
    "from evaluate import Evaluation\n",
    "\n",
    "from training_args import TrainingArguments\n",
    "#from model import (\n",
    "#   ContrastiveOrigin,\n",
    "#    ContrastiveMoCoKnnBert\n",
    "#)\n",
    "from model import (\n",
    "    ContrastiveOrigin,\n",
    "    ContrastiveMoCoKnnBert\n",
    ")\n",
    "from transformers.trainer_utils import is_main_process\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
    "\n",
    "    Using `HfArgumentParser` we can turn this class\n",
    "    into argparse arguments to be able to specify them on\n",
    "    the command line.\n",
    "    \"\"\"\n",
    "\n",
    "    task_name: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The name of the task to train on: \" + \", \".join(task_to_keys.keys())},\n",
    "    )\n",
    "    max_seq_length: int = field(\n",
    "        default=128,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "                    \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n",
    "    )\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=True,\n",
    "        metadata={\n",
    "            \"help\": \"Whether to pad all samples to `max_seq_length`. \"\n",
    "                    \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    train_file: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"A csv or a json file containing the training data.\"}\n",
    "    )\n",
    "    valid_file: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"A csv or a json file containing the validation data.\"}\n",
    "    )\n",
    "    test_file: Optional[str] = field(\n",
    "        default=None,\n",
    "    )\n",
    "\n",
    "    # def __post_init__(self):\n",
    "    #     if self.task_name is not None:\n",
    "    #         self.task_name = self.task_name.lower()\n",
    "    #         if self.task_name not in task_to_keys.keys():\n",
    "    #             raise ValueError(\"Unknown task, you should pick one in \" + \",\".join(task_to_keys.keys()))\n",
    "    #     elif self.train_file is None or self.valid_file is None:\n",
    "    #         raise ValueError(\"Need either a GLUE task or a training/validation file.\")\n",
    "    #     else:\n",
    "    #         extension = self.train_file.split(\".\")[-1]\n",
    "    #         assert extension in [\"csv\", \"json\", \"tsv\"], \"`train_file` should be a csv or a json file.\"\n",
    "    #         extension = self.valid_file.split(\".\")[-1]\n",
    "    #         assert extension in [\"csv\", \"json\", \"tsv\"], \"`validation_file` should be a csv or a json file.\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
    "    )\n",
    "    use_fast_tokenizer: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"},\n",
    "    )\n",
    "\n",
    "    train_pattern: str = field(default=\"further_pretrain\")\n",
    "\n",
    "@dataclass\n",
    "class FitLogArguments:\n",
    "    #task: str = field(default='mrpc')\n",
    "    negative_num: int = field(default=96)\n",
    "    positive_num: int = field(default=3)\n",
    "    queue_size: int = field(default=32000)\n",
    "    top_k: int = field(default=20)\n",
    "    end_k: int = field(default=1)\n",
    "    m: float = field(default=0.999)\n",
    "    contrastive_rate_in_training: float = field(default=0.1)\n",
    "    contrastive_rate_in_inference: float = field(default=0.1)\n",
    "\n",
    "\n",
    "def data_collator(features):\n",
    "    \"\"\"\n",
    "    Very simple data collator that simply collates batches of dict-like objects and performs special handling for\n",
    "    potential keys named:\n",
    "\n",
    "        - ``label``: handles a single value (int or float) per object\n",
    "        - ``label_ids``: handles a list of values per object\n",
    "\n",
    "    Does not do any additional preprocessing: property names of the input object will be used as corresponding inputs\n",
    "    to the model. See glue and ner for example of how it's useful.\n",
    "    \"\"\"\n",
    "\n",
    "    first = features[0]\n",
    "    batch = {}\n",
    "    if \"original_text\" in first:\n",
    "        batch[\"original_text\"] = [f[\"original_text\"] for f in features]\n",
    "    # Special handling for labels.\n",
    "    # Ensure that tensor is created with the correct type\n",
    "    # (it should be automatically the case, but let's make sure of it.)\n",
    "    if \"label\" in first and first[\"label\"] is not None:\n",
    "        label = first[\"label\"].item() if isinstance(first[\"label\"], torch.Tensor) else first[\"label\"]\n",
    "        dtype = torch.long if isinstance(label, int) else torch.float\n",
    "        batch[\"labels\"] = torch.tensor([f[\"label\"] for f in features], dtype=dtype)\n",
    "    elif \"label_ids\" in first and first[\"label_ids\"] is not None:\n",
    "        if isinstance(first[\"label_ids\"], torch.Tensor):\n",
    "            batch[\"labels\"] = torch.stack([f[\"label_ids\"] for f in features])\n",
    "        else:\n",
    "            dtype = torch.long if type(first[\"label_ids\"][0]) is int else torch.float\n",
    "            batch[\"labels\"] = torch.tensor([f[\"label_ids\"] for f in features], dtype=dtype)\n",
    "\n",
    "    # Handling of all other possible keys.\n",
    "    # Again, we will use the first element to figure out which key/values are not None for this model.\n",
    "    for k, v in first.items():\n",
    "        if k not in (\"label\", \"label_ids\") and v is not None and not isinstance(v, str):\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = torch.stack([f[k] for f in features])\n",
    "            else:\n",
    "                batch[k] = torch.tensor([f[k] for f in features])\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "# See all possible arguments in src/transformers/training_args.py\n",
    "# or by passing the --help flag to this script_v0.\n",
    "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "\n",
    "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments, FitLogArguments))\n",
    "\n",
    "\n",
    "model_args, data_args, training_args, fitlog_args = parser.parse_json_file(json_file=os.path.abspath('json/snips/0.25/0.json'))\n",
    "\n",
    "\n",
    "# model_args, data_args, training_args, fitlog_args = parser.parse_json_file(json_file=os.path.abspath('json/snips/0.25/0.json'))\n",
    "\n",
    "results_path = './model_output/' + '_'.join([training_args.data, str(training_args.known_ratio), str(training_args.seed)]) + '.csv'\n",
    "if os.path.exists(results_path):\n",
    "    exit()\n",
    "\n",
    "# model_args, data_args, training_args, fitlog_args = parser.parse_json_file(json_file='json/demo.json')\n",
    "\n",
    "data_args.train_file = './data/' + training_args.data + '/train.tsv'\n",
    "data_args.valid_file = './data/' + training_args.data + '/valid.tsv'\n",
    "data_args.test_file = './data/' + training_args.data + '/test.tsv'\n",
    "training_args.sample_file = data_args.train_file\n",
    "training_args.max_length = data_args.max_seq_length\n",
    "fitlog.set_log_dir(training_args.fitlog_dir)\n",
    "fitlog_args_dict = {\"seed\": training_args.seed,\n",
    "                    \"warmup_steps\": training_args.warmup_steps}\n",
    "\n",
    "fitlog_args_name = [i for i in dir(fitlog_args) if i[0] != \"_\"]\n",
    "for args_name in fitlog_args_name:\n",
    "    args_value = getattr(fitlog_args, args_name)\n",
    "    training_args.__dict__[args_name] = args_value\n",
    "    if args_value is not None:\n",
    "        fitlog_args_dict[args_name] = args_value\n",
    "fitlog.add_hyper(fitlog_args_dict)\n",
    "\n",
    "if (\n",
    "        os.path.exists(training_args.output_dir)\n",
    "        and os.listdir(training_args.output_dir)\n",
    "        and training_args.do_train\n",
    "        and not training_args.overwrite_output_dir\n",
    "):\n",
    "    raise ValueError(\n",
    "        f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "        \"Use --overwrite_output_dir to overcome.\"\n",
    "    )\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO if is_main_process(training_args.local_rank) else logging.WARN,\n",
    ")\n",
    "\n",
    "# Log on each process the small summary:\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "# Set the verbosity to info of the Transformers logger (on main process only):\n",
    "if is_main_process(training_args.local_rank):\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "    transformers.utils.logging.enable_default_handler()\n",
    "    transformers.utils.logging.enable_explicit_format()\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "# Set seed before initializing model.\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "# See more about loading any type of standard or custom dataset at\n",
    "# https://huggingface.co/docs/datasets/loading_datasets.html.\n",
    "df_train = pd.read_csv(data_args.train_file, sep='\\t', dtype=str)\n",
    "df_valid = pd.read_csv(data_args.valid_file, sep='\\t', dtype=str)\n",
    "df_test = pd.read_csv(data_args.test_file, sep='\\t', dtype=str)\n",
    "\n",
    "unique_labels = np.array(list(set(df_test.label.unique()) & set(df_train.label.unique())))\n",
    "seen_labels = np.random.choice(unique_labels, int(len(unique_labels)*training_args.known_ratio), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_seen = df_train[df_train.label.isin(seen_labels)]\n",
    "df_valid_seen = df_valid[df_valid.label.isin(seen_labels)]\n",
    "df_valid_oos = df_valid[~df_valid.label.isin(seen_labels)]\n",
    "df_valid_oos.loc[:, \"label\"] = 'oos'\n",
    "df_test.loc[~df_test.label.isin(seen_labels), \"label\"] = 'oos'\n",
    "\n",
    "data = dict()\n",
    "data[\"train\"] = Dataset.from_pandas(df_train_seen, preserve_index=False)\n",
    "data[\"valid_seen\"] = Dataset.from_pandas(df_valid_seen, preserve_index=False)\n",
    "data[\"valid_oos\"] = Dataset.from_pandas(df_valid_oos, preserve_index=False)\n",
    "data[\"test\"] = Dataset.from_pandas(df_test, preserve_index=False)\n",
    "datasets = DatasetDict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/19/2025 15:59:17 - WARNING - training_args -   Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    }
   ],
   "source": [
    "valid_loader = evaler.get_eval_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PlayMusic', 'AddToPlaylist', 'RateBook', 'SearchScreeningEvent',\n",
       "       'BookRestaurant', 'GetWeather', 'SearchCreativeWork'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['oos', 'SearchScreeningEvent'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/snips/test.tsv'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_args.test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AddToPlaylist', 'SearchCreativeWork', 'PlayMusic', 'RateBook',\n",
       "       'BookRestaurant', 'GetWeather', 'SearchScreeningEvent'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
