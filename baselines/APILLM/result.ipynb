{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "dataset_list = ['banking', 'clinc', 'stackoverflow']\n",
    "model_list = ['deepseek-chat', 'gpt-4o-mini']\n",
    "for dataset_name in dataset_list:\n",
    "    for ratio in [0.25, 0.5, 0.75]:\n",
    "        candidate_list = json.load(open(f\"../../data/{dataset_name}/{dataset_name}_{ratio}/train_taxnomy.json\", 'r'))['root']\n",
    "        df = pd.read_csv(f\"../../data/{dataset_name}/origin_data/test.tsv\", sep='\\t')\n",
    "        df['label'] = df['label'].apply(lambda x: x.replace('_', ' '))\n",
    "        for model_name in model_list:\n",
    "            for seed in range(1):\n",
    "                ans = {'gold':[], 'pred':[], 'text':[], 'id': []}\n",
    "                dir_name = f\"outputs/{dataset_name}/{ratio}/{model_name}/seed{seed}\"\n",
    "                if os.path.exists(f\"{dir_name}\"):\n",
    "                    for i in os.listdir(dir_name):\n",
    "                        i = int(i[:-4])\n",
    "                        content = open(f\"{dir_name}/{i}.txt\", 'r').read()\n",
    "                        pred = 'Novel'\n",
    "                        gold = 'Novel'\n",
    "                        for can in candidate_list:\n",
    "                            if can in content:\n",
    "                                pred = can\n",
    "                                break\n",
    "                        ans['pred'].append(pred)\n",
    "                        ans['text'].append(df['text'][i])\n",
    "                        ans['id'].append(i)\n",
    "                        if df['label'][i] in candidate_list:\n",
    "                            gold = df['label'][i]\n",
    "                        ans['gold'].append(gold)\n",
    "                ans = pd.DataFrame(ans)\n",
    "                if len(ans) > 0:\n",
    "                    if not os.path.exists(f'results/{dataset_name}/{ratio}/{model_name}'):\n",
    "                        os.makedirs(f'results/{dataset_name}/{ratio}/{model_name}')\n",
    "                    ans.to_csv(f'results/{dataset_name}/{ratio}/{model_name}/{seed}.tsv', index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "ans = {'method':[],'dataset':[],'ratio':[],'value':[],'metric':[]}\n",
    "for dataset_name in dataset_list:\n",
    "    for ratio in [0.25, 0.5, 0.75]:\n",
    "        for model_name in model_list:\n",
    "            for seed in range(1):\n",
    "                file_path = f\"results/{dataset_name}/{ratio}/{model_name}/{seed}.tsv\"\n",
    "                if os.path.exists(file_path):\n",
    "                    df = pd.read_csv(file_path, sep='\\t')\n",
    "                    report = classification_report(df['gold'], df['pred'], output_dict=True)\n",
    "                    metric_result = {}\n",
    "                    metric_result['F1'] = report['macro avg']['f1-score']\n",
    "                    metric_result['ACC'] = report['accuracy']\n",
    "                    metric_result['N-F1'] = report['Novel']['f1-score']\n",
    "                    metric_result['K-F1'] = sum([report[i]['f1-score'] for i in report if i not in ['Novel', 'accuracy', 'macro avg', 'weighted avg']]) / (df['gold'].nunique() - 1) if df['gold'].nunique() - 1 != 0 else 0\n",
    "                    for k in metric_result:\n",
    "                        ans['method'].append(model_name)\n",
    "                        ans['dataset'].append(dataset_name)\n",
    "                        ans['ratio'].append(ratio)\n",
    "                        ans['value'].append(metric_result[k] * 100)\n",
    "                        ans['metric'].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:29: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\o'\n",
      "/tmp/ipykernel_1909880/2652289167.py:29: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  ans['method'].append('\\ourmodel')\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/data/chenxi/miniconda3/envs/acl25/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ratio</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>banking</td>\n",
       "      <td>0.25</td>\n",
       "      <td>53.295664</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>banking</td>\n",
       "      <td>0.25</td>\n",
       "      <td>42.682927</td>\n",
       "      <td>ACC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>banking</td>\n",
       "      <td>0.25</td>\n",
       "      <td>40.199336</td>\n",
       "      <td>N-F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>banking</td>\n",
       "      <td>0.25</td>\n",
       "      <td>53.984944</td>\n",
       "      <td>K-F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>banking</td>\n",
       "      <td>0.25</td>\n",
       "      <td>43.582147</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>\\ourmodel</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>0.50</td>\n",
       "      <td>88.214507</td>\n",
       "      <td>K-F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>\\ourmodel</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>0.75</td>\n",
       "      <td>91.356494</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>\\ourmodel</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>0.75</td>\n",
       "      <td>94.133697</td>\n",
       "      <td>ACC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>\\ourmodel</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>0.75</td>\n",
       "      <td>95.905172</td>\n",
       "      <td>N-F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>\\ourmodel</td>\n",
       "      <td>stackoverflow</td>\n",
       "      <td>0.75</td>\n",
       "      <td>91.053249</td>\n",
       "      <td>K-F1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            method        dataset  ratio      value metric\n",
       "0    deepseek-chat        banking   0.25  53.295664     F1\n",
       "1    deepseek-chat        banking   0.25  42.682927    ACC\n",
       "2    deepseek-chat        banking   0.25  40.199336   N-F1\n",
       "3    deepseek-chat        banking   0.25  53.984944   K-F1\n",
       "4      gpt-4o-mini        banking   0.25  43.582147     F1\n",
       "..             ...            ...    ...        ...    ...\n",
       "103      \\ourmodel  stackoverflow   0.50  88.214507   K-F1\n",
       "104      \\ourmodel  stackoverflow   0.75  91.356494     F1\n",
       "105      \\ourmodel  stackoverflow   0.75  94.133697    ACC\n",
       "106      \\ourmodel  stackoverflow   0.75  95.905172   N-F1\n",
       "107      \\ourmodel  stackoverflow   0.75  91.053249   K-F1\n",
       "\n",
       "[108 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "for dataset_name in dataset_list:\n",
    "    for ratio in [0.25, 0.5, 0.75]:\n",
    "        for model_name in model_list[:1]:\n",
    "            for seed in range(1):\n",
    "                file_path = f\"results/{dataset_name}/{ratio}/{model_name}/{seed}.tsv\"\n",
    "                if os.path.exists(file_path):\n",
    "                    df = pd.read_csv(file_path, sep='\\t')\n",
    "                idx_list = []\n",
    "                dir_name = f\"outputs/{dataset_name}/{ratio}/{model_name}/seed{seed}\"\n",
    "                if os.path.exists(f\"{dir_name}\"):\n",
    "                    for i in os.listdir(dir_name):\n",
    "                        i = int(i[:-4])\n",
    "                        idx_list.append(i)\n",
    "\n",
    "                preds = torch.load(f'../../outputs/{dataset_name}/{dataset_name}-{ratio}--1/Meta-Llama-3.1-8B-Instruct-1-2-2-20-binary_0.1_0.1_1.0-sft-qlora-dsz3-seed_0/ood_eval_scores/test_binary_preds.pt')\n",
    "                golds = torch.load(f'../../outputs/{dataset_name}/{dataset_name}-{ratio}--1/Meta-Llama-3.1-8B-Instruct-1-2-2-20-binary_0.1_0.1_1.0-sft-qlora-dsz3-seed_0/ood_eval_scores/test_golds.pt')\n",
    "                pred = preds[idx_list]\n",
    "                gold = golds[idx_list]\n",
    "\n",
    "                report = classification_report(gold, pred, output_dict=True)\n",
    "                metric_result = {}\n",
    "                metric_result['F1'] = report['macro avg']['f1-score']\n",
    "                metric_result['ACC'] = report['accuracy']\n",
    "                metric_result['N-F1'] = report['0']['f1-score']\n",
    "                metric_result['K-F1'] = sum([report[i]['f1-score'] for i in report if i not in ['0', 'accuracy', 'macro avg', 'weighted avg']]) / (df['gold'].nunique() - 1) if df['gold'].nunique() - 1 != 0 else 0\n",
    "\n",
    "                for k in metric_result:\n",
    "                    ans['method'].append('\\ourmodel')\n",
    "                    ans['dataset'].append(dataset_name)\n",
    "                    ans['ratio'].append(ratio)\n",
    "                    ans['value'].append(metric_result[k] * 100)\n",
    "                    ans['metric'].append(k)\n",
    "ans = pd.DataFrame(ans)\n",
    "ans.to_csv('../../table_results/csv/Close-LLM_result.csv', index=None)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\o'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\o'\n",
      "/tmp/ipykernel_1909880/615028707.py:1: SyntaxWarning: invalid escape sequence '\\o'\n",
      "  ans['method'] = pd.Categorical(ans['method'], categories=['gpt-4o-mini', 'deepseek-chat', '\\ourmodel'], ordered=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"4\" halign=\"left\">banking</th>\n",
       "      <th colspan=\"4\" halign=\"left\">clinc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">stackoverflow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>K-F1</th>\n",
       "      <th>N-F1</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>K-F1</th>\n",
       "      <th>N-F1</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>K-F1</th>\n",
       "      <th>N-F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio</th>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.25</th>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>31.45</td>\n",
       "      <td>43.58</td>\n",
       "      <td>47.25</td>\n",
       "      <td>24.88</td>\n",
       "      <td>30.24</td>\n",
       "      <td>42.37</td>\n",
       "      <td>48.75</td>\n",
       "      <td>20.34</td>\n",
       "      <td>70.49</td>\n",
       "      <td>67.76</td>\n",
       "      <td>65.82</td>\n",
       "      <td>77.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-chat</th>\n",
       "      <td>42.68</td>\n",
       "      <td>53.30</td>\n",
       "      <td>53.98</td>\n",
       "      <td>40.20</td>\n",
       "      <td>42.67</td>\n",
       "      <td>52.14</td>\n",
       "      <td>52.46</td>\n",
       "      <td>40.11</td>\n",
       "      <td>71.08</td>\n",
       "      <td>71.00</td>\n",
       "      <td>69.85</td>\n",
       "      <td>76.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\ourmodel</th>\n",
       "      <td>91.77</td>\n",
       "      <td>78.23</td>\n",
       "      <td>77.34</td>\n",
       "      <td>95.08</td>\n",
       "      <td>95.20</td>\n",
       "      <td>84.35</td>\n",
       "      <td>79.44</td>\n",
       "      <td>97.14</td>\n",
       "      <td>97.04</td>\n",
       "      <td>90.70</td>\n",
       "      <td>89.18</td>\n",
       "      <td>98.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.50</th>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>41.26</td>\n",
       "      <td>53.59</td>\n",
       "      <td>59.55</td>\n",
       "      <td>5.77</td>\n",
       "      <td>43.90</td>\n",
       "      <td>52.74</td>\n",
       "      <td>60.76</td>\n",
       "      <td>9.52</td>\n",
       "      <td>78.26</td>\n",
       "      <td>78.22</td>\n",
       "      <td>78.41</td>\n",
       "      <td>76.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-chat</th>\n",
       "      <td>47.56</td>\n",
       "      <td>58.61</td>\n",
       "      <td>59.42</td>\n",
       "      <td>27.84</td>\n",
       "      <td>59.20</td>\n",
       "      <td>67.63</td>\n",
       "      <td>67.88</td>\n",
       "      <td>49.01</td>\n",
       "      <td>77.87</td>\n",
       "      <td>80.61</td>\n",
       "      <td>81.12</td>\n",
       "      <td>75.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\ourmodel</th>\n",
       "      <td>91.31</td>\n",
       "      <td>80.27</td>\n",
       "      <td>77.79</td>\n",
       "      <td>94.36</td>\n",
       "      <td>94.80</td>\n",
       "      <td>91.85</td>\n",
       "      <td>86.89</td>\n",
       "      <td>96.53</td>\n",
       "      <td>93.63</td>\n",
       "      <td>88.90</td>\n",
       "      <td>88.21</td>\n",
       "      <td>95.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.75</th>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>50.00</td>\n",
       "      <td>57.21</td>\n",
       "      <td>62.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>56.59</td>\n",
       "      <td>58.92</td>\n",
       "      <td>65.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>82.13</td>\n",
       "      <td>85.40</td>\n",
       "      <td>87.00</td>\n",
       "      <td>61.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-chat</th>\n",
       "      <td>58.08</td>\n",
       "      <td>66.61</td>\n",
       "      <td>67.58</td>\n",
       "      <td>11.40</td>\n",
       "      <td>61.07</td>\n",
       "      <td>74.63</td>\n",
       "      <td>75.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>83.90</td>\n",
       "      <td>87.07</td>\n",
       "      <td>88.08</td>\n",
       "      <td>71.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\ourmodel</th>\n",
       "      <td>92.53</td>\n",
       "      <td>91.12</td>\n",
       "      <td>91.07</td>\n",
       "      <td>93.89</td>\n",
       "      <td>95.47</td>\n",
       "      <td>91.42</td>\n",
       "      <td>83.21</td>\n",
       "      <td>96.41</td>\n",
       "      <td>94.13</td>\n",
       "      <td>91.36</td>\n",
       "      <td>91.05</td>\n",
       "      <td>95.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      value                                                   \\\n",
       "dataset             banking                       clinc                        \n",
       "metric                  ACC     F1   K-F1   N-F1    ACC     F1   K-F1   N-F1   \n",
       "ratio method                                                                   \n",
       "0.25  gpt-4o-mini     31.45  43.58  47.25  24.88  30.24  42.37  48.75  20.34   \n",
       "      deepseek-chat   42.68  53.30  53.98  40.20  42.67  52.14  52.46  40.11   \n",
       "      \\ourmodel       91.77  78.23  77.34  95.08  95.20  84.35  79.44  97.14   \n",
       "0.50  gpt-4o-mini     41.26  53.59  59.55   5.77  43.90  52.74  60.76   9.52   \n",
       "      deepseek-chat   47.56  58.61  59.42  27.84  59.20  67.63  67.88  49.01   \n",
       "      \\ourmodel       91.31  80.27  77.79  94.36  94.80  91.85  86.89  96.53   \n",
       "0.75  gpt-4o-mini     50.00  57.21  62.72   0.00  56.59  58.92  65.77   0.00   \n",
       "      deepseek-chat   58.08  66.61  67.58  11.40  61.07  74.63  75.30   0.00   \n",
       "      \\ourmodel       92.53  91.12  91.07  93.89  95.47  91.42  83.21  96.41   \n",
       "\n",
       "                                                        \n",
       "dataset             stackoverflow                       \n",
       "metric                        ACC     F1   K-F1   N-F1  \n",
       "ratio method                                            \n",
       "0.25  gpt-4o-mini           70.49  67.76  65.82  77.44  \n",
       "      deepseek-chat         71.08  71.00  69.85  76.74  \n",
       "      \\ourmodel             97.04  90.70  89.18  98.30  \n",
       "0.50  gpt-4o-mini           78.26  78.22  78.41  76.34  \n",
       "      deepseek-chat         77.87  80.61  81.12  75.44  \n",
       "      \\ourmodel             93.63  88.90  88.21  95.72  \n",
       "0.75  gpt-4o-mini           82.13  85.40  87.00  61.54  \n",
       "      deepseek-chat         83.90  87.07  88.08  71.83  \n",
       "      \\ourmodel             94.13  91.36  91.05  95.91  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans['method'] = pd.Categorical(ans['method'], categories=['gpt-4o-mini', 'deepseek-chat', '\\ourmodel'], ordered=True)\n",
    "ans = ans.sort_values(['ratio', 'method', 'dataset', 'metric'])\n",
    "ans = ans.pivot(index=['ratio', 'method'], columns=['dataset', 'metric'], values=['value'])\n",
    "ans = ans.round(2)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "&&\\multicolumn{12}{r}{value}\\\\\n",
      "&dataset&\\multicolumn{4}{r}{banking}&\\multicolumn{4}{r}{clinc}&\\multicolumn{4}{r}{stackoverflow}\\\\\n",
      "&metric&ACC&F1&K-F1&N-F1&ACC&F1&K-F1&N-F1&ACC&F1&K-F1&N-F1\\\\\n",
      "ratio&method&&&&&&&&&&&&\\\\\n",
      "\\midrule\n",
      "\\multirow[t]{3}{*}{0.25}&GPT-4o-mini&31.45&43.58&47.25&24.88&30.24&42.37&48.75&20.34&70.49&67.76&65.82&77.44\\\\\n",
      "&DeepSeek-V3&42.68&53.30&53.98&40.20&42.67&52.14&52.46&40.11&71.08&71.00&69.85&76.74\\\\\n",
      "&\\ourmodel&91.77&78.23&77.34&95.08&95.20&84.35&79.44&97.14&97.04&90.70&89.18&98.30\\\\\n",
      "\\midrule\n",
      "\\multirow[t]{3}{*}{0.50}&GPT-4o-mini&41.26&53.59&59.55&5.77&43.90&52.74&60.76&9.52&78.26&78.22&78.41&76.34\\\\\n",
      "&DeepSeek-V3&47.56&58.61&59.42&27.84&59.20&67.63&67.88&49.01&77.87&80.61&81.12&75.44\\\\\n",
      "&\\ourmodel&91.31&80.27&77.79&94.36&94.80&91.85&86.89&96.53&93.63&88.90&88.21&95.72\\\\\n",
      "\\midrule\n",
      "\\multirow[t]{3}{*}{0.75}&GPT-4o-mini&50.00&57.21&62.72&0.00&56.59&58.92&65.77&0.00&82.13&85.40&87.00&61.54\\\\\n",
      "&DeepSeek-V3&58.08&66.61&67.58&11.40&61.07&74.63&75.30&0.00&83.90&87.07&88.08&71.83\\\\\n",
      "&\\ourmodel&92.53&91.12&91.07&93.89&95.47&91.42&83.21&96.41&94.13&91.36&91.05&95.91\\\\\n",
      "\\midrule\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "/tmp/ipykernel_1909880/2563063742.py:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  latex_text = latex_text.replace('gpt-4o-mini', 'GPT-4o-mini').replace('deepseek-chat', 'DeepSeek-V3').replace(' ', '').replace('0000', '').replace('\\cline{1-14}', '\\midrule')\n",
      "/tmp/ipykernel_1909880/2563063742.py:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  latex_text = latex_text.replace('gpt-4o-mini', 'GPT-4o-mini').replace('deepseek-chat', 'DeepSeek-V3').replace(' ', '').replace('0000', '').replace('\\cline{1-14}', '\\midrule')\n"
     ]
    }
   ],
   "source": [
    "latex_text = ans.to_latex()\n",
    "latex_text = latex_text.replace('gpt-4o-mini', 'GPT-4o-mini').replace('deepseek-chat', 'DeepSeek-V3').replace(' ', '').replace('0000', '').replace('\\cline{1-14}', '\\midrule')\n",
    "print(latex_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acl25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
